diff --git a/dff.txt b/dff.txt
index 1d46b53..3371a54 100644
--- a/dff.txt
+++ b/dff.txt
@@ -1,6710 +1,52 @@
-diff --git a/susebox/java/io/ExtIOException.java b/susebox/java/io/ExtIOException.java
-new file mode 100644
-index 0000000..877f9e5
---- /dev/null
-+++ b/susebox/java/io/ExtIOException.java
-@@ -0,0 +1,201 @@
-+/*
-+ * ExtIOException.java: Extended standard exception for stacks
-+ *
-+ * Copyright (C) 2001 Heiko Blau
-+ *
-+ * This file belongs to the Susebox Java Core Library (Susebox JCL).
-+ * The Susebox JCL is free software; you can redistribute it and/or modify it 
-+ * under the terms of the GNU Lesser General Public License as published by the 
-+ * Free Software Foundation; either version 2.1 of the License, or (at your 
-+ * option) any later version.
-+ *
-+ * This software is distributed in the hope that it will be useful, but WITHOUT
-+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or 
-+ * FITNESS FOR A PARTICULAR PURPOSE. 
-+ * See the GNU Lesser General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU Lesser General Public License along
-+ * with the Susebox JCL. If not, write to the
-+ *
-+ *   Free Software Foundation, Inc.
-+ *   59 Temple Place, Suite 330, 
-+ *   Boston, MA 02111-1307 
-+ *   USA
-+ *
-+ * or check the Internet: http://www.fsf.org
-+ *
-+ * Contact:
-+ *   email: heiko@susebox.de 
-+ */
-+
-+package de.susebox.java.io;
-+
-+//------------------------------------------------------------------------------
-+// Imports
-+//
-+import java.text.MessageFormat;
-+import java.io.IOException;
-+
-+import de.susebox.java.lang.ExceptionList;
-+
-+
-+//------------------------------------------------------------------------------
-+// ExtIOException - definition
-+//
-+
-+/** 
-+ * Implementation of the ExceptionList interface for the JDK IOException.
-+ *
-+ * @version	1.00, 2001/06/26
-+ * @author 	Heiko Blau
-+ */
-+public class ExtIOException 
-+  extends    IOException 
-+  implements ExceptionList 
-+{
-+  //---------------------------------------------------------------------------
-+  // methods of the ExceptionList interface
-+  //
-+  
-+  /**
-+   * Method to traverse the exception list. By convention, <CODE>nextException</CODE>
-+   * returns the "earlier" exception. By walking down the exception list one gets the
-+   * the following meaning:<br>
-+   * this happened because nextException happened because nextException happened...
-+   *
-+   * @return the "earlier" exception
-+   */  
-+  public Exception nextException() {
-+		return _next;
-+	}
-+
-+  /**
-+   * Check if <CODE>this</CODE> is only a exception that wraps the real one. This
-+   * might be nessecary to pass an exception incompatible to a method declaration.
-+   *
-+   * @return <CODE>true</CODE> if this is a wrapper exception,
-+   *         <CODE>false</CODE> otherwise
-+   */  
-+	public boolean isWrapperException() {
-+		return _isWrapper;
-+	}
-+
-+
-+  //---------------------------------------------------------------------------
-+  // constructors
-+  //
-+  
-+  /**
-+   * This constructor should be used for wrapping another exception. While reading
-+   * data an IOException may occur, but a certain interface requires a
-+   * {@link java.sql.SQLException}. Simply use:
-+   *<blockquote><pre>
-+   * try {
-+   *   ...
-+   * } catch (SQLException ex) {
-+   *   throw new ExtIOException(ex);
-+   * }
-+   *</pre></blockquote>
-+   *
-+   * @param ex the exception to wrap
-+   */  
-+	public ExtIOException(Exception ex) {
-+		this(ex, null, null);
-+	}
-+
-+  /**
-+   * If one likes to add ones own information to an exception, this constructor is
-+   * the easiest way to do so. By using such an approach a exception trace with useful
-+   * additional informations (which file could be found, what username is unknown)
-+   * can be realized:
-+   *<blockquote><pre>
-+   * try {
-+   *   ...
-+   * } catch (SQLException ex) {
-+   *   throw new ExtIOException(ex, "while connecting to " + url);
-+   * }
-+   *</pre></blockquote>
-+   *
-+   * @param ex    the inner exception
-+   * @param msg   exception message
-+   */  
-+	public ExtIOException(Exception ex, String msg) {
-+		this(ex, msg, null);
-+	}
-+
-+  /**
-+   * This constructor takes a format string and its arguments. The format string
-+   * must have a form that can be used by {@link java.text.MessageFormat} methods.
-+   * That means:
-+   *<blockquote><pre>
-+   *    java.text.Message.format(fmt, args)
-+   *</pre></blockquote>
-+   * is similar to
-+   *<blockquote><pre>
-+   *    new MyException(fmt, args).getMessage();
-+   *</pre></blockquote>
-+   *
-+   * @param fmt   exception message
-+   * @param args  arguments for the given format string
-+   */  
-+	public ExtIOException(String fmt, Object[] args) {
-+    this(null, fmt, args);
-+	}
-+  
-+  /**
-+   * This is the most complex way to construct an <CODE>ExceptionList</CODE>-
-+   * Exception.<br>
-+   * An inner exception is accompanied by a format string and its arguments.
-+   * Use this constructor in language-sensitive contexts or for formalized messages.
-+   * The meaning of the parameters is explained in the other constructors.
-+   *
-+   * @param ex    the inner exception
-+   * @param fmt   exception message
-+   * @param args  arguments for the given format string
-+   */  
-+	public ExtIOException(Exception ex, String msg, Object[] args) {
-+		super(msg);
-+		_next      = ex;
-+		_isWrapper = true;
-+	}
-+
-+
-+  //---------------------------------------------------------------------------
-+  // overridden methods
-+  //
-+  
-+  /**
-+   * Implementation of the standard {@link java.Throwable#getMessage} method to 
-+   * meet the requirements of formats and format arguments as well as wrapper
-+   * exceptions.
-+   * If this is a wrapper exception then the <CODE>getMessage</CODE> of the wrapped 
-+   * exception is returned.
-+   * If no arguments were given in the constructor then the format parameter is
-+   * taken as the formatted message itself. Otherwise it is treated like the
-+   * patter for the {@link java.text.MessageFormat#format} method.
-+   *
-+   * @return  the formatted exception message
-+   * @see     java.text.MessageFormat
-+   */  
-+	public String getMessage() {
-+    if (isWrapperException()) {
-+      return nextException().getMessage();
-+    } else {
-+      String fmt = super.getMessage();
-+
-+      if (_args == null) {
-+        return fmt;
-+      } else {
-+        return MessageFormat.format(fmt, _args);
-+      }
-+    }
-+	}
-+
-+  
-+  //---------------------------------------------------------------------------
-+  // members
-+  //
-+  protected Object[]  _args       = null;
-+  protected Exception _next       = null;
-+  protected boolean   _isWrapper  = false;
-+}
-diff --git a/susebox/java/lang/ExceptionList.java b/susebox/java/lang/ExceptionList.java
-new file mode 100644
-index 0000000..b0c3b24
---- /dev/null
-+++ b/susebox/java/lang/ExceptionList.java
-@@ -0,0 +1,231 @@
-+/*
-+ * ExceptionList.java: Interface for exception stacks
-+ *
-+ * Copyright (C) 2001 Heiko Blau
-+ *
-+ * This file belongs to the Susebox Java Core Library (Susebox JCL).
-+ * The Susebox JCL is free software; you can redistribute it and/or modify it
-+ * under the terms of the GNU Lesser General Public License as published by the
-+ * Free Software Foundation; either version 2.1 of the License, or (at your
-+ * option) any later version.
-+ *
-+ * This software is distributed in the hope that it will be useful, but WITHOUT
-+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
-+ * FITNESS FOR A PARTICULAR PURPOSE.
-+ * See the GNU Lesser General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU Lesser General Public License along
-+ * with the Susebox JCL. If not, write to the
-+ *
-+ *   Free Software Foundation, Inc.
-+ *   59 Temple Place, Suite 330,
-+ *   Boston, MA 02111-1307
-+ *   USA
-+ *
-+ * or check the Internet: http://www.fsf.org
-+ *
-+ * Contact:
-+ *   email: heiko@susebox.de
-+ */
-+
-+package de.susebox.java.lang;
-+
-+//------------------------------------------------------------------------------
-+// Imports
-+//
-+
-+/*-->
-+import java.text.MessageFormat;
-+ 
-+import de.susebox.java.lang.ExceptionList;
-+-->*/
-+
-+
-+//------------------------------------------------------------------------------
-+// Interface ExceptionList
-+//
-+
-+/**<p>
-+ * This interface should be implemented by exception classes that may contain
-+ * a stacked, additional or wrapped exception.
-+ *</p><p>
-+ * Such cases are common when
-+ *<ul><li>
-+ *   a method implements a certain interface method that allows for a specific
-+ *   exception like IOException, but the method itself may encounter a different
-+ *   exception type like SQLException (wrapped exception)
-+ *</li><li>
-+ *   one application layer catches an exception only to add its specific
-+ *   information in form of another exception (exception stack, nested exception
-+ *   like in SQLException or MessagingException).
-+ *</li></ul>
-+ *</p><p>
-+ * We provide the expected code in block comments starting with --&gt;, terminated
-+ * by --&gt;. Note that the provided code also includes a new implementation of
-+ * the base class method {@link java.lang.Throwable#getMessage} using the text
-+ * formatting capabilities of {@link java.text.MessageFormat}.
-+ *
-+ * @version	1.00, 2001/06/26
-+ * @author 	Heiko Blau
-+ */
-+public interface ExceptionList {
-+  /**
-+   * Method to traverse the exception list. By convention, <CODE>nextException</CODE>
-+   * returns the "earlier" exception. By walking down the exception list one gets the
-+   * the following meaning:<br>
-+   * this happened because nextException happened because nextException happened...
-+   *
-+   * @return the "earlier" exception
-+   */
-+  Exception nextException();
-+  /*-->
-+  {
-+    return _next;
-+  }
-+  -->*/
-+  
-+  
-+  /**
-+   * Check if <CODE>this</CODE> is only a exception that wraps the real one. This
-+   * might be nessecary to pass an exception incompatible to a method declaration.
-+   *
-+   * @return <CODE>true</CODE> if this is a wrapper exception,
-+   *         <CODE>false</CODE> otherwise
-+   */
-+  boolean isWrapperException();
-+  /*-->
-+  {
-+    return _isWrapper;
-+  }
-+  -->*/
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // implementation code templates
-+  //
-+  
-+  /**
-+   * This constructor should be used for wrapping another exception. While reading
-+   * data an IOException may occur, but a certain interface requires a
-+   * <CODE>SQLException</CODE>. Simply use:
-+   *<blockquote><pre>
-+   *   try {
-+   *     ...
-+   *   } catch (IOException ex) {
-+   *     throw new MyException(ex);
-+   *   }
-+   *</pre></blockquote>
-+   *
-+   * @param ex the exception to wrap
-+   */
-+  /*-->
-+  public <<WHICH>>Exception(Exception ex) {
-+    this(ex, null, null);
-+  }
-+  -->*/
-+  
-+  /**
-+   * If one likes to add ones own information to an exception, this constructor is
-+   * the easiest way to do so. By using such an approach a exception trace with useful
-+   * additional informations (which file could be found, what username is unknown)
-+   * can be realized:
-+   *<br><br><CODE>
-+   * try {                                                                      <br>&nbsp;
-+   *   ...                                                                      <br>
-+   * } catch (SQLException ex) {                                                <br>&nbsp;
-+   *   throw new MyException(ex, "while connecting to " + url);                 <br>
-+   * }
-+   *<br></CODE>
-+   *
-+   * @param ex    the inner exception
-+   * @param msg   exception message
-+   */
-+  /*-->
-+  public <<WHICH>>Exception(Exception ex, String msg) {
-+    this(ex, msg, null);
-+  }
-+  -->*/
-+  
-+  /**
-+   * This constructor takes a format string and its arguments. The format string
-+   * must have a form that can be used by {@link java.text.MessageFormat} methods.
-+   * That means:
-+   *<br><CODE>
-+   *    java.text.Message.format(fmt, args)
-+   *<br><CODE>
-+   * is similar to
-+   *<br><CODE>
-+   *    new MyException(fmt, args).getMessage();
-+   *<CODE>
-+   *
-+   * @param fmt   exception message
-+   * @param args  arguments for the given format string
-+   */
-+  /*-->
-+  public <<WHICH>>Exception(String fmt, Object[] args) {
-+    this(null, msg, args);
-+  }
-+  -->*/
-+  
-+  /**
-+   * This is the most complex way to construct an <CODE>ExceptionList</CODE>-
-+   * Exception.<br>
-+   * An inner exception is accompanied by a format string and its arguments.
-+   * Use this constructor in language-sensitive contexts or for formalized messages.
-+   * The meaning of the parameters is explained in the other constructors.
-+   *
-+   * @param ex    the inner exception
-+   * @param fmt   exception message
-+   * @param args  arguments for the given format string
-+   */
-+  /*-->
-+  public <<WHICH>>Exception(Exception ex, String fmt, Object[] args) {
-+    super(fmt);
-+   
-+    if (ex != null && fmt == null) {
-+      _isWrapper = true;
-+    } else {
-+      _isWrapper = false;
-+    }
-+    _next = ex;
-+  }
-+  -->
-+   
-+  /**
-+   * Implementation of the standard {@link java.Throwable#getMessage} method to
-+   * meet the requirements of formats and format arguments as well as wrapper
-+   * exceptions.
-+   * If this is a wrapper exception then the <CODE>getMessage</CODE> of the wrapped
-+   * exception is returned.
-+   * If no arguments were given in the constructor then the format parameter is
-+   * taken as the formatted message itself. Otherwise it is treated like the
-+   * patter for the {@link java.text.MessageFormat#format} method.
-+   *
-+   * @return  the formatted exception message
-+   * @see     java.text.MessageFormat
-+   */
-+  /*-->
-+  public String getMessage() {
-+    if (isWrapperException()) {
-+      return nextException().getMessage();
-+    } else {
-+      String fmt = super.getMessage();
-+   
-+      if (_args == null) {
-+        return fmt;
-+      } else {
-+        return MessageFormat.format(fmt, _args);
-+      }
-+    }
-+  }
-+  -->*/
-+  
-+  //---------------------------------------------------------------------------
-+  // members
-+  //
-+  /*-->
-+  protected Object[]  _args       = null;
-+  protected Exception _next       = null;
-+  protected boolean   _isWrapper  = false;
-+  -->*/
-+}
-diff --git a/susebox/java/lang/ExtIndexOutOfBoundsException.java b/susebox/java/lang/ExtIndexOutOfBoundsException.java
-new file mode 100644
-index 0000000..927daee
---- /dev/null
-+++ b/susebox/java/lang/ExtIndexOutOfBoundsException.java
-@@ -0,0 +1,200 @@
-+/*
-+ * ExtIndexOutOfBoundsException.java: Extended standard exceptio for stacks
-+ *
-+ * Copyright (C) 2001 Heiko Blau
-+ *
-+ * This file belongs to the Susebox Java Core Library (Susebox JCL).
-+ * The Susebox JCL is free software; you can redistribute it and/or modify it
-+ * under the terms of the GNU Lesser General Public License as published by the
-+ * Free Software Foundation; either version 2.1 of the License, or (at your
-+ * option) any later version.
-+ *
-+ * This software is distributed in the hope that it will be useful, but WITHOUT
-+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
-+ * FITNESS FOR A PARTICULAR PURPOSE.
-+ * See the GNU Lesser General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU Lesser General Public License along
-+ * with the Susebox JCL. If not, write to the
-+ *
-+ *   Free Software Foundation, Inc.
-+ *   59 Temple Place, Suite 330,
-+ *   Boston, MA 02111-1307
-+ *   USA
-+ *
-+ * or check the Internet: http://www.fsf.org
-+ *
-+ * Contact:
-+ *   email: heiko@susebox.de
-+ */
-+
-+package de.susebox.java.lang;
-+
-+//------------------------------------------------------------------------------
-+// Imports
-+//
-+import java.lang.IndexOutOfBoundsException;
-+import java.text.MessageFormat;
-+
-+
-+//------------------------------------------------------------------------------
-+// ExtIndexOutOfBoundsException - definition
-+//
-+
-+/**
-+ * Implementation of the ExceptionList interface for the JDK IOException.
-+ *
-+ * @version	1.00, 2001/06/26
-+ * @author 	Heiko Blau
-+ */
-+public class ExtIndexOutOfBoundsException
-+  extends     IndexOutOfBoundsException 
-+  implements  ExceptionList 
-+{
-+  
-+  //---------------------------------------------------------------------------
-+  // methods of the ExceptionList interface
-+  //
-+  
-+  /**
-+   * Method to traverse the exception list. By convention, <CODE>nextException</CODE>
-+   * returns the "earlier" exception. By walking down the exception list one gets the
-+   * the following meaning:<br>
-+   * this happened because nextException happened because nextException happened...
-+   *
-+   * @return the "earlier" exception
-+   */
-+  public Exception nextException() {
-+    return _next;
-+  }
-+  
-+  /**
-+   * Check if <CODE>this</CODE> is only a exception that wraps the real one. This
-+   * might be nessecary to pass an exception incompatible to a method declaration.
-+   *
-+   * @return <CODE>true</CODE> if this is a wrapper exception,
-+   *         <CODE>false</CODE> otherwise
-+   */
-+  public boolean isWrapperException() {
-+    return _isWrapper;
-+  }
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // constructors
-+  //
-+  
-+  /**
-+   * This constructor should be used for wrapping another exception. While reading
-+   * data an IOException may occur, but a certain interface requires a
-+   * {@link java.sql.SQLException}. Simply use:
-+   *<blockquote><pre>
-+   * try {
-+   *   ...
-+   * } catch (NullPointerException ex) {
-+   *   throw new ExtIndexOutOfBoundsException(ex);
-+   * }
-+   *</pre></blockquote>
-+   *
-+   * @param ex the exception to wrap
-+   */
-+  public ExtIndexOutOfBoundsException(Exception ex) {
-+    this(ex, null, null);
-+  }
-+  
-+  /**
-+   * If one likes to add ones own information to an exception, this constructor is
-+   * the easiest way to do so. By using such an approach a exception trace with useful
-+   * additional informations (which file could be found, what username is unknown)
-+   * can be realized:
-+   *<blockquote><pre>
-+   * try {
-+   *   ...
-+   * } catch (SQLException ex) {
-+   *   throw new IOException(ex, "while connecting to " + url);
-+   * }
-+   *</pre></blockquote>
-+   *
-+   * @param ex    the inner exception
-+   * @param msg   exception message
-+   */
-+  public ExtIndexOutOfBoundsException(Exception ex, String msg) {
-+    this(ex, msg, null);
-+  }
-+  
-+  /**
-+   * This constructor takes a format string and its arguments. The format string
-+   * must have a form that can be used by {@link java.text.MessageFormat} methods.
-+   * That means:
-+   *<blockquote><pre>
-+   *    java.text.Message.format(fmt, args)
-+   *</pre></blockquote>
-+   * is similar to
-+   *<blockquote><pre>
-+   *    new MyException(fmt, args).getMessage();
-+   *</pre></blockquote>
-+   *
-+   * @param fmt   exception message
-+   * @param args  arguments for the given format string
-+   */
-+  public ExtIndexOutOfBoundsException(String fmt, Object[] args) {
-+    this(null, fmt, args);
-+  }
-+  
-+  /**
-+   * This is the most complex way to construct an <CODE>ExceptionList</CODE>-
-+   * Exception.<br>
-+   * An inner exception is accompanied by a format string and its arguments.
-+   * Use this constructor in language-sensitive contexts or for formalized messages.
-+   * The meaning of the parameters is explained in the other constructors.
-+   *
-+   * @param ex    the inner exception
-+   * @param fmt   exception message
-+   * @param args  arguments for the given format string
-+   */
-+  public ExtIndexOutOfBoundsException(Exception ex, String msg, Object[] args) {
-+    super(msg);
-+    _next      = ex;
-+    _isWrapper = true;
-+  }
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // overridden methods
-+  //
-+  
-+  /**
-+   * Implementation of the standard {@link java.Throwable#getMessage} method to
-+   * meet the requirements of formats and format arguments as well as wrapper
-+   * exceptions.
-+   * If this is a wrapper exception then the <CODE>getMessage</CODE> of the wrapped
-+   * exception is returned.
-+   * If no arguments were given in the constructor then the format parameter is
-+   * taken as the formatted message itself. Otherwise it is treated like the
-+   * patter for the {@link java.text.MessageFormat#format} method.
-+   *
-+   * @return  the formatted exception message
-+   * @see     java.text.MessageFormat
-+   */
-+  public String getMessage() {
-+    if (isWrapperException()) {
-+      return nextException().getMessage();
-+    } else {
-+      String fmt = super.getMessage();
-+      
-+      if (_args == null) {
-+        return fmt;
-+      } else {
-+        return MessageFormat.format(fmt, _args);
-+      }
-+    }
-+  }
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // members
-+  //
-+  protected Object[]  _args       = null;
-+  protected Exception _next       = null;
-+  protected boolean   _isWrapper  = false;
-+}
-diff --git a/susebox/java/lang/ExtRuntimeException.java b/susebox/java/lang/ExtRuntimeException.java
-new file mode 100644
-index 0000000..03ee589
---- /dev/null
-+++ b/susebox/java/lang/ExtRuntimeException.java
-@@ -0,0 +1,199 @@
-+/*
-+ * ExtRuntimeException.java: Extended standard exception for stacks
-+ *
-+ * Copyright (C) 2001 Heiko Blau
-+ *
-+ * This file belongs to the Susebox Java Core Library (Susebox JCL).
-+ * The Susebox JCL is free software; you can redistribute it and/or modify it
-+ * under the terms of the GNU Lesser General Public License as published by the
-+ * Free Software Foundation; either version 2.1 of the License, or (at your
-+ * option) any later version.
-+ *
-+ * This software is distributed in the hope that it will be useful, but WITHOUT
-+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
-+ * FITNESS FOR A PARTICULAR PURPOSE.
-+ * See the GNU Lesser General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU Lesser General Public License along
-+ * with the Susebox JCL. If not, write to the
-+ *
-+ *   Free Software Foundation, Inc.
-+ *   59 Temple Place, Suite 330,
-+ *   Boston, MA 02111-1307
-+ *   USA
-+ *
-+ * or check the Internet: http://www.fsf.org
-+ *
-+ * Contact:
-+ *   email: heiko@susebox.de
-+ */
-+
-+package de.susebox.java.lang;
-+
-+//------------------------------------------------------------------------------
-+// Imports
-+//
-+import java.lang.RuntimeException;
-+import java.text.MessageFormat;
-+
-+
-+//------------------------------------------------------------------------------
-+// ExtRuntimeException - definition
-+//
-+
-+/**
-+ * Implementation of the ExceptionList interface for the JDK RuntimeException.
-+ *
-+ * @version	1.00, 2001/06/26
-+ * @author 	Heiko Blau
-+ */
-+public class ExtRuntimeException
-+  extends     RuntimeException
-+  implements  ExceptionList 
-+{
-+  //---------------------------------------------------------------------------
-+  // methods of the ExceptionList interface
-+  //
-+  
-+  /**
-+   * Method to traverse the exception list. By convention, <CODE>nextException</CODE>
-+   * returns the "earlier" exception. By walking down the exception list one gets the
-+   * the following meaning:<br>
-+   * this happened because nextException happened because nextException happened...
-+   *
-+   * @return the "earlier" exception
-+   */
-+  public Exception nextException() {
-+    return _next;
-+  }
-+  
-+  /**
-+   * Check if <CODE>this</CODE> is only a exception that wraps the real one. This
-+   * might be nessecary to pass an exception incompatible to a method declaration.
-+   *
-+   * @return <CODE>true</CODE> if this is a wrapper exception,
-+   *         <CODE>false</CODE> otherwise
-+   */
-+  public boolean isWrapperException() {
-+    return _isWrapper;
-+  }
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // constructors
-+  //
-+  
-+  /**
-+   * This constructor should be used for wrapping another exception. While reading
-+   * data an IOException may occur, but a certain interface requires a
-+   * <CODE>SQLException</CODE>. Simply use:
-+   *<blockquote><pre>
-+   * try {
-+   *   ...
-+   * } catch (NullPointerException ex) {
-+   *   throw new ExtRuntimeException(ex);
-+   * }
-+   *</pre></blockquote>
-+   *
-+   * @param ex the exception to wrap
-+   */
-+  public ExtRuntimeException(Exception ex) {
-+    this(ex, null, null);
-+  }
-+  
-+  /**
-+   * If one likes to add ones own information to an exception, this constructor is
-+   * the easiest way to do so. By using such an approach a exception trace with useful
-+   * additional informations (which file could be found, what username is unknown)
-+   * can be realized:
-+   *<blockquote><pre>
-+   * try {
-+   *   ...
-+   * } catch (SQLException ex) {
-+   *   throw new IOException(ex, "while connecting to " + url);
-+   * }
-+   *</pre></blockquote>
-+   *
-+   * @param ex    the inner exception
-+   * @param msg   exception message
-+   */
-+  public ExtRuntimeException(Exception ex, String msg) {
-+    this(ex, msg, null);
-+  }
-+  
-+  /**
-+   * This constructor takes a format string and its arguments. The format string
-+   * must have a form that can be used by {@link java.text.MessageFormat} methods.
-+   * That means:
-+   *<blockquote><pre>
-+   *    java.text.Message.format(fmt, args)
-+   *</pre></blockquote>
-+   * is similar to
-+   *<blockquote><pre>
-+   *    new MyException(fmt, args).getMessage();
-+   *</pre></blockquote>
-+   *
-+   * @param fmt   exception message
-+   * @param args  arguments for the given format string
-+   */
-+  public ExtRuntimeException(String fmt, Object[] args) {
-+    this(null, fmt, args);
-+  }
-+  
-+  /**
-+   * This is the most complex way to construct an <CODE>ExceptionList</CODE>-
-+   * Exception.<br>
-+   * An inner exception is accompanied by a format string and its arguments.
-+   * Use this constructor in language-sensitive contexts or for formalized messages.
-+   * The meaning of the parameters is explained in the other constructors.
-+   *
-+   * @param ex    the inner exception
-+   * @param fmt   exception message
-+   * @param args  arguments for the given format string
-+   */
-+  public ExtRuntimeException(Exception ex, String msg, Object[] args) {
-+    super(msg);
-+    _next      = ex;
-+    _isWrapper = true;
-+  }
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // overridden methods
-+  //
-+  
-+  /**
-+   * Implementation of the standard {@link java.Throwable#getMessage} method to
-+   * meet the requirements of formats and format arguments as well as wrapper
-+   * exceptions.
-+   * If this is a wrapper exception then the <CODE>getMessage</CODE> of the wrapped
-+   * exception is returned.
-+   * If no arguments were given in the constructor then the format parameter is
-+   * taken as the formatted message itself. Otherwise it is treated like the
-+   * patter for the {@link java.text.MessageFormat#format} method.
-+   *
-+   * @return  the formatted exception message
-+   * @see     java.text.MessageFormat
-+   */
-+  public String getMessage() {
-+    if (isWrapperException()) {
-+      return nextException().getMessage();
-+    } else {
-+      String fmt = super.getMessage();
-+      
-+      if (_args == null) {
-+        return fmt;
-+      } else {
-+        return MessageFormat.format(fmt, _args);
-+      }
-+    }
-+  }
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // members
-+  //
-+  protected Object[]  _args       = null;
-+  protected Exception _next       = null;
-+  protected boolean   _isWrapper  = false;
-+}
-diff --git a/susebox/java/util/AbstractTokenizer.java b/susebox/java/util/AbstractTokenizer.java
-new file mode 100644
-index 0000000..9de7264
---- /dev/null
-+++ b/susebox/java/util/AbstractTokenizer.java
-@@ -0,0 +1,2874 @@
-+/*
-+ * AbstractTokenizer.java: core class for lexical parser.
-+ *
-+ * Copyright (C) 2001 Heiko Blau
-+ *
-+ * This file belongs to the Susebox Java Core Library (Susebox JCL).
-+ * The Susebox JCL is free software; you can redistribute it and/or modify it 
-+ * under the terms of the GNU Lesser General Public License as published by the 
-+ * Free Software Foundation; either version 2.1 of the License, or (at your 
-+ * option) any later version.
-+ *
-+ * This software is distributed in the hope that it will be useful, but WITHOUT
-+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or 
-+ * FITNESS FOR A PARTICULAR PURPOSE. 
-+ * See the GNU Lesser General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU Lesser General Public License along
-+ * with the Susebox JCL. If not, write to the
-+ *
-+ *   Free Software Foundation, Inc.
-+ *   59 Temple Place, Suite 330, 
-+ *   Boston, MA 02111-1307 
-+ *   USA
-+ *
-+ * or check the Internet: http://www.fsf.org
-+ *
-+ * Contact:
-+ *   email: heiko@susebox.de 
-+ */
-+
-+package de.susebox.java.util;
-+
-+//-----------------------------------------------------------------------------
-+// Imports
-+//
-+import java.util.ArrayList;
-+import java.util.HashMap;
-+import java.util.Iterator;
-+
-+import de.susebox.java.lang.ExtRuntimeException;
-+import de.susebox.java.lang.ExtIndexOutOfBoundsException;
-+
-+
-+//-----------------------------------------------------------------------------
-+// Class AbstractTokenizer
-+//
-+
-+/** <p>
-+ * This is the core class for mainstream Tokenizers. It implements the {@link Tokenizer}
-+ * interface in a straightforward approach without too specialised parse
-+ * optimizations.
-+ * </p><p>
-+ * The class is abstract, so it cannot be used by itself. It defines one abstract
-+ * method, {@link #read}. This method is equivalent to the complex read methods of
-+ * the {@link java.io.InputStream} interface, which is most likely to be used for
-+ * implementing our read method.
-+ * </p><p>
-+ * Beside the {@link Tokenizer} interface, the class <CODE>AbstractTokenizer</CODE>
-+ * provides some basic features for cascading (nested) tokenizers. Conider the usual
-+ * HTML pages found today in the WWW. Most of them are a mixture of regular HTML,
-+ * cascading style sheets (CSS) and embedded JavaScript. These different languages
-+ * use different syntaxes, so one needs varous tokenizers on the same input stream.
-+ * </p><p>
-+ * There are also several methods suitable for own implementations in derived 
-+ * classes ({@link isWhitespace}, {@link isSeparator} and {@link isSequenceCommentOrString}).
-+ * Being a general approach to tokenizing, the <code>AbstractTokenizer</code> may
-+ * be not the fastest solution for ones specific situation. By implementing the
-+ * mentioned methods, one can improve the performance through exact knowledge of
-+ * what whitespaces, separators, comment starts and other special sequences are.
-+ *</p>
-+ *
-+ * @see Tokenizer
-+ * @see InputStreamTokenizer
-+ * @author Heiko Blau
-+ */
-+public abstract class AbstractTokenizer implements Tokenizer
-+{
-+  //---------------------------------------------------------------------------
-+  // Abstract methods
-+  //
-+  
-+  /**
-+   * This is the abstract method to be implemented by derived classes. It is supposed
-+   * to deliver data from some sort of input stream to the tokenizer. The simplest
-+   * implementation would use {@link java.io.InputStream#read}.
-+   *
-+   * @param cbuf      buffer to receive data
-+   * @param offset    position from where the data should be inserted in <CODE>cbuf</CODE>
-+   * @param maxChars  maximum number of characters to be read into <CODE>cbuf</CODE>
-+   * @return actually read characters or -1 on an end-of-file condition
-+   * @throws Exception anything that could happen during read, most likely {@link java.io.IOException}
-+   */
-+  protected abstract int read(char[] cbuf, int offset, int maxChars) throws Exception;
-+  
-+  
-+  /**
-+   * This method should be called by derived classes whenever the input buffer
-+   * has to be flushed. Such a situation may arise when the input source of the 
-+   * read method is changed.<br>
-+   * Position informations are reset to start. All data in the input buffer are
-+   * lost. So are the current token and any lookahead data. This is also true
-+   * for instances there the {@link Tokenizer#F_KEEP_DATA} flag is set.
-+   */
-+  protected void reset() {
-+    synchronized(this) {
-+      _currentReadPos   = 0;
-+      _currentWritePos  = 0;
-+      _rangeStart       = 0;
-+      _lineNumber       = -1;
-+      _columnNumber     = -1;
-+      _currentToken     = null;
-+      _lookAheadToken.setType(Token.UNKNOWN);
-+    }
-+  }
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // Constructors
-+  //
-+  
-+  /**
-+   * Default constructor that sets the tokenizer control flags as it would be
-+   * approbriate for C/C++ and Java. Found token images are copied. No line nor
-+   * column informations are provided. Nested comments are not allowed.
-+   *<br>
-+   * The tokenizer will use the {@link Tokenizer#DEFAULT_WHITESPACES} and 
-+   * {@link Tokenizer#DEFAULT_SEPARATORS} for whitespace and separator handling.
-+   */  
-+  public AbstractTokenizer() {
-+    this(0);
-+  }
-+
-+  /**
-+   * This constructor takes the control flags to be used. It is a shortcut to:
-+   * <pre>
-+   *   Tokenizer t = new MyTokenizer();
-+   *
-+   *   t.setParseFlags(flags);
-+   * </pre>
-+   * See the {@link Tokenizer} interface for the supported flags.
-+   *<br>
-+   * The tokenizer will use the {@link Tokenizer#DEFAULT_WHITESPACES} and 
-+   * {@link Tokenizer#DEFAULT_SEPARATORS} for whitespace and separator handling
-+   * if no explicit calls to {@link #setWhitespaces} and {@link #setSeparators}
-+   * are made.
-+   *
-+   * @param flags tokenizer control flags
-+   */  
-+  public AbstractTokenizer(int flags) {
-+    this(flags, Tokenizer.DEFAULT_WHITESPACES, Tokenizer.DEFAULT_SEPARATORS);
-+  }
-+  
-+  
-+  /**
-+   * This constructor takes the control flags, whitespace and separator strings
-+   * to be used. It is a shortcut to:
-+   * <pre>
-+   *   Tokenizer t = new MyTokenizer();
-+   *
-+   *   t.setParseFlags(flags);
-+   *   t.setWhitespaces(ws);
-+   *   t.setSeparators(sep);
-+   * </pre>
-+   *
-+   * @param flags       tokenizer control flags
-+   * @param whitespaces the whitespace set
-+   * @param separators  the set of separating characters
-+   * @see   #setWhitespaces
-+   * @see   #setSeparators
-+   */  
-+  public AbstractTokenizer(int flags, String whitespaces, String separators) {
-+    setParseFlags(flags);
-+    setWhitespaces(whitespaces);
-+    setSeparators(separators);
-+
-+    if ((_flags & Tokenizer.F_KEEP_DATA) != 0) {
-+      _inputBuffer = new char[0x10000];   // 64k
-+    } else {
-+      _inputBuffer = new char[0x2000];    // 8k
-+    }
-+  }
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // Methods of the Tokenizer interface
-+  //
-+  
-+  /**
-+   * Setting the control flags of the <code>Tokenizer</code>. Use a combination
-+   * of the <code>Tokenizer.F_...</code> flags for the parameter.
-+   *
-+   * @param flags the parser control flags
-+   */
-+  public void setParseFlags(int flags) {
-+    _flags = flags;
-+    
-+    // we would like to test flags on F_KEYWORDS_CASE
-+    if ((_flags & (Tokenizer.F_KEYWORDS_NO_CASE | Tokenizer.F_NO_CASE)) == 0) {
-+      _flags |= Tokenizer.F_KEYWORDS_CASE;
-+    } else if ((_flags & Tokenizer.F_KEYWORDS_CASE) != 0) {
-+      _flags &= ~Tokenizer.F_KEYWORDS_NO_CASE;
-+    }
-+    
-+    // when counting lines initialize the current line and column position
-+    if ((_flags & Tokenizer.F_COUNT_LINES) != 0) {
-+      _lineNumber   = 0;
-+      _columnNumber = 0;
-+    }
-+  }
-+
-+   /**
-+    * Retrieving the parser control flags. A bitmask containing the <code>F_...</code>
-+    * constants is returned.
-+    * @return the current parser control flags
-+    * @see #setParseFlags
-+    */
-+  public int getParseFlags() {
-+    return _flags;
-+  }
-+  
-+  /**
-+   * Registering a string description. Strings are things like the primitive string 
-+   * literals in C/C++, SQL varchar literals, but also the character literals 
-+   * of C/C++ and Java.<br>
-+   * If the given string starting sequence is already known to the parser,
-+   * it will simply be re-registered. Using this method on a known string
-+   * with an associated companion will remove that companion.
-+   *
-+   * @param start     the starting sequence of a string
-+   * @param end       the finishing sequence of a string
-+   * @param escape    the escape sequence inside the string
-+   */
-+  public void addString(String start, String end, String escape) {
-+    addString(start, end, escape, null);
-+  }
-+
-+  /**
-+   * Registering a the sequences that are used for string-like text parts.
-+   * This method supports also an information associated with the string,
-+   * called the companion.<br>
-+   * If the given string starting sequence is already known to the parser,
-+   * it will simply be re-registered. Using this method on a known string
-+   * with an associated companion will replace that companion against the given
-+   * one.
-+   *
-+   * @param start     the starting sequence of a string
-+   * @param end       the finishing sequence of a string
-+   * @param escape    the escape sequence inside the string
-+   * @param companion the associated information
-+   */
-+  public void addString(
-+    String start, 
-+    String end, 
-+    String escape, 
-+    Object companion
-+  )
-+  {
-+    addString(start, end, escape, companion, getParseFlags());
-+  }
-+  
-+  
-+  /**
-+   * Registering a the sequences that are used for string-like text parts.
-+   * This method supports also an information associated with the string,
-+   * called the companion.<br>
-+   * If the given string starting sequence is already known to the parser,
-+   * it will simply be re-registered. Using this method on a known string
-+   * with an associated companion will replace that companion against the given
-+   * one.
-+   * This version of <code>addString</code> supports a bitmask of the 
-+   * <code>F_...</code> flags to modify the general tokenizer settings (see
-+   * {@link #setParseFlags} for this special element.
-+   *
-+   * @param start     the starting sequence of a string
-+   * @param end       the finishing sequence of a string
-+   * @param escape    the escape sequence inside the string
-+   * @param companion the associated information
-+   * @param flags     modification flags 
-+   */
-+  public void addString(
-+    String start, 
-+    String end, 
-+    String escape, 
-+    Object companion, 
-+    int    flags
-+  )
-+  {
-+    addSpecialSequence(
-+      new TokenizerProperty(Token.STRING, new String[] { start, end, escape }, 
-+                            companion, flags)
-+    );
-+  }
-+  
-+  /**
-+   * Removing a string description.
-+   *
-+   * @param start     the starting sequence of a string
-+   */  
-+  public void removeString(String start) {
-+    removeSpecialSequence(start);
-+  }
-+  
-+    
-+  /**
-+   * Retrieving the information associated with a certain string. Only the 
-+   * starting sequence is nessecary to identify the string. If the string is not 
-+   * known to the parser, <CODE>null</CODE> will be returned.<br>
-+   * If one needs to know if a string exists without a companion or if the string
-+   * is unknown so far, use also the method {@link #stringExists}.
-+   *
-+   * @param start     the starting sequence of a string
-+   * @return the associated information or <CODE>null</CODE>
-+   */
-+  public Object getStringCompanion(String start) {
-+    return getSpecialSequenceCompanion(start);
-+  }
-+  
-+
-+  /**
-+   * Checks if the given starting sequence of the string is known to the parser.
-+   *
-+   * @param start     the starting sequence of a string
-+   * @return <CODE>true</CODE> if the string is registered, 
-+   *         <CODE>false</CODE> otherwise
-+   */
-+  public boolean stringExists(String start) {
-+    return specialSequenceExists(start);
-+  }
-+
-+  
-+  /**
-+   * This method returns an {@link java.util.Iterator} of {@link TokenizerProperty}
-+   * objects. Each <CODE>TokenizerProperty</CODE> object contains the starting,
-+   * finishing and escaping sequence of a string description and the companion if 
-+   * it exists.
-+   *
-+   * @return enumeration of {@link TokenizerProperty} objects
-+   */  
-+  public Iterator getStrings() {
-+    return new SpecialSequencesIterator(this, Token.STRING);
-+  }
-+  
-+  /**
-+   * Setting the whitespace character set of the tokenizer. It is possible to
-+   * use ranges like "a-z" when more than two whitespace characters are
-+   * neighbours in the UNICODE character set.<br>
-+   * Whitespaces are sequences that have the same syntactical meaning as one
-+   * single whitespace character would have. That means "     " (many spaces) is
-+   * the same as " " (one space).
-+   *
-+   * @param whitespaces the whitespace set
-+   */
-+  public void setWhitespaces(String whitespaces) {
-+    // set whitespaces and detect if end-of-line characters are part of them
-+    _whitespaces = (whitespaces != null) ? whitespaces : "";
-+    if (_whitespaces.indexOf('\n') >= 0 || _whitespaces.indexOf('\r') >= 0) {
-+      _newlineIsWhitespace = true;
-+    }
-+    
-+    // for fast whitespace scanning check for the most common ones
-+    if (   _whitespaces.equals(Tokenizer.DEFAULT_WHITESPACES)
-+        || (   _whitespaces.length()      == 4
-+            && _whitespaces.indexOf('\n') >= 0 
-+            && _whitespaces.indexOf('\r') >= 0
-+            && _whitespaces.indexOf(' ')  >= 0
-+            && _whitespaces.indexOf('\t') >= 0)) {
-+      _defaultWhitespaces = true;
-+    }
-+  }
-+  
-+  /**
-+   * Obtaining the whitespace character set. The set may contain ranges.
-+   *
-+   * @see #setWhitespaces
-+   * @return the currently active whitespace set
-+   */
-+  public String getWhitespaces() {
-+    return _whitespaces;
-+  }
-+  
-+  /**
-+   * Setting the separator set. This set may contain ranges. A range is a
-+   * character (lower limit) followed by a '-' (minus) followed by a
-+   * second character (upper limit). A range of "a-z" means: all characters in
-+   * the UNICODE character set between and including 'a' and 'z'. Ranges should
-+   * be used whenever possible since they speed up the parsing process.<br>
-+   * Separators are characters that are significant for the syntax. A sequence
-+   * of separators is <i>NOT</i> equal to one single separator. Thats the
-+   * difference to whitespaces.
-+   *
-+   * @param separators the set of separating characters
-+   */
-+  public void setSeparators(String separators) {
-+    _separators = (separators != null) ? separators : "";
-+  }
-+  
-+  /**
-+   * Obtaining the separator set of the <code>Tokenizer</code>. The set may
-+   * contain ranges.
-+   *
-+   * @see #setSeparators
-+   * @return the currently used set of separating characters
-+   */
-+  public String getSeparators() {
-+    return _separators;
-+  }
-+  
-+  /**
-+   * Registering a the starting sequence of a line comment. The line comment is
-+   * a special type of whitespace. It starts with the given character sequence
-+   * and contains all characters up to and including the next end-of-line
-+   * character(s).<br>
-+   * Although most languages have only one line comment sequence, it is possible
-+   * to use more than one.<br>
-+   * If the given line comment starting sequence is already known to the parser,
-+   * it will simply be re-registered. Using this method on a known line comment
-+   * with an associated companion will effectively remove the companion.
-+   *
-+   * @param lineComment the starting sequence of the line comment
-+   */
-+  public void addLineComment(String lineComment) {
-+    addLineComment(lineComment, null);
-+  }
-+
-+  /**
-+   * Registering a the starting sequence of a line comment. The line comment is
-+   * a special type of whitespace. It starts with the given character sequence
-+   * and contains all characters up to and including the next end-of-line
-+   * character(s).<br>
-+   * Although most languages have only one line comment sequence, it is possible
-+   * to use more than one.<br>
-+   * This method supports also an information associated with the line comment,
-+   * called the companion.<br>
-+   * If the given line comment starting sequence is already known to the parser,
-+   * it will simply be re-registered. Using this method on a known line comment
-+   * with an associated companion will replace that companion against the given
-+   * one.
-+   *
-+   * @param lineComment the starting sequence of a line comment
-+   * @param companion the associated information
-+   */
-+  public void addLineComment(String lineComment, Object companion) {
-+    addLineComment(lineComment, companion, getParseFlags());
-+  }
-+
-+  
-+  /**
-+   * Registering a the starting sequence of a line comment. The line comment is
-+   * a special type of whitespace. It starts with the given character sequence
-+   * and contains all characters up to and including the next end-of-line
-+   * character(s).<br>
-+   * Although most languages have only one line comment sequence, it is possible
-+   * to use more than one.<br>
-+   * This method supports also an information associated with the line comment,
-+   * called the companion.<br>
-+   * If the given line comment starting sequence is already known to the parser,
-+   * it will simply be re-registered. Using this method on a known line comment
-+   * with an associated companion will replace that companion against the given
-+   * one.<br>
-+   * This version of <code>addLineComment</code> supports a bitmask of the
-+   * <code>F_...</code> flags to modify the general tokenizer settings (see
-+   * {@link #setParseFlags}) for this special element.
-+   *
-+   * @param lineComment the starting sequence of a line comment
-+   * @param companion the associated information
-+   * @param flags     modification flags
-+   */
-+  public void addLineComment(String lineComment, Object companion, int flags) {
-+    addSpecialSequence(
-+      new TokenizerProperty(Token.LINE_COMMENT, new String[] { lineComment }, 
-+                            companion, flags)
-+    );
-+  }  
-+
-+  /**
-+   * Removing a certain line comment.
-+   *
-+   * @param lineComment the starting sequence of the line comment
-+   */  
-+  public void removeLineComment(String lineComment) {
-+    removeSpecialSequence(lineComment);
-+  }
-+  
-+  
-+  /**
-+   * Retrieving the associated object of a certain line comment. If the given
-+   * starting sequence of a line comment is not known to the parser, then the
-+   * method returns <CODE>null</CODE>.<br>
-+   * To distinguish between an unknown line comment and companion-less line
-+   * comment, use the method {@link #lineCommentExists}.
-+   *
-+   * @param lineComment the starting sequence of the line comment
-+   * @return the object associated with the line comment
-+   */  
-+  public Object getLineCommentCompanion(String lineComment) {
-+    return getSpecialSequenceCompanion(lineComment);
-+  }
-+
-+  /**
-+   * Checks if the give line comment is known.
-+   *
-+   * @param lineComment the starting sequence of the line comment
-+   * @return <CODE>true</CODE> if the line comment is known, 
-+   *         <CODE>false</CODE> otherwise
-+   */  
-+  public boolean lineCommentExists(String lineComment) {
-+    return specialSequenceExists(lineComment);
-+  }
-+  
-+  /**
-+   * This method returns an {@link java.util.Iterator} of {@link TokenizerProperty}
-+   * objects. Each <CODE>TokenizerProperty</CODE> object contains one starting
-+   * sequence of a line comment and the companion if it exists.
-+   *
-+   * @return enumeration of {@link TokenizerProperty} objects
-+   */  
-+  public Iterator getLineComments() {
-+    return new SpecialSequencesIterator(this, Token.LINE_COMMENT);
-+  }
-+  
-+  /**
-+   * Registering a block comment with the parser. This version takes only the starting
-+   * and finishing sequence of the block comment.<br>
-+   * If the given starting sequence is already known to the parser, the block 
-+   * comment is simply re-registered. Using this method on a known block comment
-+   * with an associated companion will remove that companion.
-+   *
-+   * @param start the starting sequence of the block comment
-+   * @param end the finishing sequence of the block comment
-+   */  
-+  public void addBlockComment(String start, String end) {
-+    addBlockComment(start, end, null);
-+  }
-+  
-+  /**
-+   * Registering a block comment with the parser. Beside the obviously nessecary
-+   * starting and finishing sequence of the block comment, it takes an object that
-+   * is associated with the block comment, called the companion.<br>
-+   * If the given starting sequence is already known to the parser, the block
-+   * comment is simply re-registered. Using this method on a known block comment
-+   * with an associated companion will replace that companion against the given
-+   * one.
-+   *
-+   * @param start the starting sequence of the block comment
-+   * @param end the finishing sequence of the block comment
-+   * @param companion information object associated with this block comment
-+   */  
-+  public void addBlockComment(String start, String end, Object companion) {
-+    addBlockComment(start, end, companion, getParseFlags());
-+  }
-+  
-+  /**
-+   * Registering a block comment with the parser. Beside the obviously nessecary
-+   * starting and finishing sequence of the block comment, it takes an object that
-+   * is associated with the block comment, called the companion.<br>
-+   * If the given starting sequence is already known to the parser, the block
-+   * comment is simply re-registered. Using this method on a known block comment
-+   * with an associated companion will replace that companion against the given
-+   * one.<br>
-+   * This version of <code>addBlockComment</code> supports a bitmask of the 
-+   * <code>F_...</code> flags to modify the general tokenizer settings (see
-+   * {@link #setParseFlags}) for this special element.
-+   *
-+   * @param start     the starting sequence of the block comment
-+   * @param end       the finishing sequence of the block comment
-+   * @param companion information object associated with this block comment
-+   * @param flags     modification flags 
-+   */
-+  public void addBlockComment(String start, String end, Object companion, int flags) {
-+    addSpecialSequence(
-+      new TokenizerProperty(Token.BLOCK_COMMENT, new String[] { start, end }, 
-+                            companion, flags)
-+    );
-+  }
-+  
-+  /**
-+   * Removing a certain block comment. Only the starting sequence is nessecary
-+   * to identify the block comment.
-+   *
-+   * @param start the starting sequence of the block comment
-+   */  
-+  public void removeBlockComment(String start) {
-+    removeSpecialSequence(start);
-+  }
-+  
-+  /**
-+   * Retrieving a certain block comment. Only the starting sequence is nessecary
-+   * to identify the block comment. If the block comment is not known to the 
-+   * parser, then <CODE>null</CODE> is returned.<br>
-+   * To distinguish between an unknown line comment and companion-less line 
-+   * comment, use the method {@link #lineCommentExists}.
-+   *
-+   * @param start the starting sequence of the block comment
-+   * @return the associated object of the block comment
-+   */  
-+  public Object getBlockCommentCompanion(String start) {
-+    return getSpecialSequenceCompanion(start);
-+  }
-+  
-+  
-+  /**
-+   * Checks if the given block comment is known. Only the starting sequence is 
-+   * nessecary to identify the block comment.
-+   *
-+   * @param start the starting sequence of the block comment
-+   * @return <CODE>true</CODE> if the block comment is known, 
-+   *         <CODE>false</CODE> otherwise
-+   */  
-+  public boolean blockCommentExists(String start) {
-+    return specialSequenceExists(start);
-+  }
-+  
-+  
-+  /**
-+   * This method returns an {@link java.util.Iterator} of {@link TokenizerProperty}
-+   * objects. Each <CODE>TokenizerProperty</CODE> object contains the starting and
-+   * finishing sequence of a block comment and the companion if it exists.
-+   *
-+   * @return enumeration of {@link TokenizerProperty} objects
-+   */  
-+  public Iterator getBlockComments() {
-+    return new SpecialSequencesIterator(this, Token.BLOCK_COMMENT);
-+  }
-+  
-+  
-+  /**
-+   * Query the current row. The method can only be used if the flag <CODE>F_COUNT_LINES</CODE>
-+   * has been set.
-+   * Without this flag being set, the return value is undefined.
-+   * Note that row counting starts with 0, while editors often use 1 for the first
-+   * row.
-+   *
-+   * @return current row (starting with 0) 
-+   *         or -1 if the flag {@link Tokenizer#F_COUNT_LINES} is set
-+   */
-+  public int getCurrentLine() {
-+    return _lineNumber;
-+  }
-+  
-+  
-+  /**
-+   * Retrieve the current column. The method can only be used if the flag <CODE>F_COUNT_LINES</CODE>
-+   * has been set.
-+   * Without this flag being set, the return value is undefined.
-+   * Note that column counting starts with 0, while editors often use 1 for the first
-+   * column in one row.
-+   *
-+   * @return current column number (starting with 0)
-+   */
-+  public int getCurrentColumn() {
-+    return _columnNumber;
-+  }
-+  
-+
-+  /**
-+   * Registering a special sequence of characters. Such sequences may be multicharacter
-+   * operators like the shift operators in Java.
-+   * Unlike keywords, special sequences act also as separators between other tokens.
-+   * If one special sequence is the prefix of other special sequences (in Java the
-+   * shift operator <CODE>&gt;&gt;</CODE> is the prefix of the shift operator
-+   * <CODE>&gt;&gt;&gt;</CODE>), always the longest possible match is returned.
-+   * Testing on special sequences takes place after whitespaces and comments are ruled
-+   * out, but before ordinary separators are tested.
-+   *
-+   * @param specSeq   special sequence to register
-+   * @see   #addKeyword
-+   * @see   #setSeparators
-+   */
-+  public void addSpecialSequence(String specSeq) {
-+    addSpecialSequence(specSeq, null);
-+  }
-+  
-+  
-+  /**
-+   * Registering a special sequence of characters. Such sequences may be multicharacter
-+   * operators like the shift operators in Java.
-+   * Unlike keywords, special sequences act also as separators between other tokens.
-+   * If one special sequence is the prefix of other special sequences (in Java the
-+   * shift operator <CODE>&gt;&gt;</CODE> is the prefix of the shift operator
-+   * <CODE>&gt;&gt;&gt;</CODE>), always the longest possible match is returned.
-+   * Testing on special sequences takes place after whitespaces and comments are ruled
-+   * out, but before ordinary separators are tested.
-+   * This form of <CODE>addSpecialSequence</CODE> also takes an object associated with
-+   * the special sequence, called the companion.
-+   *
-+   * @param specSeq     special sequence to register
-+   * @param companion information object associated with this special sequence
-+   * @see #addKeyword
-+   * @see #setSeparators
-+   */  
-+  public void addSpecialSequence(String specSeq, Object companion) {
-+    addSpecialSequence(specSeq, companion, getParseFlags());
-+  }
-+
-+  
-+  /**
-+   * Registering a special sequence of characters. Such sequences may be multicharacter
-+   * operators like the shift operators in Java.
-+   * Unlike keywords, special sequences act also as separators between other tokens.
-+   * If one special sequence is the prefix of other special sequences (in Java the
-+   * shift operator <CODE>&gt;&gt;</CODE> is the prefix of the shift operator
-+   * <CODE>&gt;&gt;&gt;</CODE>), always the longest possible match is returned.
-+   * Testing on special sequences takes place after whitespaces and comments are ruled
-+   * out, but before ordinary separators are tested.
-+   * This form of <CODE>addSpecialSequence</CODE> also takes an object associated with
-+   * the special sequence, called the companion.
-+   * This version of <code>addSpecialSequence</code> supports a bitmask of the
-+   * <code>F_...</code> flags to modify the general tokenizer settings (see
-+   * {@link #setParseFlags} for this special element.
-+   *
-+   * @param specSeq     special sequence to register
-+   * @param companion   information object associated with this special sequence
-+   * @param flags       modification flags
-+   * @see #addKeyword
-+   * @see #setSeparators
-+   */
-+  public void addSpecialSequence(String specSeq, Object companion, int flags) {
-+    addSpecialSequence(
-+      new TokenizerProperty(Token.SPECIAL_SEQUENCE, new String[] { specSeq }, 
-+                            companion, flags)
-+    );
-+  }  
-+    
-+
-+  /**
-+   * Deregistering a special sequence from the parser.
-+   *
-+   * @param specSeq   sequence to remove
-+   */  
-+  public void removeSpecialSequence(String specSeq) {
-+    if (specSeq != null) {
-+      try {
-+        for (int pos = 0; pos < _sequences.length; ++pos) {
-+          if (_sequences[pos] != null) {
-+            _sequences[pos].searchBinary(specSeq, 0, true);
-+          }
-+        }
-+      } catch (TokenizerException ex) {
-+        // this shouldn't happen at all since we do not read from the input stream
-+        throw new ExtRuntimeException(
-+                    ex,
-+                    "While trying to remove special sequence \"{0}\".", 
-+                    new Object[] { specSeq }
-+                  );
-+      }
-+    }
-+  }
-+  
-+  
-+  /**
-+   * Retrieving the companion of the given special sequence. If the special
-+   * sequence doesn't exist the method returns <CODE>null</CODE>.
-+   *
-+   * @param specSeq   sequence to remove
-+   * @return the object associated with the special sequence
-+   */
-+  public Object getSpecialSequenceCompanion(String specSeq) {
-+    if (specSeq != null) {
-+      TokenizerProperty prop = searchBinary(specSeq);
-+
-+      if (prop != null) {
-+        return prop.getCompanion();
-+      }
-+    }
-+    
-+    // no special sequences at all or not found
-+    return null;
-+  }
-+  
-+
-+  /**
-+   * This method returns an {@link java.util.Iterator} of {@link TokenizerProperty}
-+   * objects. Each <CODE>TokenizerProperty</CODE> object contains a special
-+   * sequence and the companion if it exists.
-+   *
-+   * @return enumeration of {@link TokenizerProperty} objects
-+   */  
-+  public Iterator getSpecialSequences() {
-+    return new SpecialSequencesIterator(this, Token.SPECIAL_SEQUENCE);
-+  }
-+  
-+  
-+  /**
-+   * Checks if the given special sequence is known to the <CODE>Tokenizer</CODE>.
-+   *
-+   * @param specSeq sequence to check
-+   * @return <CODE>true</CODE> if the block comment is known,
-+   *       <CODE>false</CODE> otherwise
-+   */  
-+  public boolean specialSequenceExists(String specSeq) {
-+    if (specSeq != null && searchBinary(specSeq) != null) {
-+      return true;
-+    } else {
-+      return false;
-+    }
-+  }
-+  
-+  
-+  /**
-+   * Registering a keyword. If the keyword is already known to the <CODE>Tokenizer</CODE>
-+   * then it is simply re-registered. If the known keyword has an associated 
-+   * companion it will be removed.
-+   *
-+   * @param keyword   keyword to register
-+   */
-+  public void addKeyword(String keyword) {
-+    addKeyword(keyword, null);
-+  }
-+  
-+  
-+  /**
-+   * Registering a keyword. If the keyword is already known to the <CODE>Tokenizer</CODE>
-+   * then it is simply re-registered. If the known keyword has an associated
-+   * companion it will be replaced against the given one.
-+   *
-+   * @param keyword   keyword to register
-+   * @param companion information object associated with this keyword
-+   */  
-+  public void addKeyword(String keyword, Object companion) {
-+    addKeyword(keyword, companion, getParseFlags());
-+  }
-+  
-+  
-+  /**
-+   * Registering a keyword. If the keyword is already known to the <CODE>Tokenizer</CODE>
-+   * then it is simply re-registered. If the known keyword has an associated
-+   * companion it will be replaced against the given one.<br>
-+   * This version of <code>addKeyword</code> supports a bitmask of the 
-+   * <code>F_...</code> flags to modify the general tokenizer settings (see
-+   * {@link #setParseFlags}) for this special element.
-+   *
-+   * @param keyword   keyword to register
-+   * @param companion information object associated with this keyword
-+   */  
-+  public void addKeyword(String keyword, Object companion, int flags) {
-+    // normalize flags
-+    int commonFlags = getParseFlags();
-+    
-+    if (flags != commonFlags) {
-+      if ((commonFlags & F_KEYWORDS_CASE) == 0) {
-+        if ((flags & F_KEYWORDS_CASE) != 0) {
-+          flags |= F_KEYWORDS_CASE;
-+        }
-+      } else {
-+        if ((flags & (F_KEYWORDS_NO_CASE | F_NO_CASE)) != 0) {
-+          flags &= ~F_KEYWORDS_CASE;
-+        }
-+      }
-+    }
-+    
-+    // there is a HashMap for case-sensitive and one for non case-sensitive
-+    // keywords
-+    // case-insensitive comparison must be done by comparing normalized strings
-+    // we choose the upper case (lower case would be fine as well)
-+    HashMap table;
-+
-+    if ((flags & Tokenizer.F_KEYWORDS_CASE) != 0) {
-+      if (_keywords[0] == null) {
-+        _keywords[0] = new HashMap();
-+      }
-+      table = _keywords[0];
-+    } else {
-+      if (_keywords[1] == null) {
-+        _keywords[1] = new HashMap();
-+      }
-+      table   = _keywords[1];
-+      keyword = keyword.toUpperCase();
-+    }
-+    
-+    // put keyword and its property
-+    table.put(keyword, new TokenizerProperty(Token.KEYWORD, 
-+                                             new String[] { keyword }, 
-+                                             companion, flags));
-+  }
-+  
-+  
-+  /**
-+   * Deregistering a special sequence from the parser. If the keyword is not known
-+   * then the method does nothing.
-+   *
-+   * @param keyword   keyword to remove
-+   */  
-+  public void removeKeyword(String keyword) {
-+    if (keyword != null) {
-+      for (int pos = 0; pos < _keywords.length; ++pos) {
-+        if (_keywords[pos] != null) {
-+          _keywords[pos].remove(keyword);
-+        }
-+      }
-+    }
-+  }
-+  
-+  
-+  /**
-+   * Retrieving the companion of the given special sequence. If the special
-+   * sequence doesn't exist the method returns <CODE>null</CODE>.
-+   *
-+   * @param keyword   keyword thats companion is sought
-+   * @return the object associated with the keyword
-+   */
-+  public Object getKeywordCompanion(String keyword) {
-+    // case-sensitive keywords are prior to case-insensitive ones
-+    if (keyword != null) {
-+      for (int pos = 0; pos < _keywords.length; ++pos) {
-+        if (_keywords[pos] != null) {
-+          TokenizerProperty prop = (TokenizerProperty)_keywords[pos].get(keyword);
-+          
-+          if (prop != null) {
-+            return prop.getCompanion();
-+          }
-+        }
-+      }
-+    }
-+    
-+    // no keyword given, no keywords known, not found
-+    return null;
-+  }
-+
-+  
-+  /**
-+   * This method returns an {@link java.util.Iterator} of {@link TokenizerProperty}
-+   * objects. Each <CODE>TokenizerProperty</CODE> object contains a keyword and 
-+   * the companion if it exists.
-+   *
-+   * @return iteration of {@link TokenizerProperty} objects
-+   */  
-+  public Iterator getKeywords() {
-+    return new KeywordIterator(this);
-+  }
-+  
-+  
-+  /**
-+   * Checks if the given keyword is known to the <CODE>Tokenizer</CODE>.
-+   *
-+   * @param keyword   keyword to search
-+   * @return <CODE>true</CODE> if the keyword is known,
-+   *        <CODE>false</CODE> otherwise
-+   */  
-+  public boolean keywordExists(String keyword) {
-+    if (keyword != null) {
-+      if (   (_keywords[0] != null && _keywords[0].containsKey(keyword)) 
-+          || (_keywords[1] != null && _keywords[1].containsKey(keyword.toUpperCase()))) {
-+        return true;
-+      }
-+    }
-+    return false;
-+  }
-+  
-+  
-+  /**
-+   * Checking if there are more tokens available. This method will return
-+   * <code>true</code> until and enf-of-file condition is encountered during a 
-+   * call to {@link #nextToken} or {@link #next}.<br>
-+   * That means, that the EOF is returned one time, afterwards <code>hasMoreToken</code>
-+   * will return <code>false</code>. Furthermore, that implies, that the method
-+   * will return <code>true</code> at least once, even if the input data stream
-+   * is empty.<br>
-+   * The method can be conveniently used in a while loop.
-+   *
-+   * @return  <code>true</code> if a call to {@link #nextToken} or {@link #next}
-+   *          will succed, <code>false</code> otherwise
-+   */
-+  public boolean hasMoreToken() {
-+    return _currentToken == null || _currentToken.getType() != Token.EOF;
-+  }
-+  
-+  
-+  /**
-+   * Retrieving the next {@link Token}. The method works in this order:<br>
-+   *<ol><li>
-+   *   Check for an end-of-file condition. If there is such a condition then
-+   *   return it.
-+   *</li><li>
-+   *   Try to collect a sequence of whitespaces. If such a sequence can be found
-+   *   return if the flag <CODE>F_RETURN_WHITESPACES</CODE> is set, or skip these
-+   *   whitespaces.
-+   *</li><li>
-+   *   Check the next characters against all known line and block comments. If
-+   *   a line or block comment starting sequence matches, return if the flag
-+   *   <CODE>F_RETURN_WHITESPACES</CODE> is set, or skip the comment.
-+   *   If comments are returned they include their starting and ending sequences
-+   *   (newline in the case of a line comment)
-+   *</li><li>
-+   *   Check the next characters against all known string starting sequences. If
-+   *   a string begin could be identified return the string until and including
-+   *   the closing sequence
-+   *</li><li>
-+   *   Check the next characters against all known special sequences. Especially,
-+   *   find the longest possible match. If a special sequence could be identified
-+   *   then return it.
-+   *</li><li>
-+   *   Check for ordinary separators. If one could be found return it.
-+   *</li><li>
-+   *   Check the next characters against all known keywords. If a keyword could
-+   *   be identified then return it.
-+   *</li><li>
-+   *   Return the text portion until the next whitespace, comment, special
-+   *   sequence or separator.
-+   *</li></ol>
-+   *
-+   * @return found {@link Token} including the EOF token
-+   * @throws TokenizerException generic exception (list) for all problems that may occur while parsing
-+   * (IOExceptions for instance)
-+   */
-+  public Token nextToken() throws TokenizerException {
-+    Token token = new Token();
-+    
-+    // there are a lot of read operations, adjustment of members etc. So it
-+    // might be a good idea to synchronize this core operation of the class
-+    synchronized(this) {
-+      
-+__MAIN_LOOP__:
-+      do {
-+        // we know the starting positions
-+        token.setStartPosition(getReadPosition());
-+        token.setStartLine(_lineNumber);
-+        token.setStartColumn(_columnNumber);
-+
-+        // no lookahead available
-+        switch (_lookAheadToken.getType()) {
-+        case Token.UNKNOWN:
-+          token.setToken(null);
-+        
-+          // take care to use the right order to test for different token types
-+          if ( ! test4Whitespace(token)) {
-+            if ( ! test4SpecialSequence(token)) {
-+              if ( ! test4Separator(token)) {
-+                if ( ! test4Normal(token)) {
-+                  token.setType(Token.EOF);
-+                }
-+              }
-+            }
-+          }
-+          break;
-+          
-+        case Token.LINE_COMMENT:
-+        case Token.BLOCK_COMMENT:
-+        case Token.STRING:
-+        case Token.SPECIAL_SEQUENCE:
-+          completeSpecialSequence(token);
-+          _lookAheadToken.setType(Token.UNKNOWN);
-+          break;
-+        case Token.SEPARATOR:
-+          completeSeparator(token);
-+          _lookAheadToken.setType(Token.UNKNOWN);
-+          break;
-+        default:
-+          completeWhitespace(token);
-+          _lookAheadToken.setType(Token.UNKNOWN);
-+        }
-+
-+        // more actions depending on the token
-+        switch (token.getType()) {
-+        case Token.WHITESPACE:
-+        case Token.LINE_COMMENT:
-+        case Token.BLOCK_COMMENT:
-+          if ((_flags & Tokenizer.F_RETURN_WHITESPACES) == 0) {
-+            token.setType(Token.UNKNOWN);   // see loop control (while)
-+            break;
-+          }
-+          /* no break; */
-+        default:
-+          if ((_flags & Tokenizer.F_TOKEN_POS_ONLY) == 0) {    
-+            token.setToken(new String(_inputBuffer, _currentReadPos, token.getLength()));
-+          }
-+        }
-+        
-+        // compute new line and column positions (if flag is set) and complete
-+        // the token
-+        adjustLineAndColumn(token.getType(), token.getLength());
-+        token.setEndLine(_lineNumber);
-+        token.setEndColumn(_columnNumber);
-+
-+        // this is the one and only point where the current read position is
-+        // adjusted (except for the data shifting in readMoreData).
-+        _currentReadPos += token.getLength();
-+        
-+      } while (token.getType() == Token.UNKNOWN);
-+      
-+      // store the retrieved token
-+      _currentToken = token;
-+    }
-+    return token;
-+  }
-+  
-+ 
-+  /**
-+   * This method is a convenience method. It returns only the next token image
-+   * without any informations about its type or associated information.
-+   *
-+   * @return the token image of the next token
-+   * @throws TokenizerException generic exception (list) for all problems that may occur while parsing
-+   * (IOExceptions for instance)
-+   */
-+  public String next() throws TokenizerException {
-+    nextToken();
-+    return current();
-+  }
-+ 
-+  
-+  /**
-+   * Retrieve the {@link Token} that was found by the last call to {@link #nextToken}.
-+   * @return the token that was found by the last call to <CODE>nextToken</CODE>
-+   * or <CODE>next</CODE>
-+   */
-+  public Token currentToken() {
-+    return _currentToken;
-+  }
-+  
-+ 
-+  /**
-+   * Convenience method to retrieve only the token image of the {@link Token} that
-+   * would be returned by {@link #currentToken}.
-+   *
-+   * @return the token image of the current token
-+   * @see #currentToken
-+   */
-+  public String current() {
-+    Token token = currentToken();
-+    
-+    if ((_flags & Tokenizer.F_TOKEN_POS_ONLY) == 0 || token.getToken() != null) {
-+      return token.getToken();
-+    } else {
-+      return getText(token.getStartPosition(), token.getLength());
-+    }
-+  }
-+
-+  
-+  /**
-+   * If the flag {@link Tokenizer#F_COUNT_LINES} is set, this method will return the
-+   * line number starting with 0 in the input stream. Lines are terminated by one of
-+   * the following end-of-line sequences:
-+   * <br><ul><li>
-+   * Carriage Return (ASCII 13, '\r'). This EOL is used on Apple Macintosh
-+   * </li><li>
-+   * Linefeed (ASCII 10, '\n'). This is the UNIX EOL character.
-+   * </li><li>
-+   * Carriage Return + Linefeed ("\r\n"). This is used on MS Windows systems.
-+   * </li></ul>
-+   * Note that we didn't choose to use the system property "line.separator" since
-+   * today windows files are transfered to UNIX and Macs and vice versa. However,
-+   * a combination of '\n' with a subsequent '\r' is considered to be two lines.
-+   *
-+   * @return the current line number starting with 0 or -1 if no line numbers are supplied.
-+   * @see #getColumnNumber
-+   */  
-+  public int getLineNumber() {
-+    return _lineNumber;
-+  }
-+  
-+  /**
-+   * If the flag {@link Tokenizer#F_COUNT_LINES} is set, this method will return the
-+   * current column positionstarting with 0 in the input stream.
-+   *
-+   * @return the current column position
-+   * @see #getLineNumber
-+   */  
-+  public int getColumnNumber() {
-+    return _columnNumber;
-+  }
-+  
-+  /**
-+   * This method returns the absolute offset in characters to the start of the
-+   * parsed stream. Together with {@link AbstractTokenizer#currentlyAvailable} 
-+   * it describes the currently available text "window".
-+   *
-+   * @return the absolute offset of the current text window in characters from 
-+   *         the start of the data source of the Tokenizer
-+   */
-+  public int getRangeStart() {
-+    return _rangeStart;
-+  }
-+  
-+  /**
-+   * Getting the current read offset. This is the absolute position where the
-+   * next call to <CODE>nextToken</CODE> or <CODE>next</CODE> will start.
-+   *
-+   * @return the absolute offset in characters from the start of the data source 
-+   *         of the Tokenizer where reading will be continued
-+   */
-+  public int getReadPosition() {
-+    return _rangeStart + _currentReadPos;
-+  }
-+  
-+  /**
-+   * Retrieving the number of the currently available characters. This includes
-+   * both characters already parsed by the <CODE>Tokenizer</CODE> and characters
-+   * still to be analyzed.<br>
-+   *
-+   * @return number of currently available characters
-+   */
-+  public int currentlyAvailable() {
-+    return _currentWritePos;
-+  }
-+  
-+  
-+  /**
-+   * Try to read more data into the text buffer of the tokenizer. This can be
-+   * useful when a method needs to look ahead of the available data or a skip
-+   * operation should be performed.<br>
-+   * The method returns the same value than an immediately following call to 
-+   * {@link currentlyAvailable} would return.<br>
-+   *
-+   * @return  the number of character now available
-+   * @throws  TokenizerException generic exception (list) for all problems that 
-+   *          may occur while reading (IOExceptions for instance)
-+   */
-+  public int readMore() throws TokenizerException {
-+    readMoreData();
-+    return currentlyAvailable();
-+  }
-+  
-+  
-+  /**
-+   * This method tells the tokenizer to skip the given number of characters
-+   * starting on the current read position as can be retrieved by {@link #getReadPosition}.
-+   * The given number of characters must be less or equal to 
-+   * {@link #currentlyAvailable} - ({@link #getReadPosition} - {@link #getRangeStart}).
-+   *
-+   * @param numberOfChars   Number of characters to skip
-+   */
-+  public void skip(int numberOfChars) throws IndexOutOfBoundsException {
-+    int available = _currentWritePos - _currentReadPos;
-+    
-+    if (numberOfChars > available) {
-+      throw new ExtIndexOutOfBoundsException(
-+                  "Number of characters to skip ({0}) exceeds the available number ({1}).", 
-+                  new Object[] { new Integer(numberOfChars), new Integer(available) } 
-+                );
-+    } else if (numberOfChars < 0) {
-+      throw new ExtIndexOutOfBoundsException(
-+                  "Number of characters to skip ({0}) is negative.", 
-+                  new Object[] { new Integer(numberOfChars) } 
-+                );
-+    }
-+    
-+    _currentReadPos += numberOfChars;
-+    _lookAheadToken  = null;
-+  }
-+  
-+
-+  /**
-+   * Retrieve text from the currently available range. The start and length
-+   * parameters must be inside {@link #getRangeStart} and
-+   * <CODE>getRangeStart + {@link #currentlyAvailable}</CODE>.
-+   *
-+   * @param   start   position where the text begins
-+   * @param   len     length of the text
-+   * @return  the text beginning at the given position ith the given length
-+   * @throws  IndexOutOfBoundsException if the starting position or the length 
-+   *          is out of the current text window
-+   */
-+  public String getText(int start, int len) throws IndexOutOfBoundsException {
-+    if (start < _rangeStart) {
-+      throw new ExtIndexOutOfBoundsException(
-+                  "Start position {0} lower than the current text window start {1}.", 
-+                  new Object[] { new Integer(start), new Integer(_rangeStart) } 
-+                );
-+    } else if (start + len > _rangeStart + _currentWritePos) {
-+      throw new ExtIndexOutOfBoundsException(
-+                  "required text starting at position {0} with length {1} exceeds current text window starting at {2} with length {3}.", 
-+                  new Object[] { 
-+                    new Integer(start), new Integer(len), 
-+                    new Integer(_rangeStart),  new Integer(currentlyAvailable()) 
-+                  }
-+                );
-+    }
-+    return new String(_inputBuffer, start - _rangeStart, len);
-+  }
-+  
-+  /**
-+   * Get a single character from the current text range.
-+   *
-+   * @param pos position of the required character
-+   * @return the character at the specified position
-+   * @throws IndexOutOfBoundsException if the parameter <CODE>pos</CODE> is not 
-+   *         in the available text range (text window)
-+   */
-+  public char getChar(int pos) throws IndexOutOfBoundsException {
-+    if (pos < _rangeStart || pos >= _currentWritePos) {
-+      throw new ExtIndexOutOfBoundsException(
-+                  "Given position {0} is out of current text window starting at {2} with length {3}.", 
-+                  new Object[] { 
-+                    new Integer(pos), new Integer(_rangeStart), new Integer(currentlyAvailable())
-+                  } 
-+                );
-+    }
-+    return _inputBuffer[pos - _rangeStart];
-+  }
-+
-+  
-+  /**
-+   * This is a method designed to be used by those who can guarantee to be in a 
-+   * valid position range. It is equivalent to the {@link #getChar}
-+   * method above except that it does not check for a invalid position.
-+   *<br>
-+   * When passing an invalid position value, two situations may occure: The
-+   * invalid position is really out of bounds of the input buffer (an unchecked 
-+   * exception will be thrown) or it points into an area where old or even 
-+   * initial values lay.
-+   *
-+   * @param pos position of the required character
-+   * @return the character at the specified position
-+   */
-+  public char getCharUnchecked(int pos) {
-+    return _inputBuffer[pos - _rangeStart];
-+  }
-+
-+  
-+  //---------------------------------------------------------------------------
-+  // embedded tokenizer support
-+  //
-+  
-+  /**
-+   * Adding an embedded tokenizer. Embedded tokenizer work on the same input 
-+   * buffer as their base tokenizer. A situation where embedded tokenizer could
-+   * be applied, is a HTML stream with cascading style sheet (CSS) and JavaScript
-+   * parts.<br>
-+   * There are no internal means of switching from one tokenizer to another. 
-+   * This should be done by the caller using the method {@link #switchTo}.
-+   *
-+   * @param  tokenizer   an embedded tokenizer
-+   */
-+  public void addTokenizer(AbstractTokenizer tokenizer) {
-+    AbstractTokenizer curr = this;
-+    
-+    while (curr._nextTokenizer != null) {
-+      curr = curr._nextTokenizer;
-+    }
-+    curr._nextTokenizer      = tokenizer;
-+    tokenizer._prevTokenizer = curr;
-+    
-+    // share the input buffer of the base tokenizer
-+    tokenizer._inputBuffer = getBaseTokenizer(this)._inputBuffer;
-+  }
-+
-+  
-+  /**
-+   * Changing fron one tokenizer to another. If the given tokenizer has not been
-+   * added with {@link #addTokenizer}, an exception is thrown.<br>
-+   * The <CODE>switchTo</CODE> method does the nessecary synchronisation between
-+   * <CODE>this</CODE> and the given tokenizer. The user is therefore responsible
-+   * to use <CODE>switchTo</CODE> whenever a tokenizer change is nessecary. It
-+   * must be done this way:
-+   *<blockquote><pre>
-+   *   Tokenizer base     = new MyTokenizer(...)
-+   *   Tokenizer embedded = new MyTokenizer(...)
-+   *
-+   *   // setting properties (comments, keywords etc.)
-+   *   ...
-+   *
-+   *   // embedding a tokenizer
-+   *   base.addTokenizer(embedded);
-+   *   
-+   *   // tokenizing with base
-+   *   ...
-+   *   if (<i>switch_condition</i>) {
-+   *     base.switchTo(embedded);
-+   *   }
-+   *
-+   *   // tokenizing with embedded
-+   *   ...
-+   *   if (<i>switch_condition</i>) {
-+   *     embedded.switchTo(base);
-+   *   }
-+   *</pre></blockquote>
-+   * That way we avoid a more complex synchronisation between tokenizers whenever
-+   * one of them parses the next data in the input stream. However, the danger
-+   * of not synchronized tokenizers remains, so take care.
-+   *
-+   * @param tokenizer   the tokenizer that should be used from now on
-+   */
-+  public void switchTo(AbstractTokenizer tokenizer) 
-+    throws TokenizerException
-+  {
-+    if (tokenizer._inputBuffer != _inputBuffer) {
-+      throw new TokenizerException("Trying to switch to an alien tokenizer (not added with addTokenizer).", null);
-+    }
-+    tokenizer._currentReadPos  = this._currentReadPos;
-+    tokenizer._currentWritePos = this._currentWritePos;
-+    tokenizer._columnNumber    = this._columnNumber;
-+    tokenizer._lineNumber      = this._lineNumber;
-+    tokenizer._rangeStart      = this._rangeStart;
-+  }
-+
-+
-+  //---------------------------------------------------------------------------
-+  // Methods that may be overwritten in derived classes
-+  //
-+  
-+  /**
-+   * This method checks if the character is a whitespace. Implement Your own
-+   * code for situations where this default implementation is not fast enough
-+   * or otherwise not really good.
-+   *
-+   * @param testChar  check this character
-+   * @return <CODE>true</CODE> if the given character is a whitespace,
-+   *         <CODE>false</CODE> otherwise
-+   */
-+  protected boolean isWhitespace(char testChar) {
-+    int idx = -1;
-+    
-+    if (_defaultWhitespaces) {
-+      switch (testChar) {
-+        case ' ':
-+        case '\n':
-+        case '\r':
-+        case '\t':
-+          idx = 0;
-+          break;
-+      }
-+          
-+    } else {
-+      idx = indexInSet(testChar, _whitespaces);
-+    }
-+    return (idx >= 0);
-+  }
-+      
-+ 
-+  /**
-+   * This method detects the number of whitespace characters starting at the given
-+   * position. It should use {@link #getChar} or {@link #getCharUnchecked} to 
-+   * retrieve a character to check.
-+   *<br>
-+   * The method should return the number of characters identified as whitespaces
-+   * starting from and including the given start position.
-+   *<br>
-+   * Do not attempt to actually read more data or do anything that leads to the
-+   * change of the data source or to tokenizer switching. This is done by the 
-+   * tokenizer framework.
-+   *
-+   * @param   startingAtPos  start checking for whitespace from this position
-+   * @param   maxChars  if there is no non-whitespace character, read up to this number of characters 
-+   * @return  number of whitespace characters starting from the given offset
-+   * @throws  TokenizerException failure while reading data from the input stream
-+   */
-+  protected int readWhitespaces(int startingAtPos, int maxChars) throws TokenizerException {
-+    int len   = 0;
-+    
-+    while (len < maxChars) {
-+      if ( ! isWhitespace(getCharUnchecked(startingAtPos + len))) {
-+        break;
-+      }
-+      len++;
-+    }
-+    return len;
-+  }
-+  
-+  
-+  /**
-+   * This method reads characters in a string until it detects the end of
-+   * the string (this is the end sequence of the string, '"' in C and Java)
-+   * It should use {@link #getChar} or {@link #getCharUnchecked} to retrieve a 
-+   * character to check.
-+   *<br>
-+   * The method should return the number of characters identified as parts of the
-+   * string starting from and including the given start position.
-+   *<br>
-+   * Do not attempt to actually read more data or do anything that leads to the
-+   * change of the data source or to tokenizer switching. This is done by the 
-+   * tokenizer framework.
-+   *
-+   * @param   startingAtPos   start reading the string from this position
-+   * @param   maxChars        check up to this number of characters 
-+   * @return  number of characters being part of the line comment
-+   * @throws  TokenizerException something happened
-+   */
-+  protected int readString(int startingAtPos, int maxChars) throws TokenizerException {
-+    return 0;
-+  }
-+  
-+  
-+  /**
-+   * This method checks the given character if it is a separator.
-+   * Implement Your own code for situations where this default implementation 
-+   * is not fast enough or otherwise not really good.
-+   *
-+   * @param testChar  check this character
-+   * @return <CODE>true</CODE> if the given character is a separator,
-+   *         <CODE>false</CODE> otherwise
-+   */
-+  protected boolean isSeparator(char testChar) {
-+    return indexInSet(testChar, _separators) >= 0;
-+  }
-+
-+  
-+  /**
-+   * This method checks at the given position if it contains a a special sequence. 
-+   * Unlike the method {@link #test4SpecialSequence} it does nothing more.
-+   * It should use {@link #getChar} or {@link #getCharUnchecked} to retrieve 
-+   * characters at need.
-+   *
-+   * @param  startingAtPos  check at this position
-+   * @throws TokenizerException failure while reading data from the input stream
-+   * @return <CODE>true</CODE> if a special sequence was found at the given offset,
-+   *         <CODE>false</CODE> otherwise
-+   */
-+  protected TokenizerProperty isSequenceCommentOrString(int startingAtPos) 
-+    throws TokenizerException 
-+  {
-+    // we need the longest possible match
-+    TokenizerProperty prop   = null;
-+    int               offset = startingAtPos - (_currentReadPos + _rangeStart);
-+    
-+    for (int pos = 0; pos < _sequences.length; ++pos) {
-+      if (_sequences[pos] != null) {
-+        TokenizerProperty p = _sequences[pos].searchBinary(null, offset, false);
-+        
-+        if (   p != null 
-+            && (   prop == null
-+                || p.getValues()[0].length() > prop.getValues()[0].length())) {
-+          prop = p;
-+        }
-+      }
-+    }
-+    return prop;
-+  }
-+
-+  
-+  //---------------------------------------------------------------------------
-+  // Implementation
-+  //
-+
-+  /**
-+   * This method creates the sorted arrays to store the case-sensitive and
-+   * -insensitive special sequences, comments, strings etc.
-+   *
-+   * @param prop  the description of the new sequence
-+   */
-+  protected void addSpecialSequence(TokenizerProperty prop) {
-+    int arrayIdx;
-+    int flags = prop.getFlags();
-+    
-+    if ((flags & Tokenizer.F_NO_CASE) == 0) {
-+      if (_sequences[0] == null) {
-+        _sequences[0] = new SortedArray(this, flags);
-+      }
-+      arrayIdx = 0;
-+    } else {
-+      if (_sequences[1] == null) {
-+        _sequences[1] = new SortedArray(this, flags);
-+      }
-+      arrayIdx = 1;
-+    }
-+    _sequences[arrayIdx].addSpecialSequence(prop);
-+  }
-+  
-+  
-+  /**
-+   * Search a special sequence for the getter methods.
-+   *
-+   * @param   specSeq   (starting) sequence to be found
-+   * @return  the {@link TokenizerProperty} of the sequence or <code>null</code>
-+   */
-+  protected TokenizerProperty searchBinary(String specSeq) {
-+    try {
-+      for (int pos = 0; pos < _sequences.length; ++pos) {
-+        TokenizerProperty prop;
-+        
-+        if (   _sequences[pos] != null 
-+            && (prop = _sequences[pos].searchBinary(specSeq, 0, false)) != null) {
-+          return prop;
-+        }
-+      } 
-+    } catch (TokenizerException ex) {
-+      // this shouldn't happen at all since we do not read from the input stream
-+      throw new ExtRuntimeException(
-+                  ex,
-+                  "While trying to retrieve the companion of special sequence \"{0}\".", 
-+                  new Object[] { specSeq }
-+                );
-+    }
-+    
-+    // no sequences or not found
-+    return null;
-+  }
-+  
-+  
-+  /**
-+   * Embedded tokenizers have their base tokenizer they share the input stream
-+   * with.
-+   *
-+   * @param t   the tokenizer thats base tokenizer should be found
-+   * @return the base tokenizer (the one owning the input stream and text buffer)
-+   */
-+  protected AbstractTokenizer getBaseTokenizer(AbstractTokenizer t) {
-+    while (t._prevTokenizer != null) {
-+      t = t._prevTokenizer;
-+    }
-+    return t;
-+  }
-+  
-+  /**
-+   * This method organizes the input buffer. It moves the current text window if
-+   * nessecary or allocates more space, if data should be kept completely (see the
-+   * {@link Tokenizer#F_KEEP_DATA} flag).
-+   * Its main purpose is to call the {@link #read} method of the implementing class.
-+   *
-+   * @return number of read bytes or -1 if an end-of-file condition occured
-+   * @throws TokenizerException wrapped exceptions from the {@link #read} method
-+   */
-+  protected int readMoreData() throws TokenizerException  {
-+    // its always the base tokenizer doing the reading
-+    int               bytes = 0;
-+    AbstractTokenizer base  = getBaseTokenizer(this);
-+    
-+    if (base != this) {
-+      return base.readMoreData();
-+    }
-+    
-+    // this is a good moment to move already read data if the write position is
-+    // near the end of the buffer and there is a certain space before the current
-+    // read position
-+    int readOffset = 0;
-+    
-+    if ((_flags & Tokenizer.F_KEEP_DATA) == 0) {
-+      if (   _currentReadPos  > _inputBuffer.length / 4
-+          && _currentWritePos > (3 * _inputBuffer.length) / 4) {
-+        System.arraycopy(_inputBuffer, _currentReadPos, _inputBuffer, 0, _currentWritePos - _currentReadPos);
-+        readOffset        = _currentReadPos;
-+        _rangeStart      += _currentReadPos;
-+        _currentWritePos -= _currentReadPos;
-+        _currentReadPos   = 0;
-+      }
-+    }
-+    
-+    // if there is no space any more and data couldn't be moved (see above)
-+    // we need a new input buffer
-+    if (_currentWritePos >= _inputBuffer.length) {
-+      char[] newBuffer = new char[_inputBuffer.length * 2];
-+      
-+      if ((_flags & Tokenizer.F_KEEP_DATA) != 0) {
-+        System.arraycopy(_inputBuffer, 0, newBuffer, 0, _currentWritePos);
-+      } else {
-+        System.arraycopy(_inputBuffer, _currentReadPos, newBuffer, 0, _currentWritePos - _currentReadPos);
-+      }
-+      _inputBuffer = newBuffer;
-+    }
-+    
-+    // now read more data. We need to block the potentially non-blocking read 
-+    // method of the implementing class
-+    // Note that a bytes can only be != 0 with <0 for EOF
-+    while (bytes == 0) {
-+      try {
-+        bytes = read(_inputBuffer, _currentWritePos, _inputBuffer.length - _currentWritePos);
-+      } catch (Exception ex) {
-+        throw new TokenizerException(ex);
-+      }
-+    }
-+    if (bytes > 0) {
-+      _currentWritePos += bytes;
-+    }
-+    
-+    // Inform all embedded tokenizers about input buffer changes
-+    base.synchronizeAll(readOffset);
-+    return bytes;
-+  }
-+  
-+
-+  /**
-+   * When the method {@link readMoreData} changes the contents of the input buffer 
-+   * or the input buffer itself, all embedded tokenizers must be synchronized.
-+   * That means their member variables are adjusted to the base tokenizer.
-+   *
-+   * @param readPosOffset   add this (negative) offset to all current read positions
-+   */
-+  protected void synchronizeAll(int readPosOffset) {
-+    AbstractTokenizer base     = getBaseTokenizer(this);
-+    AbstractTokenizer embedded = base;
-+
-+    while ((embedded = embedded._nextTokenizer) != null) {
-+      embedded._inputBuffer     = base._inputBuffer;
-+      embedded._currentWritePos = base._currentWritePos;
-+      embedded._currentReadPos += readPosOffset;
-+    }
-+  }
-+
-+  /**
-+   * The number of characters until the next comment, whitespace, string, special
-+   * sequence or separator are determined.
-+   *
-+   * @param token buffer to receive information about the keyword or normal token
-+   * @return <CODE>true</CODE> if a keyword or normal text (e.g. an identifier) 
-+   *         has been found, <CODE>false</CODE> otherwise
-+   * @throws TokenizerException failure while reading data from the input stream
-+   */
-+  protected boolean test4Normal(Token token) throws TokenizerException {
-+    // find out the return value (length of normal token)
-+    int len = 0;
-+    int pos;
-+    
-+    while (_currentReadPos + len < _currentWritePos || readMoreData() > 0) {
-+      if (   isWhitespace(len) 
-+          || isSpecialSequence(len) 
-+          || isSeparator(len)) {
-+        break;
-+      }
-+      len++;
-+    }
-+    
-+    // something else found (whitespace, separator, EOF, ...)
-+    if (len <= 0) {
-+      return false;
-+    }
-+    
-+    // test on keyword
-+    if (_keywords[0] != null || _keywords[1] != null) {
-+      TokenizerProperty prop    = null;
-+      String            keyword = new String(_inputBuffer, _currentReadPos, len);
-+      
-+      if (_keywords[0] != null) {
-+        prop = (TokenizerProperty)_keywords[0].get(keyword);
-+      }
-+      if (prop == null && _keywords[1] != null) {
-+        keyword = keyword.toUpperCase();
-+        prop    = (TokenizerProperty)_keywords[1].get(keyword);
-+      }
-+      if (prop != null) {
-+        token.setType(Token.KEYWORD); 
-+        token.setLength(keyword.length());
-+        token.setCompanion(prop.getCompanion());
-+      } else {
-+        token.setType(Token.NORMAL);
-+        token.setLength(len);
-+      }
-+    } else {
-+      token.setType(Token.NORMAL);
-+      token.setLength(len);
-+    }
-+    return true;
-+  }
-+  
-+  
-+  /**
-+   * Check if the current read position contains a whitespace. If so retrieve
-+   * the whole sequence of whitespaces.
-+   *
-+   * @param token   add information to this buffer
-+   * @throws TokenizerException failure while reading data from the input stream
-+   * @return <CODE>true</CODE> if a whitespace sequence was found
-+   *         <CODE>false</CODE> otherwise
-+   */
-+  protected boolean test4Whitespace(Token token) throws TokenizerException {
-+    if (_currentReadPos < _currentWritePos ||  readMoreData() > 0) {
-+      if (isWhitespace(_inputBuffer[_currentReadPos])) {
-+        completeWhitespace(token);
-+        return true;
-+      }
-+    }
-+    return false;
-+  }
-+  
-+  /**
-+   * After having identified a whitespace, this method continues to read data
-+   * until it detects a non-whitespace.<br>
-+   * The method is expected to fill in the type and the length of the whitespace
-+   * token using the methods {@link Token#setType} and {@link Token#setLength}.
-+   *
-+   * @param token   add information to this buffer
-+   * @throws TokenizerException failure while reading data from the input stream
-+   */
-+  protected void completeWhitespace(Token token) throws TokenizerException {
-+    int start     = _currentReadPos + 1;  // the first whitespace we have already
-+    int available = _currentWritePos - start;
-+    int len       = readWhitespaces(_rangeStart + start, available);
-+    
-+    while (len == available) {
-+      if (readMoreData() <= 0) {
-+        break;
-+      }
-+      start    += len;
-+      available = _currentWritePos - start;
-+      len      += readWhitespaces(_rangeStart + start, available);
-+    }
-+
-+    token.setType(Token.WHITESPACE);
-+    token.setLength(len + 1);           // the first whitespace we had already
-+  }
-+  
-+  /**
-+   * This method checks at the given offset if it is a whitespace. Unlike the
-+   * method {@link #test4Whitespace} it does nothing more.
-+   *
-+   * @param offset  check at this position relative to the current read position
-+   * @throws TokenizerException failure while reading data from the input stream
-+   * @return <CODE>true</CODE> if a whitespace sequence was found at the given offset,
-+   *         <CODE>false</CODE> otherwise
-+   */
-+  protected boolean isWhitespace(int offset) throws TokenizerException {
-+    // enough data ?
-+    if (_currentReadPos + offset >= _currentWritePos && readMoreData() < 0) {
-+      return false;
-+    }
-+    
-+    // did we find a whitespace?
-+    if (isWhitespace(_inputBuffer[_currentReadPos + offset])) {
-+      _lookAheadToken.setType(Token.WHITESPACE);
-+      return true;
-+    } else {
-+      return false;
-+    }
-+  }
-+      
-+ 
-+  /**
-+   * Check if the current read position contains a separator. If so retrieve
-+   * the separator.
-+   *
-+   * @param token   add information about the separator to this buffer
-+   * @throws TokenizerException failure while reading data from the input stream
-+   * @return <CODE>true</CODE> if a separator was found,
-+   *         <CODE>false</CODE> otherwise
-+   */
-+  protected boolean test4Separator(Token token) throws TokenizerException {
-+    if (isSeparator(0)) {
-+      _lookAheadToken.setType(Token.UNKNOWN);
-+      completeSeparator(token);
-+      return true;
-+    } else {
-+      return false;
-+    }
-+  }
-+  
-+  /**
-+   * After having identified a separator, this method stores information about
-+   * it in the given <code>Token</code>. Separators are always single characters.
-+   *
-+   * @param token   add information about the separator to this buffer
-+   * @throws TokenizerException failure while reading data from the input stream
-+   */
-+  protected void completeSeparator(Token token) throws TokenizerException {
-+    token.setType(Token.SEPARATOR);
-+    token.setLength(1);
-+  }
-+  
-+  
-+  /**
-+   * This method checks at the given offset if it contains a separator. Unlike the
-+   * method {@link #test4Separator} it does nothing more.
-+   *
-+   * @param offset  check at this position relative to the current read position
-+   * @throws TokenizerException failure while reading data from the input stream
-+   * @return <CODE>true</CODE> if a separator was found at the given offset,
-+   *         <CODE>false</CODE> otherwise
-+   */
-+  protected boolean isSeparator(int offset) throws TokenizerException {
-+    if (_currentReadPos + offset < _currentWritePos ||  readMoreData() > 0) {
-+      int idx = indexInSet(_inputBuffer[_currentReadPos + offset], _separators);
-+      
-+      if (idx >= 0) {
-+        _lookAheadToken.setType(Token.SEPARATOR);
-+        return true;
-+      }
-+    }
-+    return false;
-+  }
-+  
-+  
-+  /**
-+   * Check if the current read position is the start of a special sequence. If 
-+   * so retrieve the special sequence.
-+   *
-+   * @param token   add information about the special sequence to this buffer
-+   * @throws TokenizerException failure while reading data from the input stream
-+   * @return <CODE>true</CODE> if a special sequence was found,
-+   *         <CODE>false</CODE> otherwise
-+   */
-+  protected boolean test4SpecialSequence(Token token) throws TokenizerException {
-+    TokenizerProperty prop = isSequenceCommentOrString(_rangeStart + _currentReadPos);
-+    
-+    if (prop != null) {
-+      _lookAheadToken.setCompanion(prop);
-+      completeSpecialSequence(token);
-+      return true;
-+    } else {
-+      return false;
-+    }
-+  }
-+  
-+  
-+  /**
-+   * After having identified a special sequence, this method completes this sequence
-+   * and stores information about it in the given <code>Token</code>. Note that 
-+   * a special sequence is not identical to the token image that comprises the
-+   * special sequence. For instance, a line comment start with the character
-+   * sequence that identifies the line comment but contains also the data up to 
-+   * and including the end-of-line combination.
-+   *
-+   * @param token   add information about the separator to this buffer
-+   */
-+  protected void completeSpecialSequence(Token token) throws TokenizerException {
-+    TokenizerProperty prop = (TokenizerProperty)_lookAheadToken.getCompanion();
-+    String            seq  = prop.getValues()[0];
-+      
-+    token.setType(prop.getType());
-+    token.setCompanion(prop.getCompanion());
-+      
-+    switch (prop.getType()) {
-+    case Token.STRING:
-+      token.setLength(completeString(seq.length(), prop));
-+      break;
-+    case Token.BLOCK_COMMENT:
-+      token.setLength(completeBlockComment(seq.length(), prop));
-+      break;
-+    case Token.LINE_COMMENT:
-+      token.setLength(completeLineComment(seq.length()));
-+      break;
-+    default:
-+      token.setLength(seq.length());
-+    }          
-+  }
-+  
-+  /**
-+   * This method checks at the given offset if it contains a a special sequence. 
-+   * Unlike the method {@link #test4SpecialSequence} it does nothing more.
-+   *
-+   * @param offset  check at this position relative to the current read position
-+   * @throws TokenizerException failure while reading data from the input stream
-+   * @return <CODE>true</CODE> if a special sequence was found at the given offset,
-+   *         <CODE>false</CODE> otherwise
-+   */
-+  protected boolean isSpecialSequence(int offset) throws TokenizerException {
-+    TokenizerProperty prop = isSequenceCommentOrString(_rangeStart + _currentReadPos + offset);
-+    
-+    if (prop != null) {
-+      _lookAheadToken.setType(Token.SPECIAL_SEQUENCE);
-+      _lookAheadToken.setCompanion(prop);
-+      return true;
-+    } else {
-+      return false;
-+    }
-+  }
-+  
-+  
-+  /**
-+   * Completing a line comment. After a line comment sequence has been found, all
-+   * characters up to and including the end-of-line combination belong to the 
-+   * line comment. Note that on reaching end-of-file a line comment does not 
-+   * nessecarily ends with an end-of-line sequence (linefeed for example).
-+   *
-+   * @param  offset  start completing at this position relative to the current read position
-+   * @throws TokenizerException failure while reading data from the input stream
-+   * @return length of the line comment including start and terminating newline
-+   */
-+  protected int completeLineComment(int offset) 
-+    throws TokenizerException 
-+  {
-+    int len = offset;
-+
-+    while (_currentReadPos + len < _currentWritePos || readMoreData() > 0) {
-+      switch (_inputBuffer[_currentReadPos + len]) {
-+      case '\r':
-+        len++;
-+        if (_currentReadPos + len < _currentWritePos || readMoreData() > 0) {
-+          if (_inputBuffer[_currentReadPos + len] == '\n') {
-+            len++;
-+          }
-+        }
-+        return len;       // this should be one of the usual return points
-+      case '\n':
-+        return len + 1;     // this should be the other of the usual return points
-+      default:
-+        len++;
-+      }
-+    }
-+    
-+    // this is reached on EOF
-+    return len;
-+  }
-+  
-+  
-+  /**
-+   * Completing a block comment. After a block comment sequence has been found, all
-+   * characters up to and including the end sequence of the block comment belong 
-+   * to the block comment. Note that on reaching end-of-file a block comment does 
-+   * not nessecarily ends with an end-of-block-comment sequence.
-+   *
-+   * @param offset  start completing at this position relative to the current read position
-+   * @throws TokenizerException failure while reading data from the input stream
-+   * @return length of the block comment including start and end sequence
-+   */
-+  protected int completeBlockComment(int offset, TokenizerProperty prop) 
-+    throws TokenizerException 
-+  {
-+    String  start  = prop.getValues()[0];
-+    String  end    = prop.getValues()[1];
-+    boolean noCase = (prop.getFlags() & F_NO_CASE) != 0;
-+    int     len    = offset;
-+    int     level  = 0;
-+
-+  __LOOP__:
-+    do {
-+      // test on nested comments: we take only care for nesting the same
-+      // block comment
-+      if (   (_flags & Tokenizer.F_ALLOW_NESTED_COMMENTS) != 0) {
-+        switch (comparePrefix(len, start, noCase)) {
-+        case 0:     // comment start identified
-+          level++;
-+          len += start.length();
-+          continue __LOOP__;
-+        case -1:    // EOF reached
-+          return _currentWritePos - _currentReadPos;   
-+        }
-+      }
-+      
-+      // is it the end ?
-+      switch (comparePrefix(len, end, noCase)) {
-+      case 0:       // comment end identified
-+        level--;
-+        len += end.length();
-+        break;
-+      case -1:      // EOF reached
-+        return _currentWritePos - _currentReadPos;
-+      default:
-+        len++;
-+      }
-+    } while (level >= 0);
-+    
-+    // this is the regular return point
-+    return len;
-+  }
-+  
-+  
-+  /**
-+   * Completing a string. After a string start sequence has been found, all
-+   * characters up to and including the end-of-string sequence belong to the
-+   * string. Note that on reaching end-of-file a string does not nessecarily ends 
-+   * with an end-of-string sequence.
-+   *
-+   * @param offset  start completing at this position relative to the current read position
-+   * @throws TokenizerException failure while reading data from the input stream
-+   * @return length of the string including start and end sequence
-+   */
-+  protected int completeString(int offset, TokenizerProperty prop) 
-+    throws TokenizerException 
-+  {
-+    String  end           = prop.getValues()[1];
-+    String  esc           = prop.getValues()[2];
-+    boolean noCase        = (prop.getFlags() & F_NO_CASE) != 0;
-+    boolean escEqualsEnd  =    ( ! noCase && esc.compareTo(end)           == 0)
-+                            || (   noCase && esc.compareToIgnoreCase(end) == 0);
-+    int     len           = offset;
-+
-+    while (true) {
-+      // test on escape
-+      if (esc != null) {
-+        switch (comparePrefix(len, esc, noCase)) {
-+        case 0:       // escape found
-+          len += esc.length();
-+          if (escEqualsEnd) {
-+            switch (comparePrefix(len, end, noCase)) {
-+            case 0:
-+              len += end.length();
-+              break;
-+            case -1:      // EOF reached
-+              return _currentWritePos - _currentReadPos;   
-+            default:
-+              return len; // this is the regular return point if the esc is the string end
-+            }
-+          } else {
-+            len++;        // esc != string end: skip the next character
-+          }
-+          continue;
-+        case -1:          // EOF reached
-+          return _currentWritePos - _currentReadPos;   
-+        }
-+      }
-+
-+      // test on end sequence
-+      switch (comparePrefix(len, end, noCase)) {
-+      case 0:             // this is the regular return point if esc != string end
-+        len += end.length();    
-+        return len;
-+      case -1:            // EOF reached    
-+        return _currentWritePos - _currentReadPos;   
-+      }
-+     
-+      len++;
-+    }
-+  }
-+
-+  
-+  /**
-+   * This method compares the characters at the given offset (from the current
-+   * read position) with the given prefix.
-+   *
-+   * @param   offset  start comparing at this offset from the current read position
-+   * @param   prefic  compare read data with this prefix
-+   * @param   noCase  case- or not case-sensitive comparison
-+   * @throws  TokenizerException failure while reading data from the input stream
-+   * @return  0 if the the given prefix matches the input stream, -1 on EOF and
-+   *          1 if not matching
-+   */
-+  protected int comparePrefix(int offset, String prefix, boolean noCase) 
-+    throws TokenizerException 
-+  {
-+    // compare
-+    int len = prefix.length();
-+    
-+    for (int pos = offset; pos < offset + len; ++pos) {
-+      // do we have enough data
-+      if (_currentReadPos + pos >= _currentWritePos && readMoreData() < 0) {
-+        return -1;
-+      }
-+      
-+      // compare single character
-+      char c1 = prefix.charAt(pos - offset);
-+      char c2 = _inputBuffer[_currentReadPos + pos];
-+      
-+      if (   c1 != c2
-+          && (! noCase || Character.toUpperCase(c1) != Character.toUpperCase(c2))) {
-+        return 1;
-+      }
-+    }
-+    
-+    // found
-+    return 0;
-+  }
-+  
-+
-+  /**
-+   * A given character is searched in the given character set. This set may
-+   * contain ranges, for example "a-z" for all lowercase alpha characters. To use
-+   * the minus sign itself, escape it by "\-".
-+   *
-+   * @return  index in the given character set where the given character
-+   *          was found or -1 when not ound
-+   */
-+  protected int indexInSet(char ch, String set) {
-+    int  len = (set != null) ? set.length() : 0;
-+    char start, end, setChar;
-+    char chUp = 0;
-+    
-+    if ((_flags & Tokenizer.F_NO_CASE) != 0){
-+      chUp = Character.toUpperCase(ch);
-+    }
-+    
-+    for (int ii = 0; ii < len; ++ii)  {
-+      switch (setChar = set.charAt(ii)) {
-+      case '-':
-+        start = (ii > 0) ? set.charAt(ii - 1) : 0;
-+        end   = (ii < len - 1) ? set.charAt(ii + 1) : 0xFFFF;
-+        if (ch >= start && ch <= end) {
-+          return ii;
-+        }
-+        ii += 2; 
-+        break;
-+        
-+      case '\\':
-+        setChar = (ii + 1 >= len) ? 0 : set.charAt(ii + 1);
-+        ii++;
-+        /* no break */
-+        
-+      default:
-+        if (   ch == setChar
-+            || ((_flags & Tokenizer.F_NO_CASE) != 0 && chUp == Character.toUpperCase(setChar))) {
-+          return ii;
-+        }
-+      }
-+    }
-+    
-+    // not found
-+    return -1;
-+  }
-+  
-+  /**
-+   * The method recomputes the line and column position of the tokenizer, if the 
-+   * flag {@link Tokenizer#F_COUNT_LINES} is set. It gets the token type of the
-+   * {@link Token} that has been retrieved by the calling {@link #nextToken}.
-+   * Using the tokenizer control flags and certain other information it tries to
-+   * to find end-of-line sequences as fast as possible. For example, a line 
-+   * comment should always contain a end-of-line sequence, so we can simply 
-+   * increase the line count and set the column count to 0.
-+   *
-+   * @param type    the type of the current token
-+   * @param length  the length of the current token
-+   */
-+  protected void adjustLineAndColumn(int type, int length) {
-+    // line and column counting not required
-+    if ((_flags & Tokenizer.F_COUNT_LINES) == 0) {
-+      return;
-+    }
-+    
-+    // there might be a simple way to determine the current line and column position
-+    switch (type) {
-+    case Token.EOF:
-+      return;
-+        
-+    case Token.LINE_COMMENT:        // a line comment always ends with a newline
-+      _lineNumber++;
-+      _columnNumber = 0;
-+      return;
-+      
-+    case Token.SPECIAL_SEQUENCE:
-+    case Token.NORMAL:
-+    case Token.KEYWORD:
-+      if (_newlineIsWhitespace) {   // newline is a whitespace character
-+        _columnNumber += length;    // it does therefore not occure in other
-+        return;                     // tokens
-+      }
-+      break;
-+        
-+    case Token.WHITESPACE:
-+      if (!_newlineIsWhitespace) {  // newline is not a whitespace; we do not
-+        _columnNumber += length;    // have to test for it in the current 
-+        return;                     // token
-+      }
-+      break;
-+    }
-+    
-+    // count it
-+    for (int pos = _currentReadPos; pos < _currentReadPos + length; ++pos) {
-+      switch (_inputBuffer[pos]) {
-+      case '\r':
-+        if (pos + 1 >= _currentReadPos + length || _inputBuffer[pos + 1] != '\n') {
-+          _lineNumber++;
-+          _columnNumber = 0;
-+          break;
-+        }
-+        pos++;
-+        /* no break; */
-+      case '\n':
-+        _lineNumber++;
-+        _columnNumber = 0;
-+        break;
-+        
-+      default:
-+        _columnNumber++;
-+      }
-+    }
-+  }
-+  
-+
-+  //---------------------------------------------------------------------------
-+  // Members
-+  //
-+  
-+  /**
-+   * overall tokenizer flags.
-+   */
-+  protected int _flags = 0;
-+  
-+  /**
-+   * current whitespace characters including character ranges.
-+   */
-+  protected String _whitespaces = Tokenizer.DEFAULT_WHITESPACES;
-+  
-+  /**
-+   * current separator characters including character ranges.
-+   */
-+  protected String _separators = Tokenizer.DEFAULT_SEPARATORS;
-+  
-+  /**
-+   * The first element is the <code>SortedArray</code> for the case-sensitive 
-+   * sequences, the second is for the case-insensitive ones.
-+   */
-+  protected SortedArray[] _sequences = new SortedArray[2];
-+  
-+  /**
-+   * Like the array {@link #_sequences} this two-element Array contains two
-+   * {@link java.util.HashMap}, the first for the case-sensitive keywords, the
-+   * second for the case-insensitive ones.
-+   * With Java2, replace with {@link java.util.HashMap}.
-+   *
-+   * @deprecated
-+   */
-+  protected HashMap[] _keywords = new HashMap[2];
-+  
-+  /**
-+   * this flag speeds up the line and column counting
-+   */
-+  protected boolean _newlineIsWhitespace  = false;
-+  
-+  /**
-+   * This buffer holds the currently read data. Dont use a buffered reader, since
-+   * we do buffering here.
-+   */
-+  protected char[] _inputBuffer = null;
-+
-+  /**
-+   * index in {@link #_inputBuffer} there {@link #nextToken} will start parsing.
-+   */
-+  protected int _currentReadPos = 0;
-+
-+  /**
-+   * index in {@link #_inputBuffer} there {@link #readMoreData} will fill in new data.
-+   */
-+  protected int _currentWritePos = 0;
-+  
-+  /**
-+   * Mapping of index 0 of {@link #_inputBuffer} to the absolute start of the 
-+   * input stream.
-+   */
-+  protected int _rangeStart = 0;
-+  
-+  /**
-+   * if line counting is enabled, this contains the current line number starting
-+   * with 0.
-+   */
-+  protected int _lineNumber = -1;
-+
-+  /**
-+   * if line counting is enabled, this contains the current column number starting
-+   * with 0.
-+   */
-+  protected int _columnNumber = -1;
-+  
-+  /**
-+   * Token found by the last call to {@link #nextToken}
-+   */
-+  protected Token _currentToken = null;
-+  
-+  /**
-+   * If a mthod could detect the tokewn after the currently assembled one, infomation
-+   * regarding that token are stored here.
-+   */
-+  protected Token _lookAheadToken = new Token();
-+  
-+  /**
-+   * For embedded tokenizers: this is the list of the succeding tokenizers
-+   */
-+  protected AbstractTokenizer _nextTokenizer = null;
-+
-+  /**
-+   * For embedded tokenizers: this is the list of the previous tokenizers
-+   */
-+  protected AbstractTokenizer _prevTokenizer = null;
-+  
-+  /**
-+   * For fast whitespace scans, check the common whitespaces first
-+   */
-+  private boolean _defaultWhitespaces = false;
-+}
-+
-+
-+
-+//---------------------------------------------------------------------------
-+// inner classes
-+//
-+
-+/**
-+ * This hidden class implements a binary tree for the special sequences. It is
-+ * designed as a sorted array.
-+ */
-+final class SortedArray {
-+
-+  /**
-+   * Constructor needs the Tokenizer and the flags (compare case-sensitive or
-+   * not).
-+   *
-+   * @param parent    the Tokenizer constructing me
-+   * @param flags     <code>F_...</code> flags as defined in {@link Tokenizer}
-+   */
-+  public SortedArray(AbstractTokenizer parent, int flags) {
-+    _parent = parent;
-+    _flags  = flags;
-+  }
-+
-+  /**
-+   * Binary search in the special sequence tree. There are two results. First,
-+   * the method returns a value 0, >0 or <0 for the binary search, and in the
-+   * <code>nearestMatch</code> the index in the tree, where a new entry should be
-+   * placed.<br>
-+   * If the returned value is 0, a new entry goes to the list in nearestMatch[0].
-+   *<br>
-+   * If the returned value is <0, a new list at nearestMatch[0] + 1 will be
-+   * created.<br>
-+   * If the returned value is >0, a new list at nearestMatch[0] will be created.
-+   *
-+   * @param startChar search this character
-+   * @param nearestMatch  in this one-element array the method returns the 
-+   *                      index next to which new entries should be inserted
-+   * @return 
-+   */
-+  private int searchIndex(char startChar, int[] nearestMatch) {
-+    // do the binary search
-+    char upChar = Character.toUpperCase(startChar);
-+    int  left   = 0;
-+    int  right  = _array.size() - 1;
-+    int  res    = -1;
-+
-+    nearestMatch[0] = -1;
-+
-+    // typical binary search for the matching start character
-+  __MAIN_LOOP__:
-+    while (left <= right) {
-+      int idx;
-+
-+      // do we really have a new one
-+      if ((idx = (right + left) / 2) == nearestMatch[0]) {
-+        break;
-+      }
-+      nearestMatch[0] = idx;
-+
-+      // compare the starting characters
-+      SpecialSequence   listElem = (SpecialSequence)_array.get(idx);
-+      TokenizerProperty existing = listElem._property;
-+      String            exSeq    = existing.getValues()[0];
-+
-+      if ((_flags & Tokenizer.F_NO_CASE) != 0) {
-+        res = Character.toUpperCase(exSeq.charAt(0)) - upChar;
-+      } else {
-+        res = exSeq.charAt(0) - startChar; 
-+      }
-+
-+      // binary branching
-+      if (res == 0) { 
-+        break;                // found the list
-+      } else if (res < 0) {   
-+        left = idx + 1;       // take the upper half 
-+      } else {                
-+        right = idx - 1;      // take the lower half
-+      }
-+    }
-+
-+    // res == 0 means found
-+    return res;
-+  }
-+
-+  /**
-+   * Retrieving a special sequence at the given position. The method does not
-+   * check the given positionen for being inside the array boundaries.
-+   *
-+   * @param index   the position
-+   * @return the special sequence 
-+   */
-+  public SpecialSequence get(int index) {
-+    return (SpecialSequence)_array.get(index);
-+  }
-+
-+
-+  /**
-+   * Retrieving the size of this sorted array.
-+   *
-+   * @return the size of this array
-+   */
-+  public int size() {
-+    return _array.size();
-+  }
-+
-+
-+  /**
-+   * Search a given sequence in the special sequences vector. This is a combined
-+   * method. It can search for a given sequence or take the current reading
-+   * position to read a potential special sequence.
-+   * After having found a match in the list of special sequences, the method 
-+   * can be advised to remove the matching element.
-+   * Searching is done in a hopefully very effective way by binary search and 
-+   * length-ordered sequences with the same first character.
-+   *
-+   * @param specSeq   candidate for special sequence or <CODE>null</CODE> if the
-+   *                  input buffer should be read
-+   * @param offset    (only used when <CODE>specSeq</CODE> is null) offset from the
-+   *                  current read position
-+   */
-+  protected TokenizerProperty searchBinary(String specSeq, int offset, boolean remove) 
-+    throws TokenizerException
-+  {
-+    // no special sequences known or no more data
-+    if (  _array == null 
-+       || (specSeq == null
-+           && _parent._currentReadPos + offset >= _parent._currentWritePos 
-+           && _parent.readMoreData() <= 0)) {
-+      return null;
-+    }
-+
-+    // do the binary search
-+    boolean fromStream   = (specSeq == null);
-+    int[]   nearestMatch = { -1 };
-+    char    startChar;
-+
-+    if (specSeq == null) {
-+      startChar = _parent._inputBuffer[_parent._currentReadPos + offset];
-+    } else {
-+      startChar = specSeq.charAt(0);
-+    }
-+    if (searchIndex(startChar, nearestMatch) != 0) {
-+      return null;
-+    }
-+
-+    // does the sequence come from the input stream ?
-+    SpecialSequence   listElem   = (SpecialSequence)_array.get(nearestMatch[0]);
-+    TokenizerProperty existing   = listElem._property;
-+    String            exSeq      = existing.getValues()[0];
-+
-+    if (specSeq == null) {
-+      int len = exSeq.length();
-+
-+      if (_parent._currentReadPos + offset + len >= _parent._currentWritePos) {
-+        _parent.readMoreData();
-+
-+        if ((_parent._currentWritePos - (_parent._currentReadPos + offset)) < len) {
-+          len = _parent._currentWritePos - (_parent._currentReadPos + offset);
-+        }
-+        if (len <= 0) {
-+          return null;
-+        }
-+      }
-+      specSeq = new String(_parent._inputBuffer, _parent._currentReadPos + offset, len);
-+    }
-+
-+    // try to find the longest match in the list of equaly starting sequences
-+    SpecialSequence prevElem = null;
-+
-+    do {
-+      existing = listElem._property;
-+      exSeq    = existing.getValues()[0];
-+
-+      // given sequences should be found as they are. Potential sequences from
-+      // the input stream are shortened approbriately as the list elements 
-+      // become shorter.
-+      if (specSeq.length() > exSeq.length()) {
-+        if (fromStream) {
-+          specSeq = specSeq.substring(0, exSeq.length());
-+        } else {
-+          return null;
-+        }
-+      }
-+
-+      // only need to compare on equal lengths
-+      if (specSeq.length() == exSeq.length()) {
-+        int res;
-+
-+        if ((_flags & Tokenizer.F_NO_CASE) != 0) {
-+          res = exSeq.compareToIgnoreCase(specSeq);
-+        } else {
-+          res = exSeq.compareTo(specSeq); 
-+        }
-+        if (res == 0) {
-+          if (remove) {
-+            if (prevElem == null) {
-+              if (listElem._next == null) {
-+                _array.remove(nearestMatch[0]);
-+              } else {
-+                listElem = listElem._next;
-+                _array.set(nearestMatch[0], listElem);
-+              }
-+            } else {
-+              prevElem._next = listElem._next;
-+            }
-+            return null;
-+          } else {
-+            return listElem._property;
-+          }
-+        } else if (res < 0) {   
-+          // no need to compare the spec.seq with the same length as
-+          // the current exSeq.
-+          specSeq = specSeq.substring(0, specSeq.length() - 1);
-+        }
-+      }
-+      prevElem = listElem;
-+      listElem = listElem._next;
-+    } while (listElem != null);
-+
-+    // still not found
-+    return null;
-+  }
-+
-+
-+  /**
-+   * Inner method that controls the special sequence store. This store is 
-+   * implemented as a binary tree for fast search operations.
-+   *
-+   * @param prop  the special sequence to add
-+   */
-+  public void addSpecialSequence(TokenizerProperty prop) {
-+    // first call
-+    if (_array == null) {
-+      _array = new ArrayList();
-+    }
-+
-+    // binary search for the right position of the token
-+    String  seq           = prop.getValues()[0];
-+    int[]   nearestMatch  = { -1 };
-+    int     res           = searchIndex(seq.charAt(0), nearestMatch);
-+
-+    // where to insert: < 0 means new sequence is greater than neighbouring 
-+    // existing one
-+    int idx = nearestMatch[0];
-+
-+    if (res < 0) {
-+      idx++;
-+    }
-+
-+    // new entry or replace existing one
-+    if (res != 0) {
-+      if (_array.size() > idx) {
-+        _array.add(idx, new SpecialSequence(prop));
-+      } else {        
-+        _array.add(new SpecialSequence(prop));
-+      }
-+    } else {
-+      SpecialSequence   listElem = (SpecialSequence)_array.get(idx);
-+      TokenizerProperty existing;
-+      String            exSeq;
-+
-+      while (listElem != null) {
-+        existing = listElem._property;
-+        exSeq    = existing.getValues()[0];
-+
-+        if (seq.length() > exSeq.length()) {
-+          listElem._next     = new SpecialSequence(existing, listElem._next);
-+          listElem._property = prop;
-+          break;
-+        } else if (seq.length() == exSeq.length()) {
-+          if ((_flags & Tokenizer.F_NO_CASE) != 0) {
-+            res = exSeq.compareToIgnoreCase(seq);
-+          } else {
-+            res = exSeq.compareTo(seq); 
-+          }
-+          if (res == 0) {
-+            listElem._property = prop;
-+          } else if (res < 0) {
-+            listElem._next     = new SpecialSequence(existing, listElem._next);
-+            listElem._property = prop;
-+          } else if (listElem._next == null) {
-+            listElem._next     = new SpecialSequence(prop);
-+          }
-+          break;
-+        } else if (listElem._next == null) {
-+          listElem._next = new SpecialSequence(prop);
-+          break;
-+        }
-+        listElem = listElem._next;
-+      }
-+    }
-+  }
-+
-+  // Members
-+  private AbstractTokenizer _parent = null;
-+  private ArrayList         _array  = null;
-+  int                       _flags  = 0;
-+}
-+
-+
-+/**
-+ * List for equaly starting special sequences
-+ */
-+final class SpecialSequence {
-+  SpecialSequence(TokenizerProperty prop) {
-+    this(prop, null);
-+  }
-+
-+  SpecialSequence(TokenizerProperty prop, SpecialSequence next) {
-+    _property = prop;
-+    _next     = next;
-+  }
-+
-+  public SpecialSequence    _next;
-+  public TokenizerProperty  _property;
-+}
-+  
-+  
-+/**
-+ * Instances of this inner class are returned when a call to {@link getKeywords}.
-+ * Each element of the enumeration contains a {@link TokenizerProperty} element,
-+ * that in turn has the keyword with its companion
-+ */
-+final class KeywordIterator implements Iterator {
-+
-+  /**
-+   * constructor taking the calling <code>Tokenizer</code> and the type of the
-+   * {@link TokenizerProperty}.
-+   *
-+   * @param parent  the calling tokenizer
-+   * @param type    type of the <code>TokenizerProperty</code> 
-+   */
-+  public KeywordIterator(AbstractTokenizer parent) {
-+    if (parent._keywords[0] != null) {
-+      _iterators[0] = parent._keywords[0].values().iterator();
-+    }
-+    if (parent._keywords[1] != null) {
-+      _iterators[1] = parent._keywords[1].values().iterator();
-+    }
-+  }
-+
-+  /**
-+   * the well known method from the {@link java.util.Iterator} interface.
-+   *
-+   * @return <code>true</code> if there are more {@link TokenizerProperty}
-+   *         elements, <code>false</code> otherwise
-+   */
-+  public boolean hasNext() {
-+    // check the current array
-+    if (_iterators[0] != null) {
-+      if (_iterators[0].hasNext()) {
-+        return true;
-+      } else {
-+        _iterators[0] = null;
-+      }
-+    }
-+    if (_iterators[1] != null) {
-+      if (_iterators[1].hasNext()) {
-+        return true;
-+      } else {
-+        _iterators[1] = null;
-+      }
-+    }
-+    return false;
-+  }
-+
-+  /**
-+   * Retrieve the next {@link TokenizerProperty} in this enumeration. 
-+   *
-+   * @return  the next keyword as a <code>TokenizerProperty</code>
-+   */
-+  public Object next() {
-+    if (hasNext()) {
-+      if (_iterators[0] != null) {
-+        return _iterators[0].next();
-+      } else {
-+        return _iterators[1].next();
-+      }
-+    }
-+    return null;
-+  }
-+  
-+  /**
-+   * This method is similar to {@link Tokenizer#removeKeyword}
-+   */
-+  public void remove() {
-+    if (_iterators[0] != null) {
-+      _iterators[0].remove();
-+    } else {
-+      _iterators[1].remove();
-+    }
-+  }
-+
-+  // members
-+  private Iterator[] _iterators = new Iterator[2];
-+}
-+
-+
-+
-+/**
-+ * Iterator for comments.
-+ * Instances of this inner class are returned when a call to one of the methods
-+ *<ul><li>
-+ *    {@link #getBlockComments}
-+ *</li><li>
-+ *    {@link #getLineComments}
-+ *</li><li>
-+ *    {@link #getStrings}
-+ *</li><li>
-+ *    {@link #getSpecialSequences}
-+ *</li></ul>
-+ * is done. Each element of the enumeration contains a {@link TokenizerProperty}
-+ * element, that in turn has the comment, special sequence etc. together with
-+ * its companion
-+ */
-+final class SpecialSequencesIterator implements Iterator {
-+
-+  /**
-+   * constructor taking the calling <code>Tokenizer</code> and the type of the
-+   * {@link TokenizerProperty}.
-+   *
-+   * @param parent  the calling tokenizer
-+   * @param type    type of the <code>TokenizerProperty</code> 
-+   */
-+  public SpecialSequencesIterator(AbstractTokenizer parent, int type) {
-+    _type      = type;
-+    _arrays[0] = parent._sequences[0];
-+    _arrays[1] = parent._sequences[1];
-+  }
-+
-+  /**
-+   * Checking for the next element in a special sequence list, that has the
-+   * required type. This method is the one that ultimately decides if there are
-+   * more elements or not.
-+   *
-+   * @return <code>true</code> if there is a matching {@link TokenizerProperty}
-+   *         element, <code>false</code> otherwise
-+   */
-+  private boolean listHasNext() {
-+    while (_currentElem != null) {
-+      if (_currentElem._property.getType() == _type) {
-+        return true;
-+      }
-+      _currentElem = _currentElem._next;
-+    }
-+    return false;
-+  }
-+
-+  /**
-+   * the well known method from the {@link java.util.Iterator} interface.
-+   *
-+   * @return <code>true</code> if there are more {@link TokenizerProperty}
-+   *         elements, <code>false</code> otherwise
-+   */
-+  public boolean hasNext() {
-+    // simple: check the current list for a successor
-+    if (listHasNext()) {
-+      return true;
-+    }
-+
-+    // which is the current array ?
-+    SortedArray array = null;
-+
-+    if (_arrays[0] != null) {
-+      array = _arrays[0];
-+    } else {
-+      array = _arrays[1];
-+    }
-+
-+    // check the current array 
-+    if (array != null) {
-+      int size = array.size();        
-+
-+      while (++_currentIndex < size) {
-+        _currentElem = array.get(_currentIndex);
-+        if (listHasNext()) {
-+          return true;
-+        }
-+      }
-+
-+      // possible to switch to the no-case array ?
-+      if (array == _arrays[0]) {
-+        _arrays[0]    = null;
-+        _currentElem  = null;
-+        _currentIndex = -1;
-+        return hasNext();
-+      }
-+    }
-+
-+    // no (more) sequences
-+    return false;
-+  }
-+
-+  /**
-+   * Retrieve the next {@link TokenizerProperty} in this enumeration.
-+   *
-+   * @return a {@link TokenizerProperty} of the desired type or <code>null</code>
-+   */
-+  public Object next() {
-+    if (! hasNext()) {
-+      return null;
-+    } else {
-+      TokenizerProperty prop = _currentElem._property;
-+      _currentElem = _currentElem._next;
-+      return prop;
-+    }
-+  }
-+  
-+  /**
-+   * Remove the current special sequence entry from the collection. This is an
-+   * alternative to {@link Tokenizer#removeSpecialSequence}.
-+   */
-+  public void remove() {
-+    // which is the current array ?
-+    SortedArray array = null;
-+
-+    if (_arrays[0] != null) {
-+      array = _arrays[0];
-+    } else {
-+      array = _arrays[1];
-+    }
-+
-+    try {
-+      TokenizerProperty prop = _currentElem._property;
-+      
-+      _currentElem = _currentElem._next;
-+      array.searchBinary(prop.getValues()[0], 0, true);
-+    } catch (Exception ex) {
-+      throw new ExtRuntimeException(ex, "While trying to remove current element of a SpecialSequencesIterator.");
-+    }
-+  }
-+
-+
-+  // members
-+  private SortedArray[]   _arrays       = new SortedArray[2];
-+  private SpecialSequence _currentElem  = null;
-+  private int             _currentIndex = -1;
-+  private int             _type         = Token.UNKNOWN;
-+}
-diff --git a/susebox/java/util/InputStreamTokenizer.class b/susebox/java/util/InputStreamTokenizer.class
-new file mode 100644
-index 0000000..2cc4fa0
-Binary files /dev/null and b/susebox/java/util/InputStreamTokenizer.class differ
-diff --git a/susebox/java/util/InputStreamTokenizer.java b/susebox/java/util/InputStreamTokenizer.java
-new file mode 100644
-index 0000000..6ba6848
---- /dev/null
-+++ b/susebox/java/util/InputStreamTokenizer.java
-@@ -0,0 +1,183 @@
-+/*
-+ * InputStreamTokenizer.java: Implementation of a Tokenizer for input streams.
-+ *
-+ * Copyright (C) 2001 Heiko Blau
-+ *
-+ * This file belongs to the Susebox Java Core Library (Susebox JCL).
-+ * The Susebox JCL is free software; you can redistribute it and/or modify it 
-+ * under the terms of the GNU Lesser General Public License as published by the 
-+ * Free Software Foundation; either version 2.1 of the License, or (at your 
-+ * option) any later version.
-+ *
-+ * This software is distributed in the hope that it will be useful, but WITHOUT
-+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or 
-+ * FITNESS FOR A PARTICULAR PURPOSE. 
-+ * See the GNU Lesser General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU Lesser General Public License along
-+ * with the Susebox JCL. If not, write to the
-+ *
-+ *   Free Software Foundation, Inc.
-+ *   59 Temple Place, Suite 330, 
-+ *   Boston, MA 02111-1307 
-+ *   USA
-+ *
-+ * or check the Internet: http://www.fsf.org
-+ *
-+ * Contact:
-+ *   email: heiko@susebox.de 
-+ */
-+
-+package de.susebox.java.util;
-+
-+//-----------------------------------------------------------------------------
-+// Imports
-+//
-+import java.io.Reader;
-+import java.io.InputStreamReader;
-+
-+
-+//-----------------------------------------------------------------------------
-+// Class InputStreamTokenizer
-+//
-+
-+/**<p>
-+ * The class extends the {@link AbstractTokenizer} and provides the {@link Tokenizer}
-+ * functionality for {@link java.io.Reader} sources, e.g. {@link java.io.InputStreamReader}
-+ * or {@link java.io.StringReader}.
-+ *</p><p>
-+ * The name is somewhat misleading since the class does actually work with 
-+ * every <code>Reader</code> implementation, but {@link java.io.InputStreamReader} 
-+ * are probably the most important ones.
-+ *</p>
-+ *
-+ * @see     Tokenizer
-+ * @see     AbstractTokenizer
-+ * @see     java.io.Reader
-+ * @see     java.io.InputStreamReader
-+ * @author  Heiko Blau
-+ */
-+public class InputStreamTokenizer extends AbstractTokenizer {
-+  
-+  //---------------------------------------------------------------------------
-+  // Abstract methods
-+  //
-+  
-+  /**
-+   * Implements the abstract method {@link AbstractTokenizer#read} by wrapping 
-+   * the {@link java.io.InputStreamReader#read} call of the JDK standard class
-+   * {@link java.io.InputStreamReader}.
-+   *
-+   * @param cbuf      buffer to receive data
-+   * @param offset    position from where the data should be inserted in <CODE>cbuf</CODE>
-+   * @param maxChars  maximum number of characters to be read into <CODE>cbuf</CODE>
-+   * @return actually read characters or -1 on an end-of-file condition
-+   * @throws Exception anything that could happen during read, most likely {@link java.io.IOException}
-+   */
-+  protected int read(char[] cbuf, int offset, int maxChars) throws Exception {
-+    if (_reader != null) {
-+      return _reader.read(cbuf, offset, maxChars);
-+    } else {
-+      return -1;
-+    }
-+  }
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // Constructors
-+  //
-+  
-+  /**
-+   * Default constructor. Standard input {@link java.lang.System#in} is used
-+   * to construct the input stream reader.
-+   */  
-+  public InputStreamTokenizer() {
-+    this(null, 0);
-+  }
-+
-+  /**
-+   * Constructor that takes a instantiated {@link java.io.InputStream}. If 
-+   * <CODE>null</CODE> is given then standard input is used ({@link java.lang.System#in}.
-+   *
-+   * @param Reader   input stream to be used for reading
-+   * @see   java.lang.InputStream
-+   */
-+  public InputStreamTokenizer(Reader reader) {
-+    this(reader, 0);
-+  }
-+  
-+  /**
-+   * Constructor that takes a instantiated {@link java.io.InputStream} and the
-+   * tokenizer control flags.
-+   * If <CODE>null</CODE> is given for the stream then standard input is used 
-+   * ({@link java.lang.System#in}.
-+   * For the tokenizer control flags use a combination of the <CODE>F_...</CODE>
-+   * constants from the {@link Tokenizer} for this parameter.
-+   *
-+   * @param reader   input stream to be used for reading
-+   * @param flags    tokenizer control flags
-+   * @see   java.lang.InputStream
-+   * @see   Tokenizer
-+   */
-+  public InputStreamTokenizer(Reader reader, int flags) {
-+    super(flags);
-+    
-+    setSource((reader != null) ? reader : new InputStreamReader(System.in));
-+  }
-+  
-+  
-+  /**
-+   * Constructor that takes a instantiated {@link java.io.InputStream}, the
-+   * tokenizer control flags, whitespace and separator strings.
-+   * If <CODE>null</CODE> is given for the stream then standard input is used 
-+   * ({@link java.lang.System#in}.
-+   * For the tokenizer control flags use a combination of the <CODE>F_...</CODE>
-+   * constants from the {@link Tokenizer} for this parameter.
-+   *
-+   * @param reader      input stream to be used for reading
-+   * @param flags       tokenizer control flags
-+   * @param whitespaces the whitespace set
-+   * @param separators  the set of separating characters
-+   * @see   java.lang.InputStream
-+   * @see   Tokenizer
-+   */
-+  public InputStreamTokenizer(Reader reader, int flags, String whitespaces, String separators) {
-+    super(flags);
-+    
-+    setSource((reader != null) ? reader : new InputStreamReader(System.in));
-+  }
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // Getter and setter
-+  //
-+  
-+  /** 
-+   * Setting the source for the tokenizer. Note that any data read from a previous
-+   * source are lost. Position, line and column counting will start from 0.
-+   * With this method it is possible to use one tokenizer on more than one
-+   * source. A common example is a list of files that are to be processed.
-+   *
-+   * @param reader    the new source for the {@link #read} method
-+   */
-+  public void setSource(Reader reader) {
-+    _reader = reader;
-+    reset();
-+  }
-+  
-+  /**
-+   * Retrieving the current source. Note that the Tokenizer probably read ahead a
-+   * huge part or even all data from this source.
-+   *
-+   * @return the current source of the tokenizer
-+   */
-+  public Reader getSource() {
-+    return _reader;
-+  }
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // Members
-+  //
-+  protected Reader _reader = null;
-+}
-diff --git a/susebox/java/util/KeywordIterator.class b/susebox/java/util/KeywordIterator.class
-new file mode 100644
-index 0000000..81d7929
-Binary files /dev/null and b/susebox/java/util/KeywordIterator.class differ
-diff --git a/susebox/java/util/SortedArray.class b/susebox/java/util/SortedArray.class
-new file mode 100644
-index 0000000..80faaf3
-Binary files /dev/null and b/susebox/java/util/SortedArray.class differ
-diff --git a/susebox/java/util/SpecialSequence.class b/susebox/java/util/SpecialSequence.class
-new file mode 100644
-index 0000000..1b16ddf
-Binary files /dev/null and b/susebox/java/util/SpecialSequence.class differ
-diff --git a/susebox/java/util/SpecialSequencesIterator.class b/susebox/java/util/SpecialSequencesIterator.class
-new file mode 100644
-index 0000000..dd327d6
-Binary files /dev/null and b/susebox/java/util/SpecialSequencesIterator.class differ
-diff --git a/susebox/java/util/Token.class b/susebox/java/util/Token.class
-new file mode 100644
-index 0000000..e084959
-Binary files /dev/null and b/susebox/java/util/Token.class differ
-diff --git a/susebox/java/util/Token.java b/susebox/java/util/Token.java
-new file mode 100644
-index 0000000..cc1ffad
---- /dev/null
-+++ b/susebox/java/util/Token.java
-@@ -0,0 +1,401 @@
-+/*
-+ * Token.java: Token for parsers etc.
-+ *
-+ * Copyright (C) 2001 Heiko Blau
-+ *
-+ * This file belongs to the Susebox Java Core Library (Susebox JCL).
-+ * The Susebox JCL is free software; you can redistribute it and/or modify it 
-+ * under the terms of the GNU Lesser General Public License as published by the 
-+ * Free Software Foundation; either version 2.1 of the License, or (at your 
-+ * option) any later version.
-+ *
-+ * This software is distributed in the hope that it will be useful, but WITHOUT
-+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or 
-+ * FITNESS FOR A PARTICULAR PURPOSE. 
-+ * See the GNU Lesser General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU Lesser General Public License along
-+ * with the Susebox JCL. If not, write to the
-+ *
-+ *   Free Software Foundation, Inc.
-+ *   59 Temple Place, Suite 330, 
-+ *   Boston, MA 02111-1307 
-+ *   USA
-+ *
-+ * or check the Internet: http://www.fsf.org
-+ *
-+ * Contact:
-+ *   email: heiko@susebox.de 
-+ */
-+
-+package de.susebox.java.util;
-+
-+//-----------------------------------------------------------------------------
-+// Class Token
-+//
-+
-+/** 
-+ * Instances of this class are created by the classes implementing the 
-+ * {@link Tokenizer} interface.
-+ * <CODE>Token</CODE> describes a portion of text according to the settings given
-+ * to the producing {@link Tokenizer}. Beside the token type the token image 
-+ * itself, its position in the input stream, line and column position and 
-+ * associated informations can be obtained from the <CODE>Token</CODE>.
-+ *
-+ * @author Heiko Blau
-+ * @see Tokenizer
-+ */
-+public class Token {
-+  
-+  //---------------------------------------------------------------------------
-+  // constants (token types)
-+  //
-+
-+  /**
-+   * The token is nothing special (no keyword, no whitespace, etc.).
-+   */  
-+  public static final int NORMAL = 0;
-+
-+  /**
-+   * The token is a keyword registered with the used {@link Tokenizer}.
-+   */  
-+  public static final int KEYWORD = 1;
-+
-+  /**
-+   * The token is one of the quoted strings known to the {@link Tokenizer}. In Java
-+   * this would be for instance a "String" or a 'c' (haracter).
-+   */  
-+  public static final int STRING = 2;
-+  
-+  /**
-+   * If a {@link Tokenizer} recognizes numbers, this token is one.
-+   */  
-+  public static final int NUMBER = 3;
-+  
-+  /**
-+   * Special sequences are characters or character combinations that have a certain
-+   * meaning to the parsed language or dialect. In computer languages we have for
-+   * instance operators, end-of-statement characters etc.
-+   * A companion might have been associated with a special sequence. It probably
-+   * contains information important to the user of the <CODE>Token</CODE>.
-+   */  
-+  public static final int SPECIAL_SEQUENCE = 4;
-+  
-+  /** 
-+   * Separators are otherwise not remarkable characters. An opening parenthesis 
-+   * might be nessecary for a syntactically correct text, but without any special 
-+   * meaning to the compiler, interpreter etc. after it has been detected.
-+   */  
-+  public static final int SEPARATOR = 5;
-+  
-+  /** 
-+   * Whitespaces are portions of the text, that contain one or more characters 
-+   * that separate the significant parts of the text. Generally, a sequence of 
-+   * whitespaces is equally represented by one single whitespace character. That 
-+   * is the difference to separators.
-+   */  
-+  public static final int WHITESPACE = 6;
-+
-+  /**
-+   * Although a line comment is - in most cases - actually a whitespace sequence, it
-+   * is often nessecary to handle it separately. Syntax hilighting is a thing that
-+   * needs to know a line comment.
-+   */  
-+  public static final int LINE_COMMENT = 7;
-+
-+  /**
-+   * Block comments are also a special form of a whitespace sequence. See 
-+   * {@link #LINE_COMMENT} for details.
-+   */  
-+  public static final int BLOCK_COMMENT = 8;
-+
-+  /**
-+   * A token of the type <CODE>EOF</CODE> is used to indicate an end-of-line condition
-+   * on the input stream of the tokenizer.
-+   */  
-+  public static final int EOF = -1;
-+  
-+  /**
-+   * This is for the leftovers of the lexical analysis of a text.
-+   */  
-+  public static final int UNKNOWN = -2;
-+    
-+
-+  //---------------------------------------------------------------------------
-+  // Getter- und Setter-Methoden
-+  //
-+  
-+  /**
-+   * Setting the type property of the <CODE>Token</CODE>. This is one of the constants
-+   * defined in this class.
-+   *
-+   * @param type the token type
-+   */  
-+  public void setType(int type) {
-+    _type = type;
-+  }
-+    
-+  /**
-+   * Obtaining the type of the <CODE>Token</CODE>. This is one of the constants
-+   * defined in the <CODE>Token</CODE> class.
-+   *
-+   * @return the token type
-+   */  
-+  public int getType() {
-+    return _type;
-+  }
-+    
-+  /**
-+   * Setting the token image. Note that some {@link Tokenizer} only fill position and
-+   * length information rather than setting the token image. This strategy might have
-+   * a tremendous influence on the parse performance and the memory allocation.
-+   *
-+   * @param token the token image
-+   */  
-+  public void setToken(String token) {
-+    if ((_token = token) == null) {
-+      _length = 0;
-+    } else {
-+      _length = _token.length();
-+    }
-+  }
-+    
-+  /**
-+   * Obtaining the token image as a String.
-+   * @return the token image as a {@link java.lang.String}.
-+   */  
-+  public String getToken() {
-+    return _token;
-+  }
-+    
-+  /**
-+   * Setting the length of the token. Some {@link Tokenizer} may prefer or may be
-+   * configured not to return a token image, but only the position and length
-+   * informations. This may save a lot of time whereever only a subset of the found
-+   * tokens are actually needed by the user.
-+   *
-+   * @param length the length of the token
-+   */  
-+  public void setLength(int length) {
-+    _length = length;
-+  }
-+    
-+  /**
-+   * Obtaining the length of the token. Note that some token types have a zero length
-+   * (like EOF or UNKNOWN).
-+   *
-+   * @return the length of the token.
-+   */  
-+  public int getLength() {
-+    return _length;
-+  }
-+    
-+  /**
-+   * Some token may have associated informations for the user of the <CODE>Token</CODE>.
-+   * A popular thing would be the association of an integer constant to a special
-+   * sequence or keyword to be used in fast <CODE>switch</CODE> statetents.
-+   *
-+   * @param companion the associated information for this token
-+   */  
-+  public void setCompanion(Object companion) {
-+    _companion = companion;
-+  }
-+    
-+  /**
-+   * Obtaining the associated information of the token. Can be <CODE>null</CODE>. See
-+   * {@link #setCompanion} for details.
-+   *
-+   * @return the associated information of this token
-+   */  
-+  public Object getCompanion() {
-+    return _companion;
-+  }
-+  
-+  /**
-+   * Setting the start position of the token relative to the start of the input 
-+   * stream. For instance, the first character in a file has the start position 
-+   * 0.
-+   *
-+   * @param startPosition the position where the token starts in the input stream.
-+   */  
-+  public void setStartPosition(int startPosition) {
-+    _startPosition = startPosition;
-+  }
-+    
-+  /**
-+   * Obtaining the starting position of the token.
-+   *
-+   * @return  start position of the token.
-+   * @see     #setStartPosition
-+   */  
-+  public int getStartPosition() {
-+    return _startPosition;
-+  }
-+    
-+  /**
-+   * In {@link Tokenizer}'s counting lines and columns, this method is used to 
-+   * set the line number where the beginning of the <CODE>Token</CODE> was found.
-+   * Line numbers start with 0.
-+   *
-+   * @param lineno line number where the token begins
-+   */  
-+  public void setStartLine(int lineno) {
-+    _startLine = lineno;
-+  }
-+    
-+  /**
-+   * Obtaining the line number where the <CODE>Token</CODE> starts. See also
-+   * {@link #setStartLine} for details.<br>
-+   * If a tokenizer doesn't count lines and columns, the returned value is -1.
-+   *
-+   * @return  the line number where the token starts or -1, if no line counting is
-+   *          performed
-+   * @see     #setStartLine
-+   */  
-+  public int getStartLine() {
-+    return _startLine;
-+  }
-+    
-+  /**
-+   * In {@link Tokenizer}'s counting lines and columns, this method is used to 
-+   * set the column number where the beginning of the <CODE>Token</CODE> was 
-+   * found. Column numbers start with 0.
-+   *
-+   * @param colno number where the token begins
-+   */  
-+  public void setStartColumn(int colno) {
-+    _startColumn = colno;
-+  }
-+    
-+  /**
-+   * Obtaining the column number of the <CODE>Token</CODE> start. See {@link #setStartColumn}
-+   * for details.<br>
-+   * If a tokenizer doesn't count lines and columns, the returned value is -1.
-+   *
-+   * @return  the column number where the token starts or -1, if no line counting 
-+   *          is performed
-+   * @see     #setStartColumn
-+   */  
-+  public int getStartColumn() {
-+    return _startColumn;
-+  }
-+    
-+  /**
-+   * In {@link Tokenizer}'s counting lines and columns, this method is used to 
-+   * set the line number where the end of the <CODE>Token</CODE> was found. 
-+   * See {@link #setStartLine} for more.<br>
-+   * The end line number is the one there the first character was found that does
-+   * <b><i>NOT</i></b> belongs to the token. This approach is choosen in accordance
-+   * to the toIndex parameters in {@link java.lang.String#substring(int, int)}.
-+   *
-+   * @param lineno line number where the token ends
-+   */  
-+  public void setEndLine(int lineno) {
-+    _endLine = lineno;
-+  }
-+    
-+  /**
-+   * Obtaining the line number where the token ends. See {@link #setEndLine} for 
-+   * more. If a tokenizer doesn't count lines and columns, the returned value is 
-+   * -1.
-+   *
-+   * @return  line number where the token ends or -1, if no line counting is
-+   *          performed
-+   * @see     #setEndLine
-+   */  
-+  public int getEndLine() {
-+    return _endLine;
-+  }
-+    
-+  /**
-+   * In {@link Tokenizer}'s counting lines and columns, this method is used to set the
-+   * column number where the end of the <CODE>Token</CODE> was found.<br>
-+   * The end column number is the one of the first character that does
-+   * <b><i>NOT</i></b> belongs to the token. This approach is choosen in accordance
-+   * to the toIndex parameters in {@link java.lang.String#substring(int, int)}.
-+   *
-+   * @param colno column number where the token ends
-+   */  
-+  public void setEndColumn(int colno) {
-+    _endColumn = colno;
-+  }
-+    
-+  /**
-+   * Obtaining the column number where the <CODE>Token</CODE> ends. See {@link #setEndColumn}
-+   * for more.<br>
-+   * If a tokenizer doesn't count lines and columns, the returned value is -1.
-+   *
-+   * @return  column number where the token ends or -1, if no line counting is
-+   *          performed
-+   * @see     #setEndColumn
-+   */  
-+  public int getEndColumn() {
-+    return _endColumn;
-+  }
-+    
-+ 
-+  //---------------------------------------------------------------------------
-+  // construction
-+  //
-+  
-+  /**
-+   * Default constructor.
-+   */  
-+  public Token() {
-+    this(UNKNOWN, null, null);
-+  }
-+  
-+  /**
-+   * Constructs a token of a given type. Only the type of the token is known but not
-+   * its image or positions.
-+   *
-+   * @param type token type, one of the class constants.
-+   */  
-+  public Token(int type) {
-+    this(type, null, null);
-+  }
-+  
-+  /**
-+   * Construct a token of a given type with the given image. No position information
-+   * is given.
-+   *
-+   * @param type token type, one of the class constants.
-+   * @param token the token image itself
-+   */  
-+  public Token(int type, String token) {
-+    this(type, token, null);
-+  }
-+  
-+  /**
-+   * Construct a token of a given type with the given image and a companion. This
-+   * constructor is most useful for keywords or special sequences.
-+   *
-+   * @param type token type, one of the class constants.
-+   * @param token the token image itself
-+   * @param companion an associated information of the token type
-+   */  
-+  public Token(int type, String token, Object companion) {
-+    setType(type);
-+    setToken(token);
-+    setCompanion(companion);
-+    setStartPosition(-1);
-+    setStartLine(-1);
-+    setStartColumn(-1);
-+    setEndLine(-1);
-+    setEndColumn(-1);
-+  }
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // members
-+  //
-+  protected int     _type;
-+  protected String  _token;
-+  protected int     _length;
-+  protected Object  _companion;
-+  protected int     _startPosition;
-+  protected int     _startLine;
-+  protected int     _startColumn;
-+  protected int     _endLine;
-+  protected int     _endColumn;
-+}
-diff --git a/susebox/java/util/Tokenizer.class b/susebox/java/util/Tokenizer.class
-new file mode 100644
-index 0000000..45f9714
-Binary files /dev/null and b/susebox/java/util/Tokenizer.class differ
-diff --git a/susebox/java/util/Tokenizer.java b/susebox/java/util/Tokenizer.java
-new file mode 100644
-index 0000000..b74333b
---- /dev/null
-+++ b/susebox/java/util/Tokenizer.java
-@@ -0,0 +1,985 @@
-+/*
-+ * Tokenizer.java: lexical parser interface.
-+ *
-+ * Copyright (C) 2001 Heiko Blau
-+ *
-+ * This file belongs to the Susebox Java Core Library (Susebox JCL).
-+ * The Susebox JCL is free software; you can redistribute it and/or modify it 
-+ * under the terms of the GNU Lesser General Public License as published by the 
-+ * Free Software Foundation; either version 2.1 of the License, or (at your 
-+ * option) any later version.
-+ *
-+ * This software is distributed in the hope that it will be useful, but WITHOUT
-+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or 
-+ * FITNESS FOR A PARTICULAR PURPOSE. 
-+ * See the GNU Lesser General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU Lesser General Public License along
-+ * with the Susebox JCL. If not, write to the
-+ *
-+ *   Free Software Foundation, Inc.
-+ *   59 Temple Place, Suite 330, 
-+ *   Boston, MA 02111-1307 
-+ *   USA
-+ *
-+ * or check the Internet: http://www.fsf.org
-+ *
-+ * Contact:
-+ *   email: heiko@susebox.de 
-+ */
-+
-+package de.susebox.java.util;
-+
-+//-----------------------------------------------------------------------------
-+// Imports
-+//
-+import java.util.Iterator;
-+
-+
-+//-----------------------------------------------------------------------------
-+// Interface Tokenizer
-+//
-+
-+/**<p>
-+ * The interface <CODE>Tokenizer</CODE> contains parse operations, control flags 
-+ * and comment, keyword and special sequence support. It is designed to 
-+ * enable a common approach for parsing texts like program code, annotated 
-+ * documents like HTML and so on.
-+ *</p><p>
-+ * To detect links in an HTML document, a tokenizer would be invoked like that:
-+ *<blockquote><pre>
-+ *
-+ * Vector    links     = new Vector();
-+ * Tokenizer tokenizer = new MyTokenizer();
-+ * Token     token;
-+ *
-+ * tokenizer.setParseFlags(Tokenizer.F_NO_CASE);
-+ * tokenizer.setSeparators("=");
-+ * tokenizer.addString("\"", "\"", "\\");
-+ * tokenizer.addBlockComment("&gt;", "&lt;");
-+ * tokenizer.addKeyword("HREF");
-+ *
-+ * while (tokenizer.hasMoreToken()) {
-+ *   token = tokenizer.nextToken();
-+ *   if (token.getType() == Token.KEYWORD) {
-+ *     tokenizer.nextToken();               // should be the '=' character
-+ *     links.addElement(tokenizer.next());
-+ *   }
-+ * }
-+ *
-+ *</pre></blockquote>
-+ * This is somewhat rough way to find links should work fine on syntactically
-+ * correct HTML code. It finds common links as well as mail, ftp links etc. Note
-+ * the block comment. It starts with the "&gt;" character, that is the closing
-+ * character for HTML tags and ends with the "&lt;" being the starting character
-+ * of HTML tags. The effect is that all the real text is treated as a comment.
-+ *</p><p>
-+ * To extract the contents of a HTML file, one would do:
-+ *<blockquote><pre>
-+ *
-+ * StringBuffer  contents  = new StringBuffer(4096);
-+ * Tokenizer     tokenizer = new MyTokenizer();
-+ * Token         token;
-+ *
-+ * tokenizer.setParseFlags(Tokenizer.F_NO_CASE);
-+ * tokenizer.addBlockComment("&gt;", "&lt;");
-+ * tokenizer.addBlockComment("&gt;HEAD&lt;", "&gt;/HEAD&lt;");
-+ * tokenizer.addBlockComment("&gt;!--;", "--&lt;");
-+ *    
-+ * while (tokenizer.hasMoreToken()) {
-+ *   token = tokenizer.nextToken();
-+ *   if (token.getType() != Token.BLOCK_COMMENT) {
-+ *     contents.append(token.getToken());
-+ *   }
-+ * }
-+ *
-+ *</pre></blockquote>
-+ * Here the block comment is the exact opposite of the first example. Now all the
-+ * HTML tags are skipped. Moreover, we declared the HTML-Header as a block
-+ * comment as well - the informations from the header are thus skipped alltogether.
-+ *</p><p>
-+ * Parsing (tokenizing) is done on a well defined priority scheme. See 
-+ * {@link #nextToken} for details.
-+ *</p><p>
-+ * NOTE: if a character sequence is registered for two categories of tokenizer
-+ * properties (e.g. as a line comments starting sequence as well as a special
-+ * sequence), the category with the highest priority wins (e.g. if the metioned
-+ * sequence is found, it is interpreted as a line comment). 
-+ *</p><p>
-+ * The tokenizer interface is clearly designed for "readable" data, say ASCII-
-+ * or UNICODE data. Parsing binary data has other characteristics that do not
-+ * nessecarily fit in a scheme of comments, keywords, strings, identifiers and 
-+ * operators.
-+ *</p>
-+ *
-+ * @see     Token
-+ * @see     TokenizerProperty
-+ * @see     AbstractTokenizer
-+ * @see     InputStreamTokenizer
-+ * @author  Heiko Blau
-+ */
-+public interface Tokenizer
-+{
-+  //---------------------------------------------------------------------------
-+  // default character classes
-+  //
-+  
-+  /** 
-+   * Whitespaces are portions of the text, that contain one or more characters 
-+   * that separate the significant parts of the text. Generally, a sequence of 
-+   * whitespaces is equally represented by one single whitespace character. That 
-+   * is the difference to separators.
-+   */  
-+  public static final String DEFAULT_WHITESPACES = " \t\r\n";
-+  
-+  /** 
-+   * Separators are otherwise not remarkable characters. An opening parenthesis 
-+   * might be nessecary for a syntactically correct text, but without any special 
-+   * meaning to the compiler, interpreter etc. after it has been detected.
-+   */  
-+  public static final String DEFAULT_SEPARATORS = "\u0021\u0023-\u002f\u003a-\u0040\u005b-\u005e\u0060\u007b-\u007e";
-+  
-+  /**
-+   * Default starting sequence of a block comment (Java, C/C++).
-+   */  
-+  public static final String DEFAULT_BLOCK_COMMENT_START = "/*";
-+
-+  /**
-+   * Default end sequence of a block comment (Java, C/C++).
-+   */  
-+  public static final String DEFAULT_BLOCK_COMMENT_END = "*/";
-+  
-+  /**
-+   * Default line comment seqence (Java, C++)
-+   */  
-+  public static final String DEFAULT_LINE_COMMENT = "//";
-+  
-+  /**
-+   * The well-known string starting sequence of C/C++, Java and other languages.
-+   */  
-+  public static final String DEFAULT_STRING_START  = "\"";
-+  
-+  /**
-+   * The well-known string ending sequence of C/C++, Java and other languages.
-+   */  
-+  public static final String DEFAULT_STRING_END    = DEFAULT_STRING_START;
-+  
-+  /**
-+   * The well-known escape sequence for strings in C/C++, Java and other languages.
-+   */  
-+  public static final String DEFAULT_STRING_ESCAPE = "\\";
-+  
-+  /**
-+   * The well-known character starting sequence of C/C++, Java and other languages.
-+   */  
-+  public static final String DEFAULT_CHAR_START  = "'";
-+  
-+  /**
-+   * The well-known character ending sequence of C/C++, Java and other languages.
-+   */  
-+  public static final String DEFAULT_CHAR_END    = DEFAULT_CHAR_START;
-+
-+  /**
-+   * The well-known escape sequence for character literals in C/C++, Java and other
-+   * languages.
-+   */  
-+  public static final String DEFAULT_CHAR_ESCAPE = DEFAULT_STRING_ESCAPE;
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // common control flags
-+  //
-+  
-+  /**
-+   * General compare operations are case-sensitive, that means 'A' equals 'A' 
-+   * but not 'a'.<br>
-+   * Without this flag, comparison is done like in Java or C/C++. When the flag 
-+   * is set, the tokenizer compares tokens like in HTML or PL/SQL.
-+   */
-+  public static final int F_NO_CASE               = 0x0001;
-+
-+  /**
-+   * In case that the <CODE>F_NO_CASE</CODE> flag is set, this flag is used to
-+   * alter the behaviour of the tokenizer for keyword comparison.
-+   * The combination between <CODE>F_NO_CASE</CODE> and <CODE>F_KEYWORDS_CASE</CODE>
-+   * means, that keywords are case-sensitive but everything else is not.
-+   */
-+  public static final int F_KEYWORDS_CASE         = 0x0002;
-+  
-+  /**
-+   * In case that the <CODE>F_NO_CASE</CODE> flag is not set, this flag is used 
-+   * to alter the behaviour of the tokenizer for keyword comparison.
-+   * The flag <CODE>F_KEYWORDS_NO_CASE</CODE> means, that keywords are not 
-+   * case-sensitive but everything else is.
-+   */
-+  public static final int F_KEYWORDS_NO_CASE      = 0x0004;
-+  
-+  /**
-+   * In many cases, parsers are not interested in whitespaces. If You are, use
-+   * this flag to force the tokenizer to return whitespace sequences as a token.
-+   */
-+  public static final int F_RETURN_WHITESPACES    = 0x0008;
-+  
-+  /**
-+   * For perfomance and memory reasons, this flag is used to avoid copy operations
-+   * for every token. The token image itself is not returned in a {@link Token}
-+   * instance, only its position and length in the input stream.
-+   */
-+  public static final int F_TOKEN_POS_ONLY        = 0x0010;
-+
-+  /**
-+   * Set this flag to let the tokenizer buffer all data. Normally, a tokenizer
-+   * keeps only a certain amount of periodically changing data in its internal 
-+   * buffer.
-+   */
-+  public static final int F_KEEP_DATA             = 0x0020;
-+
-+  /**
-+   * Tells the tokenizer to count lines and columns. The tokenizer may use
-+   * System.getProperty("line.separator") to obtain the end-of-line sequence.
-+   */
-+  public static final int F_COUNT_LINES           = 0x0040;
-+
-+  /**
-+   * Nested block comments are normally not allowed. This flag changes the 
-+   * default behaviour
-+   */
-+  public static final int F_ALLOW_NESTED_COMMENTS = 0x0080;
-+  
-+  /**
-+   * With this flag, the tokenizer tries to identify numbers.
-+   */
-+  public static final int F_PARSE_NUMBERS         = 0x0100;
-+
-+
-+  //---------------------------------------------------------------------------
-+  // trivial property methods
-+  //
-+  
-+  /**
-+   * Setting the control flags of the <code>Tokenizer</code>. Use a combination
-+   * of the <code>F_...</code> flags for the parameter.
-+   * @param flags the parser control flags
-+   */
-+  public void setParseFlags(int flags);
-+
-+   /**
-+    * Retrieving the parser control flags. A bitmask containing the <code>F_...</code>
-+    * constants is returned.
-+    * @return the current parser control flags
-+    * @see #setParseFlags
-+    */
-+  public int getParseFlags();
-+  
-+  /**
-+   * Registering a string description. Strings are things like the primitive string 
-+   * literals in C/C++, SQL varchar literals, but also the character literals 
-+   * of C/C++ and Java.<br>
-+   * If the given string starting sequence is already known to the parser,
-+   * it will simply be re-registered. Using this method on a known string
-+   * with an associated companion will remove that companion.
-+   *
-+   * @param start     the starting sequence of a string
-+   * @param end       the finishing sequence of a string
-+   * @param escape    the escape sequence inside the string
-+   */
-+  public void addString(String start, String end, String escape);
-+
-+  /**
-+   * Registering a the sequences that are used for string-like text parts.
-+   * This method supports also an information associated with the string,
-+   * called the companion.<br>
-+   * If the given string starting sequence is already known to the parser,
-+   * it will simply be re-registered. Using this method on a known string
-+   * with an associated companion will replace that companion against the given
-+   * one.
-+   *
-+   * @param start     the starting sequence of a string
-+   * @param end       the finishing sequence of a string
-+   * @param escape    the escape sequence inside the string
-+   * @param companion the associated information
-+   */
-+  public void addString(String start, String end, String escape, Object companion);
-+  
-+  /**
-+   * Registering a the sequences that are used for string-like text parts.
-+   * This method supports also an information associated with the string,
-+   * called the companion.<br>
-+   * If the given string starting sequence is already known to the parser,
-+   * it will simply be re-registered. Using this method on a known string
-+   * with an associated companion will replace that companion against the given
-+   * one.
-+   * This version of <code>addString</code> supports a bitmask of the 
-+   * <code>F_...</code> flags to modify the general tokenizer settings (see
-+   * {@link #setParseFlags} for this special element.
-+   *
-+   * @param start     the starting sequence of a string
-+   * @param end       the finishing sequence of a string
-+   * @param escape    the escape sequence inside the string
-+   * @param companion the associated information
-+   * @param flags     modification flags 
-+   */
-+  public void addString(
-+    String start, 
-+    String end, 
-+    String escape, 
-+    Object companion, 
-+    int    flags
-+  );
-+  
-+  /**
-+   * Removing a string description.
-+   *
-+   * @param start     the starting sequence of a string
-+   */  
-+  public void removeString(String start);
-+  
-+  /**
-+   * Retrieving the information associated with a certain string. Only the 
-+   * starting sequence is nessecary to identify the string. If the string is not 
-+   * known to the parser, <CODE>null</CODE> will be returned.<br>
-+   * If one needs to know if a string exists without a companion or if the string
-+   * is unknown so far, use also the method {@link #stringExists}.
-+   *
-+   * @param start     the starting sequence of a string
-+   * @return the associated information or <CODE>null</CODE>
-+   */
-+  public Object getStringCompanion(String start);
-+  
-+  /**
-+   * Checks if the given starting sequence of the string is known to the parser.
-+   *
-+   * @param start     the starting sequence of a string
-+   * @return <CODE>true</CODE> if the string is registered, 
-+   *         <CODE>false</CODE> otherwise
-+   */
-+  public boolean stringExists(String start);
-+
-+  /**
-+   * This method returns an {@link java.util.Iterator} of {@link TokenizerProperty}
-+   * objects. Each <CODE>TokenizerProperty</CODE> object contains the starting,
-+   * finishing and escaping sequence of a string description and the companion if 
-+   * it exists.
-+   *
-+   * @return enumeration of {@link TokenizerProperty} objects
-+   */  
-+  public Iterator getStrings();
-+  
-+  /**
-+   * Setting the whitespace character set of the tokenizer. It is possible to
-+   * use ranges like "a-z" when more than two whitespace characters are
-+   * neighbours in the UNICODE character set.<br>
-+   * Whitespaces are sequences that have the same syntactical meaning as one
-+   * single whitespace character would have. That means "     " (many spaces) is
-+   * the same as " " (one space).
-+   *
-+   * @param whitespaces the whitespace set
-+   */
-+  public void setWhitespaces(String whitespaces);
-+  
-+  /**
-+   * Obtaining the whitespace character set. The set may contain ranges.
-+   *
-+   * @see #setWhitespaces
-+   * @return the currently active whitespace set
-+   */
-+  public String getWhitespaces();
-+  
-+  /**
-+   * Setting the separator set. This set may contain ranges. A range is a
-+   * character (lower limit) followed by a '-' (minus) followed by a
-+   * second character (upper limit). A range of "a-z" means: all characters in
-+   * the UNICODE character set between and including 'a' and 'z'. Ranges should
-+   * be used whenever possible since they speed up the parsing process.<br>
-+   * Separators are characters that are significant for the syntax. A sequence
-+   * of separators is <i>NOT</i> equal to one single separator. Thats the
-+   * difference to whitespaces.
-+   *
-+   * @param separators the set of separating characters
-+   */
-+  public void setSeparators(String separators);
-+  
-+  /**
-+   * Obtaining the separator set of the <code>Tokenizer</code>. The set may
-+   * contain ranges.
-+   *
-+   * @see #setSeparators
-+   * @return the currently used set of separating characters
-+   */
-+  public String getSeparators();
-+  
-+  /**
-+   * Registering a the starting sequence of a line comment. The line comment is
-+   * a special type of whitespace. It starts with the given character sequence
-+   * and contains all characters up to and including the next end-of-line
-+   * character(s).<br>
-+   * Although most languages have only one line comment sequence, it is possible
-+   * to use more than one.<br>
-+   * If the given line comment starting sequence is already known to the parser,
-+   * it will simply be re-registered. Using this method on a known line comment
-+   * with an associated companion will effectively remove the companion.
-+   *
-+   * @param lineComment the starting sequence of the line comment
-+   */
-+  public void addLineComment(String lineComment);
-+
-+  /**
-+   * Registering a the starting sequence of a line comment. The line comment is
-+   * a special type of whitespace. It starts with the given character sequence
-+   * and contains all characters up to and including the next end-of-line
-+   * character(s).<br>
-+   * Although most languages have only one line comment sequence, it is possible
-+   * to use more than one.<br>
-+   * This method supports also an information associated with the line comment,
-+   * called the companion.<br>
-+   * If the given line comment starting sequence is already known to the parser,
-+   * it will simply be re-registered. Using this method on a known line comment
-+   * with an associated companion will replace that companion against the given
-+   * one.
-+   *
-+   * @param lineComment the starting sequence of a line comment
-+   * @param companion the associated information
-+   */
-+  public void addLineComment(String lineComment, Object companion);
-+
-+  /**
-+   * Registering a the starting sequence of a line comment. The line comment is
-+   * a special type of whitespace. It starts with the given character sequence
-+   * and contains all characters up to and including the next end-of-line
-+   * character(s).<br>
-+   * Although most languages have only one line comment sequence, it is possible
-+   * to use more than one.<br>
-+   * This method supports also an information associated with the line comment,
-+   * called the companion.<br>
-+   * If the given line comment starting sequence is already known to the parser,
-+   * it will simply be re-registered. Using this method on a known line comment
-+   * with an associated companion will replace that companion against the given
-+   * one.<br>
-+   * This version of <code>addLineComment</code> supports a bitmask of the 
-+   * <code>F_...</code> flags to modify the general tokenizer settings (see
-+   * {@link #setParseFlags}) for this special element.
-+   *
-+   * @param lineComment the starting sequence of a line comment
-+   * @param companion the associated information
-+   * @param flags     modification flags 
-+   */
-+  public void addLineComment(String lineComment, Object companion, int flags);
-+  
-+  /**
-+   * Removing a certain line comment.
-+   *
-+   * @param lineComment the starting sequence of the line comment
-+   */  
-+  public void removeLineComment(String lineComment);
-+  
-+  /**
-+   * Retrieving the associated object of a certain line comment. If the given
-+   * starting sequence of a line comment is not known to the parser, then the
-+   * method returns <CODE>null</CODE>.<br>
-+   * To distinguish between an unknown line comment and companion-less line
-+   * comment, use the method {@link #lineCommentExists}.
-+   *
-+   * @param lineComment the starting sequence of the line comment
-+   * @return the object associated with the line comment
-+   */  
-+  public Object getLineCommentCompanion(String lineComment);
-+
-+  /**
-+   * Checks if the give line comment is known.
-+   *
-+   * @param lineComment the starting sequence of the line comment
-+   * @return <CODE>true</CODE> if the line comment is known, 
-+   *         <CODE>false</CODE> otherwise
-+   */  
-+  public boolean lineCommentExists(String lineComment);
-+  
-+  /**
-+   * This method returns an {@link java.util.Iterator} of {@link TokenizerProperty}
-+   * objects. Each <CODE>TokenizerProperty</CODE> object contains one starting
-+   * sequence of a line comment and the companion if it exists.
-+   *
-+   * @return enumeration of {@link TokenizerProperty} objects
-+   */  
-+  public Iterator getLineComments();
-+  
-+  /**
-+   * Registering a block comment with the parser. This version takes only the starting
-+   * and finishing sequence of the block comment.<br>
-+   * If the given starting sequence is already known to the parser, the block 
-+   * comment is simply re-registered. Using this method on a known block comment
-+   * with an associated companion will remove that companion.
-+   *
-+   * @param start the starting sequence of the block comment
-+   * @param end   the finishing sequence of the block comment
-+   */  
-+  public void addBlockComment(String start, String end);
-+  
-+  /**
-+   * Registering a block comment with the parser. Beside the obviously nessecary
-+   * starting and finishing sequence of the block comment, it takes an object that
-+   * is associated with the block comment, called the companion.<br>
-+   * If the given starting sequence is already known to the parser, the block
-+   * comment is simply re-registered. Using this method on a known block comment
-+   * with an associated companion will replace that companion against the given
-+   * one.
-+   *
-+   * @param start     the starting sequence of the block comment
-+   * @param end       the finishing sequence of the block comment
-+   * @param companion information object associated with this block comment
-+   */  
-+  public void addBlockComment(String start, String end, Object companion);
-+  
-+  /**
-+   * Registering a block comment with the parser. Beside the obviously nessecary
-+   * starting and finishing sequence of the block comment, it takes an object that
-+   * is associated with the block comment, called the companion.<br>
-+   * If the given starting sequence is already known to the parser, the block
-+   * comment is simply re-registered. Using this method on a known block comment
-+   * with an associated companion will replace that companion against the given
-+   * one.<br>
-+   * This version of <code>addBlockComment</code> supports a bitmask of the 
-+   * <code>F_...</code> flags to modify the general tokenizer settings (see
-+   * {@link #setParseFlags}) for this special element.
-+   *
-+   * @param start     the starting sequence of the block comment
-+   * @param end       the finishing sequence of the block comment
-+   * @param companion information object associated with this block comment
-+   * @param flags     modification flags 
-+   */
-+  public void addBlockComment(String start, String end, Object companion, int flags);
-+  
-+  /**
-+   * Removing a certain block comment. Only the starting sequence is nessecary
-+   * to identify the block comment.
-+   *
-+   * @param start the starting sequence of the block comment
-+   */  
-+  public void removeBlockComment(String start);
-+  
-+  /**
-+   * Retrieving a certain block comment. Only the starting sequence is nessecary
-+   * to identify the block comment. If the block comment is not known to the 
-+   * parser, then <CODE>null</CODE> is returned.<br>
-+   * To distinguish between an unknown line comment and companion-less line 
-+   * comment, use the method {@link #lineCommentExists}.
-+   *
-+   * @param start the starting sequence of the block comment
-+   * @return the associated object of the block comment
-+   */  
-+  public Object getBlockCommentCompanion(String start);
-+  
-+  /**
-+   * Checks if the give block comment is known. Only the starting sequence is 
-+   * nessecary to identify the block comment.
-+   *
-+   * @param start the starting sequence of the block comment
-+   * @return <CODE>true</CODE> if the block comment is known, 
-+   *         <CODE>false</CODE> otherwise
-+   */  
-+  public boolean blockCommentExists(String start);
-+  
-+  /**
-+   * This method returns an {@link java.util.Iterator} of {@link TokenizerProperty}
-+   * objects. Each <CODE>TokenizerProperty</CODE> object contains the starting and
-+   * finishing sequence of a block comment and the companion if it exists.
-+   *
-+   * @return enumeration of {@link TokenizerProperty} objects
-+   */  
-+  public Iterator getBlockComments();
-+  
-+  /**
-+   * Query the current row. The method can only be used if the flag <CODE>F_COUNTLINES</CODE>
-+   * has been set.
-+   * Without this flag being set, the return value is undefined.
-+   * Note that row counting starts with 0, while editors often use 1 for the first
-+   * row.
-+   *
-+   * @return current row (starting with 0)
-+   */
-+  public int getCurrentLine();
-+  
-+  /**
-+   * Retrieve the current column. The method can only be used if the flag <CODE>F_COUNTLINES</CODE>
-+   * has been set.
-+   * Without this flag being set, the return value is undefined.
-+   * Note that column counting starts with 0, while editors often use 1 for the first
-+   * column in one row.
-+   *
-+   * @return current column number (starting with 0)
-+   */
-+  public int getCurrentColumn();
-+  
-+
-+  //---------------------------------------------------------------------------
-+  // properties for sophisticated parser operations
-+  //
-+  
-+  /**
-+   * Registering a special sequence of characters. Such sequences may be multicharacter
-+   * operators like the shift operators in Java.
-+   * Unlike keywords, special sequences act also as separators between other tokens.
-+   * If one special sequence is the prefix of other special sequences (in Java the
-+   * shift operator <CODE>&gt;&gt;</CODE> is the prefix of the shift operator
-+   * <CODE>&gt;&gt;&gt;</CODE>), always the longest possible match is returned.
-+   * Testing on special sequences takes place after whitespaces and comments are ruled
-+   * out, but before ordinary separators are tested.
-+   *
-+   * @param specSeq   special sequence to register
-+   * @see   #addKeyword
-+   * @see   #setSeparators
-+   */
-+  public void addSpecialSequence(String specSeq);
-+  
-+  /**
-+   * Registering a special sequence of characters. Such sequences may be multicharacter
-+   * operators like the shift operators in Java.
-+   * Unlike keywords, special sequences act also as separators between other tokens.
-+   * If one special sequence is the prefix of other special sequences (in Java the
-+   * shift operator <CODE>&gt;&gt;</CODE> is the prefix of the shift operator
-+   * <CODE>&gt;&gt;&gt;</CODE>), always the longest possible match is returned.
-+   * Testing on special sequences takes place after whitespaces and comments are ruled
-+   * out, but before ordinary separators are tested.
-+   * This form of <CODE>addSpecialSequence</CODE> also takes an object associated with
-+   * the special sequence, called the companion.
-+   *
-+   * @param specSeq     special sequence to register
-+   * @param companion   information object associated with this special sequence
-+   * @see #addKeyword
-+   * @see #setSeparators
-+   */  
-+  public void addSpecialSequence(String specSeq, Object companion);
-+  
-+  /**
-+   * Registering a special sequence of characters. Such sequences may be multicharacter
-+   * operators like the shift operators in Java.
-+   * Unlike keywords, special sequences act also as separators between other tokens.
-+   * If one special sequence is the prefix of other special sequences (in Java the
-+   * shift operator <CODE>&gt;&gt;</CODE> is the prefix of the shift operator
-+   * <CODE>&gt;&gt;&gt;</CODE>), always the longest possible match is returned.
-+   * Testing on special sequences takes place after whitespaces and comments are ruled
-+   * out, but before ordinary separators are tested.
-+   * This form of <CODE>addSpecialSequence</CODE> also takes an object associated with
-+   * the special sequence, called the companion.<br>
-+   * This version of <code>addSpecialSequence</code> supports a bitmask of the 
-+   * <code>F_...</code> flags to modify the general tokenizer settings (see
-+   * {@link #setParseFlags}) for this special element.
-+   *
-+   * @param specSeq     special sequence to register
-+   * @param companion   information object associated with this special sequence
-+   * @param flags       modification flags 
-+   * @see #addKeyword
-+   * @see #setSeparators
-+   */
-+  public void addSpecialSequence(String specSeq, Object companion, int flags);
-+  
-+  
-+  /**
-+   * Deregistering a special sequence from the parser.
-+   *
-+   * @param specSeq   sequence to remove
-+   */  
-+  public void removeSpecialSequence(String specSeq);
-+  
-+  /**
-+   * Retrieving the companion of the given special sequence. If the special
-+   * sequence doesn't exist the method returns <CODE>null</CODE>.
-+   *
-+   * @param specSeq   sequence to remove
-+   * @return the object associated with the special sequence
-+   */
-+  public Object getSpecialSequenceCompanion(String specSeq);
-+
-+  /**
-+   * This method returns an {@link java.util.Iterator} of {@link TokenizerProperty}
-+   * objects. Each <CODE>TokenizerProperty</CODE> object contains a special
-+   * sequence and the companion if it exists.
-+   *
-+   * @return enumeration of {@link TokenizerProperty} objects
-+   */  
-+  public Iterator getSpecialSequences();
-+  
-+  /**
-+   * Checks if the given special sequence is known to the <CODE>Tokenizer</CODE>.
-+   *
-+   * @param specSeq sequence to check
-+   * @return <CODE>true</CODE> if the block comment is known,
-+   *       <CODE>false</CODE> otherwise
-+   */  
-+  public boolean specialSequenceExists(String specSeq);
-+  
-+  /**
-+   * Registering a keyword. If the keyword is already known to the <CODE>Tokenizer</CODE>
-+   * then it is simply re-registered. If the known keyword has an associated 
-+   * companion it will be removed.
-+   *
-+   * @param keyword   keyword to register
-+   */
-+  public void addKeyword(String keyword);
-+  
-+  /**
-+   * Registering a keyword. If the keyword is already known to the <CODE>Tokenizer</CODE>
-+   * then it is simply re-registered. If the known keyword has an associated
-+   * companion it will be replaced against the given one.
-+   *
-+   * @param keyword   keyword to register
-+   * @param companion information object associated with this keyword
-+   */  
-+  public void addKeyword(String keyword, Object companion);
-+  
-+  /**
-+   * Registering a keyword. If the keyword is already known to the <CODE>Tokenizer</CODE>
-+   * then it is simply re-registered. If the known keyword has an associated
-+   * companion it will be replaced against the given one.<br>
-+   * This version of <code>addKeyword</code> supports a bitmask of the 
-+   * <code>F_...</code> flags to modify the general tokenizer settings (see
-+   * {@link #setParseFlags}) for this special element.
-+   *
-+   * @param keyword   keyword to register
-+   * @param companion information object associated with this keyword
-+   * @param flags       modification flags 
-+   */  
-+  public void addKeyword(String keyword, Object companion, int flags);
-+  
-+  /**
-+   * Deregistering a keyword from the parser. If the keyword is not known
-+   * then the method does nothing.
-+   *
-+   * @param keyword   keyword to remove
-+   */  
-+  public void removeKeyword(String keyword);
-+  
-+  /**
-+   * Retrieving the companion of the given special sequence. If the special
-+   * sequence doesn't exist the method returns <CODE>null</CODE>.
-+   *
-+   * @param keyword   keyword thats companion is sought
-+   * @return the object associated with the keyword
-+   */
-+  public Object getKeywordCompanion(String keyword);
-+
-+  /**
-+   * This method returns an {@link java.util.Iterator} of {@link TokenizerProperty}
-+   * objects. Each <CODE>TokenizerProperty</CODE> object contains a keyword and 
-+   * the companion if it exists.
-+   *
-+   * @return enumeration of {@link TokenizerProperty} objects
-+   */  
-+  public Iterator getKeywords();
-+  
-+  /**
-+   * Checks if the given keyword is known to the <CODE>Tokenizer</CODE>.
-+   *
-+   * @param keyword   keyword to search
-+   * @return <CODE>true</CODE> if the keyword is known,
-+   *        <CODE>false</CODE> otherwise
-+   */  
-+  public boolean keywordExists(String keyword);
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // parser operations
-+  //
-+
-+  /**
-+   * Checking if there are more tokens available. This method will return
-+   * <code>true</code> until and enf-of-file condition is encountered during a 
-+   * call to {@link #nextToken} or {@link #next}.<br>
-+   * That means, that the EOF is returned one time, afterwards <code>hasMoreToken</code>
-+   * will return <code>false</code>. Furthermore, that implies, that the method
-+   * will return <code>true</code> at least once, even if the input data stream
-+   * is empty.<br>
-+   * The method can be conveniently used in a while loop.
-+   *
-+   * @return  <code>true</code> if a call to {@link #nextToken} or {@link #next}
-+   *          will succed, <code>false</code> otherwise
-+   */
-+  public boolean hasMoreToken();
-+  
-+  
-+  /**
-+   * Retrieving the next {@link Token}. The method works in this order:<br>
-+   *<ol><li>
-+   *   Check for an end-of-file condition. If there is such a condition then
-+   *   return it.
-+   *</li><li>
-+   *   Try to collect a sequence of whitespaces. If such a sequence can be found
-+   *   return if the flag <CODE>F_RETURN_WHITESPACES</CODE> is set, or skip these
-+   *   whitespaces.
-+   *</li><li>
-+   *   Check the next characters against all known line and block comments. If
-+   *   a line or block comment starting sequence matches, return if the flag
-+   *   <CODE>F_RETURN_WHITESPACES</CODE> is set, or skip the comment.
-+   *   If comments are returned they include their starting and ending sequences
-+   *   (newline in the case of a line comment)
-+   *</li><li>
-+   *   Check the next characters against all known string starting sequences. If
-+   *   a string begin could be identified return the string until and including
-+   *   the closing sequence
-+   *</li><li>
-+   *   Check the next characters against all known special sequences. Especially,
-+   *   find the longest possible match. If a special sequence could be identified
-+   *   then return it.
-+   *</li><li>
-+   *   Check for ordinary separators. If one could be found return it.
-+   *</li><li>
-+   *   Check the next characters against all known keywords. If a keyword could
-+   *   be identified then return it.
-+   *</li><li>
-+   *   Return the text portion until the next whitespace, comment, special
-+   *   sequence or separator.
-+   *</li></ol>
-+   *
-+   * @return found {@link Token} including the EOF token
-+   * @throws TokenizerException generic exception (list) for all problems that may occur while parsing
-+   * (IOExceptions for instance)
-+   */
-+  public Token nextToken() throws TokenizerException;
-+ 
-+  /**
-+   * This method is a convenience method. It returns only the next token image
-+   * without any informations about its type or associated information.
-+   *
-+   * @return the token image of the next token
-+   * @throws TokenizerException generic exception (list) for all problems that may occur while parsing
-+   * (IOExceptions for instance)
-+   */
-+  public String next() throws TokenizerException;
-+ 
-+  /**
-+   * Retrieve the {@link Token} that was found by the last call to {@link #nextToken}.
-+   * @return the token that was found by the last call to <CODE>nextToken</CODE>
-+   * or <CODE>next</CODE>
-+   */
-+  public Token currentToken();
-+ 
-+  /**
-+   * Convenience method to retrieve only the token image of the {@link Token} that
-+   * would be returned by {@link #currentToken}.
-+   *
-+   * @return the token image of the current token
-+   * @see #currentToken
-+   */
-+  public String current();
-+
-+  
-+  //---------------------------------------------------------------------------
-+  // line and column positions
-+  //
-+  
-+  /**
-+   * If the flag {@link Tokenizer#F_COUNT_LINES} is set, this method will return the
-+   * line number starting with 0 in the input stream. The implementation of the
-+   * <CODE>Tokenizer</CODE> interface can decide which end-of-line sequences should
-+   * be recognized. The most flexible approach is to process the following 
-+   * end-of-line sequences:
-+   * <br><ul><li>
-+   * Carriage Return (ASCII 13, '\r'). This EOL is used on Apple Macintosh
-+   * </li><li>
-+   * Linefeed (ASCII 10, '\n'). This is the UNIX EOL character.
-+   * </li><li>
-+   * Carriage Return + Linefeed ("\r\n"). This is used on MS Windows systems.
-+   * </li></ul>
-+   * Another legitime and in many cases satisfying way is to use the system 
-+   * property "line.separator".
-+   *
-+   * @return the current line number starting with 0 or -1 if no line numbers are supplied.
-+   * @see #getColumnNumber
-+   */  
-+  public int getLineNumber();
-+  
-+  /**
-+   * If the flag {@link Tokenizer#F_COUNT_LINES} is set, this method will return the
-+   * current column positionstarting with 0 in the input stream.
-+   *
-+   * @return the current column position
-+   * @see #getLineNumber
-+   */  
-+  public int getColumnNumber();
-+  
-+  //---------------------------------------------------------------------------
-+  // text range operations
-+  //
-+  
-+  /**
-+   * This method returns the absolute offset in characters to the start of the
-+   * parsed stream. Together with {@link #currentlyAvailable} it describes the
-+   * currently available text "window".<br>
-+   * The position returned by this method and also by {@link getReadPosition}
-+   * are absolute rather than relative in a text buffer to give the tokenizer
-+   * the full control of how and when to refill its text buffer.
-+   *
-+   * @return the absolute offset of the current text window in characters from 
-+   *         the start of the data source of the Tokenizer
-+   */
-+  public int getRangeStart();
-+  
-+  /**
-+   * Getting the current read offset. This is the absolute position where the
-+   * next call to <CODE>nextToken</CODE> or <CODE>next</CODE> will start. It is
-+   * therefore <b><k>not</k></b> the same as the position returned by 
-+   * {@link Token#getStartPosition} of the current token ({@link #currentToken}). 
-+   *<br>
-+   * The position returned by this method and also by {@link getRangeStart}
-+   * are absolute rather than relative in a text buffer to give the tokenizer
-+   * the full control of how and when to refill its text buffer.
-+   *
-+   * @return the absolute offset in characters from the start of the data source 
-+   *         of the Tokenizer where reading will be continued
-+   */
-+  public int getReadPosition();
-+  
-+  /**
-+   * Retrieving the number of the currently available characters. This includes
-+   * both characters already parsed by the <CODE>Tokenizer</CODE> and characters
-+   * still to be analyzed.<br>
-+   *
-+   * @return number of currently available characters
-+   */
-+  public int currentlyAvailable();
-+  
-+  /**
-+   * Retrieve text from the currently available range. The start and length
-+   * parameters must be inside {@link getRangeStart} and
-+   * {@link getRangeStart} + {@link currentlyAvailable}.
-+   *
-+   * @param start position where the text begins
-+   * @param length length of the text
-+   * @return the text beginning at the given position ith the given length
-+   * @throws IndexOutOfBoundsException if the starting position or the length is out of the current
-+   * text window
-+   */
-+  public String getText(int start, int length) throws IndexOutOfBoundsException;
-+  
-+  /**
-+   * Get a single character from the current text range.
-+   *
-+   * @param pos position of the required character
-+   * @return the character at the specified position
-+   * @throws IndexOutOfBoundsException if the parameter <CODE>pos</CODE> is not 
-+   *         in the available text range (text window)
-+   */
-+  public char getChar(int pos) throws IndexOutOfBoundsException;
-+  
-+  /**
-+   * Try to read more data into the text buffer of the tokenizer. This can be
-+   * useful when a method needs to look ahead of the available data or a skip
-+   * operation should be performed.<br>
-+   * The method returns the same value than an immediately following call to 
-+   * {@link currentlyAvailable} would return.<br>
-+   *
-+   * @return  the number of character now available
-+   * @throws  TokenizerException generic exception (list) for all problems that 
-+   *          may occur while reading (IOExceptions for instance)
-+   */
-+  public int readMore() throws TokenizerException;
-+  
-+  /**
-+   * This method tells the tokenizer to skip the given number of characters
-+   * starting on the current read position as can be retrieved by {@link getReadPosition}.
-+   * The given number of characters must be less or equal to 
-+   * {@link currentlyAvailable} - ({@link getReadPosition} - {@link getRangeStart}).
-+   *
-+   * @param numberOfChars   Number of characters to skip
-+   */
-+  public void skip(int numberOfChars) throws IndexOutOfBoundsException;
-+}
-diff --git a/susebox/java/util/TokenizerException.java b/susebox/java/util/TokenizerException.java
-new file mode 100644
-index 0000000..118710a
---- /dev/null
-+++ b/susebox/java/util/TokenizerException.java
-@@ -0,0 +1,211 @@
-+/*
-+ * ExceptionList.java: Interface for exception stacks
-+ *
-+ * Copyright (C) 2001 Heiko Blau
-+ *
-+ * This file belongs to the Susebox Java Core Library (Susebox JCL).
-+ * The Susebox JCL is free software; you can redistribute it and/or modify it 
-+ * under the terms of the GNU Lesser General Public License as published by the 
-+ * Free Software Foundation; either version 2.1 of the License, or (at your 
-+ * option) any later version.
-+ *
-+ * This software is distributed in the hope that it will be useful, but WITHOUT
-+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or 
-+ * FITNESS FOR A PARTICULAR PURPOSE. 
-+ * See the GNU Lesser General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU Lesser General Public License along
-+ * with the Susebox JCL. If not, write to the
-+ *
-+ *   Free Software Foundation, Inc.
-+ *   59 Temple Place, Suite 330, 
-+ *   Boston, MA 02111-1307 
-+ *   USA
-+ *
-+ * or check the Internet: http://www.fsf.org
-+ *
-+ * Contact:
-+ *   email: heiko@susebox.de 
-+ */
-+
-+package de.susebox.java.util;
-+
-+//------------------------------------------------------------------------------
-+// Imports
-+//
-+
-+import java.text.MessageFormat;
-+import de.susebox.java.lang.ExceptionList;
-+
-+
-+//------------------------------------------------------------------------------
-+// TokenizerException - definition
-+//
-+
-+/**<p>
-+ * Wrapper exception for all the problems that may occur while parsing. There
-+ * are IOExceptions, SQLExceptions etc. that can all happen when a {@link Tokenizer}
-+ * tries to extract the next token.
-+ *</p><p>
-+ * The class supports formats and format arguments beside the usual plain 
-+ * exception message string.
-+ *</p>
-+ *
-+ * @version	1.00, 2001/07/10
-+ * @author 	Heiko Blau
-+ */
-+public class TokenizerException 
-+  extends     Exception 
-+  implements  ExceptionList 
-+{
-+  //---------------------------------------------------------------------------
-+  // methods of the ExceptionList interface
-+  //
-+  
-+  /**
-+   * Method to traverse the exception list. By convention, <CODE>nextException</CODE>
-+   * returns the "earlier" exception. By walking down the exception list one gets the
-+   * the following meaning:<br>
-+   * this happened because nextException happened because nextException happened...
-+   *
-+   * @return the "earlier" exception
-+   */  
-+  public Exception nextException() {
-+		return _next;
-+	}
-+
-+  /**
-+   * Check if <CODE>this</CODE> is only a exception that wraps the real one. This
-+   * might be nessecary to pass an exception incompatible to a method declaration.
-+   *
-+   * @return <CODE>true</CODE> if this is a wrapper exception,
-+   *         <CODE>false</CODE> otherwise
-+   */  
-+	public boolean isWrapperException() {
-+		return _isWrapper;
-+	}
-+
-+  
-+  //---------------------------------------------------------------------------
-+  // constructors
-+  //
-+  
-+  /**
-+   * This constructor should be used for wrapping another exception. While reading
-+   * data an IOException may occur, but the {@link Tokenizer} interface requires a
-+   * <code>TokenizerException</code>. Simply use:
-+   *<blockquote><pre>
-+   * try {
-+   *   ...
-+   * } catch (IOException ex) {
-+   *   throw new TokenizerException(ex);
-+   * }
-+   *</pre></blockquote>
-+   *
-+   * @param ex the exception to wrap
-+   */  
-+	public TokenizerException(Exception ex) {
-+		this(ex, null, null);
-+	}
-+
-+  /**
-+   * If one likes to add ones own information to an exception, this constructor is
-+   * the easiest way to do so. By using such an approach a exception trace with useful
-+   * additional informations (which file could be found, what username is unknown)
-+   * can be realized:
-+   *<blockquote><pre>
-+   * try {
-+   *   ...
-+   * } catch (IOException ex) {
-+   *   throw new TokenizerException(ex, "while tokenizing " + path);
-+   * }
-+   *</pre></blockquote>
-+   *
-+   * @param ex    the inner exception
-+   * @param msg   exception message
-+   */  
-+	public TokenizerException(Exception ex, String msg) {
-+		this(ex, msg, null);
-+	}
-+
-+  /**
-+   * This constructor takes a format string and its arguments. The format string
-+   * must have a form that can be used by {@link java.text.MessageFormat} methods.
-+   * That means:
-+   *<blockquote><pre>
-+   *    java.text.Message.format(fmt, args)
-+   *</pre></blockquote>
-+   * is similar to
-+   *<blockquote><pre>
-+   *    new TokenizerException(fmt, args).getMessage();
-+   *</pre></blockquote>
-+   *
-+   * @param fmt   exception message
-+   * @param args  arguments for the given format string
-+   */  
-+	public TokenizerException(String fmt, Object[] args) {
-+    this(null, fmt, args);
-+	}
-+
-+  /**
-+   * This is the most complex way to construct a <CODE>TokenizerException</CODE>.
-+   * An inner exception is accompanied by a format string and its arguments.
-+   * Use this constructor in language-sensitive contexts or for formalized messages.
-+   * The meaning of the parameters is explained in the other constructors.
-+   *
-+   * @param ex    the inner exception
-+   * @param fmt   exception message
-+   * @param args  arguments for the given format string
-+   */  
-+	public TokenizerException(Exception ex, String fmt, Object[] args) {
-+		super(fmt);
-+    
-+    if (ex != null && fmt == null) {
-+      _isWrapper = true;
-+    } else {
-+      _isWrapper = false;
-+    }
-+    _next = ex;
-+	}
-+
-+
-+  //---------------------------------------------------------------------------
-+  // overridden methods
-+  //
-+  
-+  /**
-+   * Implementation of the standard {@link java.Throwable#getMessage} method to 
-+   * meet the requirements of formats and format arguments as well as wrapper
-+   * exceptions.
-+   * If this is a wrapper exception then the <CODE>getMessage</CODE> of the wrapped 
-+   * exception is returned.
-+   * If no arguments were given in the constructor then the format parameter is
-+   * taken as the formatted message itself. Otherwise it is treated like the
-+   * patter for the {@link java.text.MessageFormat#format} method.
-+   *
-+   * @return  the formatted exception message
-+   * @see     java.text.MessageFormat
-+   */  
-+	public String getMessage() {
-+    if (isWrapperException()) {
-+      return nextException().getMessage();
-+    } else {
-+      String fmt = super.getMessage();
-+
-+      if (_args == null) {
-+        return fmt;
-+      } else {
-+        return MessageFormat.format(fmt, _args);
-+      }
-+    }
-+	}
-+
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // members
-+  //
-+  protected Object[]  _args       = null;
-+  protected Exception _next       = null;
-+  protected boolean   _isWrapper  = false;
-+}
-diff --git a/susebox/java/util/TokenizerProperty.class b/susebox/java/util/TokenizerProperty.class
-new file mode 100644
-index 0000000..9bfa107
-Binary files /dev/null and b/susebox/java/util/TokenizerProperty.class differ
-diff --git a/susebox/java/util/TokenizerProperty.java b/susebox/java/util/TokenizerProperty.java
-new file mode 100644
-index 0000000..7e88489
---- /dev/null
-+++ b/susebox/java/util/TokenizerProperty.java
-@@ -0,0 +1,194 @@
-+/*
-+ * TokenizerProperty.java: Various characteristics of Tokenizer.
-+ *
-+ * Copyright (C) 2001 Heiko Blau
-+ *
-+ * This file belongs to the Susebox Java Core Library (Susebox JCL).
-+ * The Susebox JCL is free software; you can redistribute it and/or modify it 
-+ * under the terms of the GNU Lesser General Public License as published by the 
-+ * Free Software Foundation; either version 2.1 of the License, or (at your 
-+ * option) any later version.
-+ *
-+ * This software is distributed in the hope that it will be useful, but WITHOUT
-+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or 
-+ * FITNESS FOR A PARTICULAR PURPOSE. 
-+ * See the GNU Lesser General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU Lesser General Public License along
-+ * with the Susebox JCL. If not, write to the
-+ *
-+ *   Free Software Foundation, Inc.
-+ *   59 Temple Place, Suite 330, 
-+ *   Boston, MA 02111-1307 
-+ *   USA
-+ *
-+ * or check the Internet: http://www.fsf.org
-+ *
-+ * Contact:
-+ *   email: heiko@susebox.de 
-+ */
-+
-+package de.susebox.java.util;
-+
-+//-----------------------------------------------------------------------------
-+// Imports
-+//
-+
-+
-+//-----------------------------------------------------------------------------
-+// Class TokenizerProperty
-+//
-+
-+/**
-+ * This class is used by {@link Tokenizer} implementations to return enumerations
-+ * of their various properties (keywords, special sequences etc.).
-+ *
-+ * @see Token
-+ * @see Tokenizer
-+ * @author Heiko Blau
-+ */
-+public class TokenizerProperty {
-+  
-+  //---------------------------------------------------------------------------
-+  // getter- and setter methods
-+  //
-+  
-+  /**
-+   * Setting the type of the <CODE>TokenizerProperty</CODE>. One of the constants
-+   * defined in {@link Token} is expected.
-+   *
-+   * @param type type of the tokenizer property
-+   */  
-+  public void setType(int type) {
-+    _type = type;
-+  }
-+    
-+  /**
-+   * Retrieving the type of this property.
-+   *
-+   * @return type of the property
-+   * @see #setType
-+   */  
-+  public int getType() {
-+    return _type;
-+  }
-+
-+  /**
-+   * Setting flags. These flags are not specified here. They are used by the
-+   * {@link AbstractTokenizer} to store the specific parse flags for a token.
-+   *
-+   * @param flags   a bitmask
-+   */  
-+  public void setFlags(int flags) {
-+    _flags = flags;
-+  }
-+    
-+  /**
-+   * Retrieving the flags of this property.
-+   *
-+   * @return flags of the property
-+   * @see #setFlags
-+   */  
-+  public int getFlags() {
-+    return _flags;
-+  }
-+
-+  /**
-+   * Values are quite different. Starting sequences of line comments, keywords 
-+   * and special sequences are strings representing only themselfes. Whitespaces
-+   * and separators are represented as string consisting of the single whitespace
-+   * and separator characters and / or character ranges.<br>
-+   * A block comment is represented an array of two strings. The first is the 
-+   * starting sequence, the second the finishing sequence.<br>
-+   */
-+  public void setValues(String[] values) {
-+    _values = values;
-+  }
-+    
-+  public String[] getValues() {
-+    return _values;
-+  }
-+    
-+  /**
-+   * Some token may have associated informations for the user of the <CODE>Token</CODE>.
-+   * A popular thing would be the association of an integer constant to a special
-+   * sequence or keyword to be used in fast <CODE>switch</CODE> statetents.
-+   *
-+   * @param companion the associated information for this token
-+   */  
-+  public void setCompanion(Object companion) {
-+    _companion = companion;
-+  }
-+    
-+  /**
-+   * Obtaining the associated information of the token. Can be <CODE>null</CODE>. See
-+   * {@link #setCompanion} for details.
-+   *
-+   * @return the associated information of this token
-+   */  
-+  public Object getCompanion() {
-+    return _companion;
-+  }
-+  
-+ 
-+  //---------------------------------------------------------------------------
-+  // construction
-+  //
-+  
-+  /**
-+   * Default constructor.
-+   */  
-+  public TokenizerProperty() {
-+    this(Token.UNKNOWN, null, null);
-+  }
-+  
-+  /**
-+   * Constructs a <CODE>TokenizerProperty</CODE> where only the type is known so far.
-+   * For the type, one of the constants defined in {@link Token} must be used.
-+   *
-+   * @param type the property type
-+   */  
-+  public TokenizerProperty(int type) {
-+    this(type, null, null);
-+  }
-+  
-+  /**
-+   * Constructs a <CODE>TokenizerProperty</CODE> with type and value. For the type,
-+   * one of the constants defined in {@link Token} must be used.
-+   * @param type the property type
-+   * @param value the property value
-+   */  
-+  public TokenizerProperty(int type, String[] values) {
-+    this(type, values, null);
-+  }
-+  
-+  /**
-+   * Constructs a <CODE>TokenProperty</CODE> object with a complete set of type, value,
-+   * second value and companion.
-+   *
-+   */  
-+  public TokenizerProperty(int type, String[] values, Object companion) {
-+    this(type, values, companion, 0);
-+  }
-+  
-+  /**
-+   * Constructs a <CODE>TokenProperty</CODE> object with a complete set of type, value,
-+   * second value and companion.
-+   *
-+   */  
-+  public TokenizerProperty(int type, String[] values, Object companion, int flags) {
-+    setType(type);
-+    setValues(values);
-+    setCompanion(companion);
-+    setFlags(flags);
-+  }
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // members
-+  //
-+  protected int       _type;
-+  protected int       _flags;
-+  protected String[]  _values;
-+  protected Object    _companion;
-+}
-diff --git a/susebox/jtopas/InputStreamSource.class b/susebox/jtopas/InputStreamSource.class
-new file mode 100644
-index 0000000..1fc7e70
-Binary files /dev/null and b/susebox/jtopas/InputStreamSource.class differ
-diff --git a/susebox/jtopas/InputStreamSource.java b/susebox/jtopas/InputStreamSource.java
-new file mode 100644
-index 0000000..bcc780c
---- /dev/null
-+++ b/susebox/jtopas/InputStreamSource.java
-@@ -0,0 +1,170 @@
-+/*
-+ * InputStreamSource.java: Implementation of a TokenizerSource.
-+ *
-+ * Copyright (C) 2001 Heiko Blau
-+ *
-+ * This file belongs to the JTopas Library.
-+ * JTopas is free software; you can redistribute it and/or modify it 
-+ * under the terms of the GNU Lesser General Public License as published by the 
-+ * Free Software Foundation; either version 2.1 of the License, or (at your 
-+ * option) any later version.
-+ *
-+ * This software is distributed in the hope that it will be useful, but WITHOUT
-+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or 
-+ * FITNESS FOR A PARTICULAR PURPOSE. 
-+ * See the GNU Lesser General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU Lesser General Public License along
-+ * with JTopas. If not, write to the
-+ *
-+ *   Free Software Foundation, Inc.
-+ *   59 Temple Place, Suite 330, 
-+ *   Boston, MA 02111-1307 
-+ *   USA
-+ *
-+ * or check the Internet: http://www.fsf.org
-+ *
-+ * Contact:
-+ *   email: heiko@susebox.de 
-+ */
-+
-+package de.susebox.jtopas;
-+
-+
-+//-----------------------------------------------------------------------------
-+// Imports
-+//
-+import java.io.Reader;
-+import java.io.InputStreamReader;
-+
-+
-+//-----------------------------------------------------------------------------
-+// Class InputStreamSource
-+//
-+
-+/**<p>
-+ * Implementation of the {@link TokenizerSource} interface for {@link java.io.Reader}
-+ * sources, e.g. {@link java.io.InputStreamReader}.
-+ *</p><p>
-+ * The class can be compared with {@link de.susebox.java.util.InputStreamTokenizer},
-+ * that has approximately the same (own) method set. While the <code>InputStreamTokenizer</code>
-+ * is a class directly derived from {@link de.susebox.java.util.AbstractTokenizer},
-+ * <code>InputStreamSource</code> is used in conjunction with the {@link PluginTokenizer}.
-+ * That way it is possible to switch from one <code>Reader</code> to
-+ * another dynamically.
-+ *</p>
-+ *
-+ * @see     de.susebox.java.util.Tokenizer
-+ * @see     de.susebox.java.util.AbstractTokenizer
-+ * @see     PluginTokenizer
-+ * @see     java.io.Reader
-+ * @author  Heiko Blau
-+ */
-+public class InputStreamSource implements TokenizerSource {
-+  
-+  //---------------------------------------------------------------------------
-+  // Interface methods
-+  //
-+  
-+  /**
-+   * A basic method to supply data to a {@link de.susebox.java.util.Tokenizer}.
-+   *
-+   * @param cbuf      buffer to receive data
-+   * @param offset    position from where the data should be inserted in <CODE>cbuf</CODE>
-+   * @param maxChars  maximum number of characters to be read into <CODE>cbuf</CODE>
-+   * @return actually read characters or -1 on an end-of-file condition
-+   * @throws Exception anything that could happen during read, most likely {@link java.io.IOException}
-+   */
-+  public int read(char[] cbuf, int offset, int maxChars) throws Exception {
-+    if (_reader != null) {
-+      return _reader.read(cbuf, offset, maxChars);
-+    } else {
-+      return -1;
-+    }
-+  }
-+
-+  /**
-+   * When registering an instance that implements this interface, the 
-+   * {@link PluginTokenizer} will call this method to make itself known to
-+   * the <code>SeparatorHandler</code> instance in turn.
-+   *
-+   * @param tokenizer   the controlling {@link PluginTokenizer}
-+   */
-+  public void setTokenizer(PluginTokenizer tokenizer) {}
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // Constructors
-+  //
-+  
-+  /**
-+   * Default constructor. Standard input {@link java.lang.System#in} is used
-+   * to construct the input stream reader.
-+   */  
-+  public InputStreamSource() {
-+    this(null, 0);
-+  }
-+
-+  /**
-+   * Constructor that takes a instantiated {@link java.io.Reader}. If 
-+   * <CODE>null</CODE> is given then standard input is used (see {@link java.lang.System#in}).
-+   *
-+   * @param Reader   input stream to be used for reading
-+   * @see   java.io.Reader
-+   */
-+  public InputStreamSource(Reader reader) {
-+    this(reader, 0);
-+  }
-+  
-+  /**
-+   * Constructor that takes a instantiated {@link java.io.Reader} and the
-+   * tokenizer control flags.
-+   * If <CODE>null</CODE> is given for the stream then standard input is used 
-+   * (see {@link java.lang.System#in}).
-+   * For the tokenizer control flags use a combination of the <CODE>F_...</CODE>
-+   * constants from the {@link Tokenizer} for this parameter.
-+   *
-+   * @param reader   input stream to be used for reading
-+   * @param flags    tokenizer control flags
-+   * @see   java.lang.InputStream
-+   * @see   Tokenizer
-+   */
-+  public InputStreamSource(Reader reader, int flags) {
-+    setReader((reader != null) ? reader : new InputStreamReader(System.in));
-+  }
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // Getter and setter
-+  //
-+  
-+  /** 
-+   * Setting the source for the {@link #read} method. Using this method instead
-+   * of {@link PluginTokenizer#setSource} will exchange an input stream without
-+   * the <code>Tokenizer</code> realizing the fact.
-+   *
-+   * @param reader    the new source for the {@link #read} method
-+   */
-+  public void setReader(Reader reader) {
-+    _reader = reader;
-+  }
-+  
-+  /**
-+   * Retrieving the current {@link java.io.InputStreamReader}. Note that the 
-+   * {@link de.susebox.java.util.Tokenizer} probably read ahead a huge part or 
-+   * even all data from this source. So dont try to be smart and cache data while 
-+   * the <code>Tokenizer</code> does the same. Unless, of course, You know why
-+   * You like to read ahead Yourself.
-+   *
-+   * @return the current source of the tokenizer
-+   */
-+  public Reader getReader() {
-+    return _reader;
-+  }
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // Members
-+  //
-+  protected Reader _reader = null;
-+}
-diff --git a/susebox/jtopas/Plugin.class b/susebox/jtopas/Plugin.class
-new file mode 100644
-index 0000000..48adeb9
-Binary files /dev/null and b/susebox/jtopas/Plugin.class differ
-diff --git a/susebox/jtopas/Plugin.java b/susebox/jtopas/Plugin.java
-new file mode 100644
-index 0000000..d8e4899
---- /dev/null
-+++ b/susebox/jtopas/Plugin.java
-@@ -0,0 +1,56 @@
-+/*
-+ * Plugin.java: Plugin for the PluginTokenizer.
-+ *
-+ * Copyright (C) 2001 Heiko Blau
-+ *
-+ * This file belongs to the JTopas Library.
-+ * JTopas is free software; you can redistribute it and/or modify it 
-+ * under the terms of the GNU Lesser General Public License as published by the 
-+ * Free Software Foundation; either version 2.1 of the License, or (at your 
-+ * option) any later version.
-+ *
-+ * This software is distributed in the hope that it will be useful, but WITHOUT
-+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or 
-+ * FITNESS FOR A PARTICULAR PURPOSE. 
-+ * See the GNU Lesser General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU Lesser General Public License along
-+ * with JTopas. If not, write to the
-+ *
-+ *   Free Software Foundation, Inc.
-+ *   59 Temple Place, Suite 330, 
-+ *   Boston, MA 02111-1307 
-+ *   USA
-+ *
-+ * or check the Internet: http://www.fsf.org
-+ *
-+ * Contact:
-+ *   email: heiko@susebox.de 
-+ */
-+
-+package de.susebox.jtopas;
-+
-+
-+//-----------------------------------------------------------------------------
-+// Interface Plugin
-+//
-+
-+/**<p>
-+ * This is the base interface for all handler pluggins in the {@link PluginTokenizer}.
-+ *</p>
-+ *
-+ * @see     de.susebox.java.util.Tokenizer
-+ * @see     de.susebox.java.util.AbstractTokenizer
-+ * @author  Heiko Blau
-+ */
-+public interface Plugin {
-+  
-+  /**
-+   * When registering an instance that implements this interface, the 
-+   * {@link PluginTokenizer} will call this method to make itself known to
-+   * the <code>SeparatorHandler</code> instance in turn.
-+   *
-+   * @param tokenizer   the controlling {@link PluginTokenizer}
-+   */
-+  public void setTokenizer(PluginTokenizer tokenizer);
-+}
-diff --git a/susebox/jtopas/PluginTokenizer.class b/susebox/jtopas/PluginTokenizer.class
-new file mode 100644
-index 0000000..f64f19b
-Binary files /dev/null and b/susebox/jtopas/PluginTokenizer.class differ
-diff --git a/susebox/jtopas/PluginTokenizer.java b/susebox/jtopas/PluginTokenizer.java
-new file mode 100644
-index 0000000..7622f08
---- /dev/null
-+++ b/susebox/jtopas/PluginTokenizer.java
-@@ -0,0 +1,357 @@
-+/*
-+ * PluginTokenizer.java: Implementation of a Tokenizer with handler slots.
-+ *
-+ * Copyright (C) 2001 Heiko Blau
-+ *
-+ * This file belongs to the JTopas Library.
-+ * JTopas is free software; you can redistribute it and/or modify it 
-+ * under the terms of the GNU Lesser General Public License as published by the 
-+ * Free Software Foundation; either version 2.1 of the License, or (at your 
-+ * option) any later version.
-+ *
-+ * This software is distributed in the hope that it will be useful, but WITHOUT
-+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or 
-+ * FITNESS FOR A PARTICULAR PURPOSE. 
-+ * See the GNU Lesser General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU Lesser General Public License along
-+ * with JTopas. If not, write to the
-+ *
-+ *   Free Software Foundation, Inc.
-+ *   59 Temple Place, Suite 330, 
-+ *   Boston, MA 02111-1307 
-+ *   USA
-+ *
-+ * or check the Internet: http://www.fsf.org
-+ *
-+ * Contact:
-+ *   email: heiko@susebox.de 
-+ */
-+
-+package de.susebox.jtopas;
-+
-+//-----------------------------------------------------------------------------
-+// Imports
-+//
-+import de.susebox.java.util.Tokenizer;
-+import de.susebox.java.util.TokenizerProperty;
-+import de.susebox.java.util.TokenizerException;
-+import de.susebox.java.util.AbstractTokenizer;
-+
-+
-+//-----------------------------------------------------------------------------
-+// Class PluginTokenizer
-+//
-+
-+/**<p>
-+ * This class is an extension to {@link de.susebox.java.util.AbstractTokenizer}.
-+ * It can be used instead of ({@link de.susebox.java.util.InputStreamTokenizer}
-+ * when that class is not approbriate for the situation of the user (for instance,
-+ * if its performance is to low).
-+ *</p><p>
-+ * There is another aspect to the <code>PluginTokenizer</code>: While the
-+ * basic interface {@link de.susebox.java.util.Tokenizer} requires to add 
-+ * special sequences, comments etc. prior to the tokenizing process, 
-+ * the <code>PluginTokenizer</code> allows a more lazy approach. It is possible
-+ * to start tokenizing without such properties and leave the
-+ * decision completely to the pluggins that can be associated with an instance
-+ * of this class. Only the enumeration methods like 
-+ * {@link de.susebox.java.util.Tokenizer#getSpecialSequences} won't generally 
-+ * return anything.
-+ *</p>
-+ *
-+ * @see     de.susebox.java.util.Tokenizer
-+ * @see     de.susebox.java.util.AbstractTokenizer
-+ * @author  Heiko Blau
-+ */
-+public class PluginTokenizer extends AbstractTokenizer {
-+  
-+  //---------------------------------------------------------------------------
-+  // Abstract methods
-+  //
-+  
-+  /**
-+   * Implements the abstract method {@link AbstractTokenizer#read} by wrapping 
-+   * the {@link java.io.InputStreamReader#read} call of the JDK standard class
-+   * {@link java.io.InputStreamReader}.
-+   *
-+   * @param cbuf      buffer to receive data
-+   * @param offset    position from where the data should be inserted in <CODE>cbuf</CODE>
-+   * @param maxChars  maximum number of characters to be read into <CODE>cbuf</CODE>
-+   * @return actually read characters or -1 on an end-of-file condition
-+   * @throws Exception anything that could happen during read, most likely {@link java.io.IOException}
-+   */
-+  protected int read(char[] cbuf, int offset, int maxChars) throws Exception {
-+    if (_source != null) {
-+      return _source.read(cbuf, offset, maxChars);
-+    } else {
-+      return -1;
-+    }
-+  }
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // Constructors
-+  //
-+  
-+  /**
-+   * Default constructor. Standard input {@link java.lang.System#in} is used
-+   * to construct the input stream reader.
-+   */  
-+  public PluginTokenizer() {
-+    this(null, 0);
-+  }
-+
-+  /**
-+   * Constructor that takes an instance of type {@link TokenizerSource}. If 
-+   * <CODE>null</CODE> is given then a <code>TokenizerSource</code> working
-+   * on standard input is used ({@link java.lang.System#in}.
-+   *
-+   * @param dataSource   a {@link TokenizerSource} to provide data
-+   */
-+  public PluginTokenizer(TokenizerSource dataSource) {
-+    this(dataSource, 0);
-+  }
-+  
-+  /**
-+   * Constructor that takes a instantiated {@link java.io.InputStream} and the
-+   * tokenizer control flags.
-+   * If <CODE>null</CODE> is given for the stream then standard input is used 
-+   * ({@link java.lang.System#in}.
-+   * For the tokenizer control flags use a combination of the <CODE>F_...</CODE>
-+   * constants from the {@link Tokenizer} for this parameter.
-+   *
-+   * @param reader   input stream to be used for reading
-+   * @param flags    tokenizer control flags
-+   * @see   java.lang.InputStream
-+   * @see   Tokenizer
-+   */
-+  public PluginTokenizer(TokenizerSource dataSource, int flags) {
-+    super(flags);
-+    
-+    setSource((dataSource != null) ? dataSource: new InputStreamSource());
-+  }
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // Getter and setter
-+  //
-+  
-+  /** 
-+   * Setting the source for the tokenizer. Note that any data read from a previous
-+   * source are lost. Position, line and column counting will start from 0.
-+   * With this method it is possible to use one tokenizer on more than one
-+   * source. A common example is a list of files that are to be processed.
-+   *
-+   * @param reader    the new source for the {@link de.susebox.java.util.AbstractTokenizer#read} method
-+   */
-+  public void setSource(TokenizerSource dataSource) {
-+    if ((_source = dataSource) != null) {
-+      _source.setTokenizer(this);
-+    }
-+    reset();
-+  }
-+  
-+  /**
-+   * Retrieving the current source. Note that the Tokenizer probably read ahead a
-+   * huge part or even all data from this source.
-+   *
-+   * @return the current source of the tokenizer
-+   */
-+  public TokenizerSource getSource() {
-+    return _source;
-+  }
-+  
-+  
-+  /**
-+   * Setting a new {@link WhitespaceHandler} or removing any previously installed
-+   * <code>WhitespaceHandler</code>. If <code>null</code> is passed, the tokenizer
-+   * will fall back to the base implementation.
-+   *
-+   * @param handler   the (new) whitespace handler to use or null to remove it
-+   */
-+  public void setWhitespaceHandler(WhitespaceHandler handler) {
-+    if ((_whitespaceHandler = handler) != null) {
-+      _whitespaceHandler.setTokenizer(this);
-+    }
-+  }
-+  
-+  /**
-+   * Retrieving the current {@link WhitespaceHandler}. The method may return
-+   * <code>null</code> if there isn't any handler installed. That does not
-+   * mean, that whitespaces are not dealt with, but that whitespace parsing is
-+   * done by the base method of {@link de.susebox.java.util.AbstractTokenizer}.
-+   *
-+   * @return  the currently active whitespace handler or null, if the base
-+   *          implementation is working
-+   */
-+  public WhitespaceHandler getWhitespaceHandler() {
-+    return _whitespaceHandler;
-+  }
-+  
-+  
-+  /**
-+   * Setting a new {@link SeparatorHandler} or removing any previously installed
-+   * <code>SeparatorHandler</code>. If <code>null</code> is passed, the tokenizer
-+   * will fall back to the base implementation.
-+   *
-+   * @param handler   the (new) separator handler to use or null to remove it
-+   */
-+  public void setSeparatorHandler(SeparatorHandler handler) {
-+    if ((_separatorHandler = handler) != null) {
-+      _separatorHandler.setTokenizer(this);
-+    }
-+  }
-+  
-+  /**
-+   * Retrieving the current {@link SeparatorHandler}. The method may return
-+   * <code>null</code> if there isn't any handler installed. That does not
-+   * mean, that separators are not dealt with, but that separator parsing is
-+   * done by the base method of {@link de.susebox.java.util.AbstractTokenizer}.
-+   *
-+   * @return  the currently active {@link SeparatorHandler} or null, if the base
-+   *          implementation is working
-+   */
-+  public SeparatorHandler getSeparatorHandler() {
-+    return _separatorHandler;
-+  }
-+  
-+  
-+  /**
-+   * Setting a new {@link SequenceHandler} or removing any previously installed
-+   * one. If <code>null</code> is passed, the tokenizer will fall back to the 
-+   * base implementation.
-+   *
-+   * @param handler   the (new) {@link SequenceHandler} to use or null to remove it
-+   */
-+  public void setSequenceHandler(SequenceHandler handler) {
-+    if ((_sequenceHandler = handler) != null) {
-+      _sequenceHandler.setTokenizer(this);
-+    }
-+  }
-+  
-+  /**
-+   * Retrieving the current {@link SequenceHandler}. The method may return
-+   * <code>null</code> if there isn't any handler installed. That does not
-+   * mean, that special sequences, comments and strings are not dealt with, but 
-+   * that parsing is done by the base method of {@link de.susebox.java.util.AbstractTokenizer}.
-+   *
-+   * @return  the currently active {@link SequenceHandler} or null, if the base
-+   *          implementation is working
-+   */
-+  public SequenceHandler getSequenceHandler() {
-+    return _sequenceHandler;
-+  }
-+  
-+  
-+  //---------------------------------------------------------------------------
-+  // Overridden methods of AbstractTokenizer
-+  //
-+  
-+  /**
-+   * This method checks if the character is a whitespace. It will use an installed
-+   * {@link WhitespaceHandler} or switch back to the base implementation.
-+   *
-+   * @param testChar  check this character
-+   * @return <CODE>true</CODE> if a whitespace sequence was found at the given offset,
-+   *         <CODE>false</CODE> otherwise
-+   * @see #setWhitespaceHandler
-+   */
-+  protected boolean isWhitespace(char testChar) {
-+    if (_whitespaceHandler != null) {
-+      return _whitespaceHandler.isWhitespace(testChar);
-+    } else {
-+      return super.isWhitespace(testChar);
-+    }
-+  }
-+  
-+  
-+  /**
-+   * This method detects the number of whitespace characters starting at the given
-+   * position. It should use {@link getChar} to retrieve a character to check.
-+   *<br>
-+   * The method should return the number of characters identified as whitespaces
-+   * starting from and including the given start position.
-+   *<br>
-+   * Do not attempt to actually read more data or do anything that leads to the
-+   * change of the data source or to tokenizer switching. This is done by the 
-+   * tokenizer framework.
-+   *
-+   * @param   startingAtPos start checking for whitespace from this position
-+   * @param   maxChars      if there is no non-whitespace character, read up to this number of characters 
-+   * @return  number of whitespace characters starting from the given offset
-+   * @throws  TokenizerException failure while reading data from the input stream
-+   */
-+  protected int readWhitespaces(int startingAtPos, int maxChars) 
-+    throws TokenizerException 
-+  {
-+    if (_whitespaceHandler != null) {
-+      return _whitespaceHandler.readWhitespaces(startingAtPos, maxChars);
-+    } else {
-+      return super.readWhitespaces(startingAtPos, maxChars);
-+    }
-+  }
-+  
-+  
-+  /**
-+   * This method checks the given character if it is a separator.
-+   * Implement Your own code for situations where this default implementation 
-+   * is not fast enough or otherwise not really good.
-+   *
-+   * @param testChar  check this character
-+   * @return <CODE>true</CODE> if the given character is a separator,
-+   *         <CODE>false</CODE> otherwise
-+   */
-+  protected boolean isSeparator(char testChar) {
-+    if (_separatorHandler != null) {
-+      return _separatorHandler.isSeparator(testChar);
-+    } else {
-+      return super.isSeparator(testChar);
-+    }
-+  }
-+
-+  
-+  /**
-+   * This method checks at the given position if it contains a a special sequence. 
-+   * If a {@link SequenceHandler} is installed then it will be used to identify 
-+   * the starting sequences of comments, strings or single special sequences.
-+   * The <code>SequenceHandler</code> informs the <code>Tokenizer</code> about the
-+   * maximum possible length of any of these sequences 
-+   * (see {@link SequenceHandler#getSequenceMaxLength}).
-+   *<br>
-+   * That way the tokenizer is able to provide a sufficient amount of data to the 
-+   * <code>SequenceHandler</code>. If there are less characters than the maximum 
-+   * length provided, the <code>Tokenizer</code> is near EOF.
-+   *<br>
-+   * The 
-+   *
-+   * @param  startingAtPos  start checking for sequences from this position
-+   * @throws TokenizerException failure while reading data from the input stream
-+   * @return a {@link de.susebox.java.util.TokenizerProperty} if a special sequence 
-+   *         was found at the given position or <CODE>null</CODE> otherwise
-+   */
-+  protected TokenizerProperty isSequenceCommentOrString(int startingAtPos) throws TokenizerException {
-+    if (_sequenceHandler != null) {
-+      int available = currentlyAvailable() - (startingAtPos - getRangeStart());
-+      int maxLength = _sequenceHandler.getSequenceMaxLength();
-+      
-+      if (maxLength > 0 && available < maxLength) {
-+        readMore();
-+        available = currentlyAvailable() - (startingAtPos - getRangeStart());
-+      }
-+      return _sequenceHandler.isSequenceCommentOrString(startingAtPos, available);
-+    } else {
-+      return super.isSequenceCommentOrString(startingAtPos);
-+    }
-+  }
-+
-+  
-+    
-+  //---------------------------------------------------------------------------
-+  // Members
-+  //
-+  private TokenizerSource   _source            = null;
-+  private WhitespaceHandler _whitespaceHandler = null;
-+  private SeparatorHandler  _separatorHandler  = null;
-+  private SequenceHandler   _sequenceHandler   = null;
-+}
-diff --git a/susebox/jtopas/SeparatorHandler.class b/susebox/jtopas/SeparatorHandler.class
-new file mode 100644
-index 0000000..c54b3ab
-Binary files /dev/null and b/susebox/jtopas/SeparatorHandler.class differ
-diff --git a/susebox/jtopas/SeparatorHandler.java b/susebox/jtopas/SeparatorHandler.java
-new file mode 100644
-index 0000000..1decdf0
---- /dev/null
-+++ b/susebox/jtopas/SeparatorHandler.java
-@@ -0,0 +1,57 @@
-+/*
-+ * SeparatorHandler.java: Pluggin for the PluginTokenizer.
-+ *
-+ * Copyright (C) 2001 Heiko Blau
-+ *
-+ * This file belongs to the JTopas Library.
-+ * JTopas is free software; you can redistribute it and/or modify it 
-+ * under the terms of the GNU Lesser General Public License as published by the 
-+ * Free Software Foundation; either version 2.1 of the License, or (at your 
-+ * option) any later version.
-+ *
-+ * This software is distributed in the hope that it will be useful, but WITHOUT
-+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or 
-+ * FITNESS FOR A PARTICULAR PURPOSE. 
-+ * See the GNU Lesser General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU Lesser General Public License along
-+ * with JTopas. If not, write to the
-+ *
-+ *   Free Software Foundation, Inc.
-+ *   59 Temple Place, Suite 330, 
-+ *   Boston, MA 02111-1307 
-+ *   USA
-+ *
-+ * or check the Internet: http://www.fsf.org
-+ *
-+ * Contact:
-+ *   email: heiko@susebox.de 
-+ */
-+
-+package de.susebox.jtopas;
-+
-+
-+//-----------------------------------------------------------------------------
-+// Interface SeparatorHandler
-+//
-+
-+/**<p>
-+ * This interface must be implemented by classes that should be used as a 
-+ * separator handler pluggin in the {@link PluginTokenizer}.
-+ *</p>
-+ *
-+ * @see     de.susebox.java.util.Tokenizer
-+ * @see     de.susebox.java.util.AbstractTokenizer
-+ * @author  Heiko Blau
-+ */
-+public interface SeparatorHandler extends Plugin {
-+  
-+  /**
-+   * This method checks if the character is a separator.
-+   *
-+   * @param testChar  check this character
-+   * @return <CODE>true</CODE> if the given character is a separator,
-+   *         <CODE>false</CODE> otherwise
-+   */
-+  public boolean isSeparator(char testChar);
-+}
-diff --git a/susebox/jtopas/SequenceHandler.class b/susebox/jtopas/SequenceHandler.class
-new file mode 100644
-index 0000000..bbde096
-Binary files /dev/null and b/susebox/jtopas/SequenceHandler.class differ
-diff --git a/susebox/jtopas/SequenceHandler.java b/susebox/jtopas/SequenceHandler.java
-new file mode 100644
-index 0000000..e71f294
---- /dev/null
-+++ b/susebox/jtopas/SequenceHandler.java
-@@ -0,0 +1,87 @@
-+/*
-+ * SequenceHandler.java: Pluggin for the PluginTokenizer.
-+ *
-+ * Copyright (C) 2001 Heiko Blau
-+ *
-+ * This file belongs to the JTopas Library.
-+ * JTopas is free software; you can redistribute it and/or modify it 
-+ * under the terms of the GNU Lesser General Public License as published by the 
-+ * Free Software Foundation; either version 2.1 of the License, or (at your 
-+ * option) any later version.
-+ *
-+ * This software is distributed in the hope that it will be useful, but WITHOUT
-+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or 
-+ * FITNESS FOR A PARTICULAR PURPOSE. 
-+ * See the GNU Lesser General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU Lesser General Public License along
-+ * with JTopas. If not, write to the
-+ *
-+ *   Free Software Foundation, Inc.
-+ *   59 Temple Place, Suite 330, 
-+ *   Boston, MA 02111-1307 
-+ *   USA
-+ *
-+ * or check the Internet: http://www.fsf.org
-+ *
-+ * Contact:
-+ *   email: heiko@susebox.de 
-+ */
-+
-+package de.susebox.jtopas;
-+
-+//-----------------------------------------------------------------------------
-+// Imports
-+//
-+import de.susebox.java.util.TokenizerProperty;
-+import de.susebox.java.util.TokenizerException;
-+
-+
-+//-----------------------------------------------------------------------------
-+// Interface SequenceHandler
-+//
-+
-+/**<p>
-+ * This interface must be implemented by classes that should be used as a 
-+ * special sequence and comment start sequence handler pluggin in the 
-+ * {@link PluginTokenizer}.
-+ *</p>
-+ *
-+ * @see     de.susebox.java.util.Tokenizer
-+ * @see     de.susebox.java.util.AbstractTokenizer
-+ * @author  Heiko Blau
-+ */
-+public interface SequenceHandler extends Plugin {
-+  
-+  /**
-+   * Return a {@link de.susebox.java.util.TokenizerProperty} if the character
-+   * starting at the given position comprise a special sequence (like the ++ operator
-+   * in C and Java or the &amp;bsp; in HTML), a comment starting sequence or
-+   * a string sign.<br>
-+   * Return <code>null</code> if no special sequence is present at the given
-+   * position.<br>
-+   * Use the {@link de.susebox.java.util.AbstractTokenizer#getCharUnchecked} to
-+   * retrieve a character from the tokenizers input buffer.
-+   *
-+   * @param  startingAtPos check from this position in the tokenizers input buffer
-+   * @throws {@link de.susebox.java.util.TokenizerException} for any problems
-+   * @return a <code>TokenizerProperty</code> instance describing the special sequence,
-+   *         comment etc. or <code>null</code> if no such thing was found. 
-+   */
-+  public TokenizerProperty isSequenceCommentOrString(int startingAtPos, int maxChars)     
-+    throws TokenizerException;
-+  
-+  /**
-+   * This method is called by the parent {@link PluginTokenizer} to learn how
-+   * many characters are needed by an instance of this interface to identify a
-+   * special sequence in the worst case. Usually that should be the length of
-+   * the longest possible special sequence, comment prefix etc.
-+   * The tokenizer will make sure that at least this number of characters is
-+   * available when {@link #isSequenceCommentOrString} is called. If less 
-+   * characters are provided, EOF is reached.
-+   *
-+   * @return  the number of characters needed in the worst case to identify a 
-+   *          special sequence
-+   */
-+  public int getSequenceMaxLength();
-+}
-diff --git a/susebox/jtopas/TokenizerSource.class b/susebox/jtopas/TokenizerSource.class
-new file mode 100644
-index 0000000..cc5a348
-Binary files /dev/null and b/susebox/jtopas/TokenizerSource.class differ
-diff --git a/susebox/jtopas/TokenizerSource.java b/susebox/jtopas/TokenizerSource.java
-new file mode 100644
-index 0000000..18c103f
---- /dev/null
-+++ b/susebox/jtopas/TokenizerSource.java
-@@ -0,0 +1,61 @@
-+/*
-+ * TokenizerSource.java: Data source for the PluginTokenizer.
-+ *
-+ * Copyright (C) 2001 Heiko Blau
-+ *
-+ * This file belongs to the JTopas Library.
-+ * JTopas is free software; you can redistribute it and/or modify it 
-+ * under the terms of the GNU Lesser General Public License as published by the 
-+ * Free Software Foundation; either version 2.1 of the License, or (at your 
-+ * option) any later version.
-+ *
-+ * This software is distributed in the hope that it will be useful, but WITHOUT
-+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or 
-+ * FITNESS FOR A PARTICULAR PURPOSE. 
-+ * See the GNU Lesser General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU Lesser General Public License along
-+ * with JTopas. If not, write to the
-+ *
-+ *   Free Software Foundation, Inc.
-+ *   59 Temple Place, Suite 330, 
-+ *   Boston, MA 02111-1307 
-+ *   USA
-+ *
-+ * or check the Internet: http://www.fsf.org
-+ *
-+ * Contact:
-+ *   email: heiko@susebox.de 
-+ */
-+
-+package de.susebox.jtopas;
-+
-+
-+//-----------------------------------------------------------------------------
-+// Interface TokenizerSource
-+//
-+
-+/**<p>
-+ * This class is an extension to {@link de.susebox.java.util.AbstractTokenizer}.
-+ * It can be used instead of ({@link de.susebox.java.util.InputStreamTokenizer}
-+ * when that class is not approbriate for the situation of the user (for instance,
-+ * if its performance is to low).
-+ *</p>
-+ *
-+ * @see     de.susebox.java.util.Tokenizer
-+ * @see     de.susebox.java.util.AbstractTokenizer
-+ * @author  Heiko Blau
-+ */
-+public interface TokenizerSource extends Plugin {
-+  
-+  /**
-+   * A basic method to supply data to a {@link de.susebox.java.util.Tokenizer}.
-+   *
-+   * @param cbuf      buffer to receive data
-+   * @param offset    position from where the data should be inserted in <CODE>cbuf</CODE>
-+   * @param maxChars  maximum number of characters to be read into <CODE>cbuf</CODE>
-+   * @return actually read characters or -1 on an end-of-file condition
-+   * @throws Exception anything that could happen during read, most likely {@link java.io.IOException}
-+   */
-+  int read(char[] cbuf, int offset, int maxChars) throws Exception;
-+}
-diff --git a/susebox/jtopas/WhitespaceHandler.class b/susebox/jtopas/WhitespaceHandler.class
-new file mode 100644
-index 0000000..14cbe85
-Binary files /dev/null and b/susebox/jtopas/WhitespaceHandler.class differ
-diff --git a/susebox/jtopas/WhitespaceHandler.java b/susebox/jtopas/WhitespaceHandler.java
-new file mode 100644
-index 0000000..ee087a4
---- /dev/null
-+++ b/susebox/jtopas/WhitespaceHandler.java
-@@ -0,0 +1,81 @@
-+/*
-+ * WhitespaceHandler.java: Pluggin for the PluginTokenizer.
-+ *
-+ * Copyright (C) 2001 Heiko Blau
-+ *
-+ * This file belongs to the JTopas Library.
-+ * JTopas is free software; you can redistribute it and/or modify it 
-+ * under the terms of the GNU Lesser General Public License as published by the 
-+ * Free Software Foundation; either version 2.1 of the License, or (at your 
-+ * option) any later version.
-+ *
-+ * This software is distributed in the hope that it will be useful, but WITHOUT
-+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or 
-+ * FITNESS FOR A PARTICULAR PURPOSE. 
-+ * See the GNU Lesser General Public License for more details.
-+ *
-+ * You should have received a copy of the GNU Lesser General Public License along
-+ * with JTopas. If not, write to the
-+ *
-+ *   Free Software Foundation, Inc.
-+ *   59 Temple Place, Suite 330, 
-+ *   Boston, MA 02111-1307 
-+ *   USA
-+ *
-+ * or check the Internet: http://www.fsf.org
-+ *
-+ * Contact:
-+ *   email: heiko@susebox.de 
-+ */
-+
-+package de.susebox.jtopas;
-+
-+
-+//-----------------------------------------------------------------------------
-+// Imports
-+//
-+import de.susebox.java.util.TokenizerException;
-+
-+
-+//-----------------------------------------------------------------------------
-+// Interface WhitespaceHandler
-+//
-+
-+/**<p>
-+ * This interface must be implemented by classes that should be used as a 
-+ * whitespace handler pluggin in the {@link PluginTokenizer}.
-+ *</p>
-+ *
-+ * @see     de.susebox.java.util.Tokenizer
-+ * @see     de.susebox.java.util.AbstractTokenizer
-+ * @author  Heiko Blau
-+ */
-+public interface WhitespaceHandler extends Plugin {
-+  
-+  /**
-+   * This method checks if the character is a whitespace.
-+   *
-+   * @param testChar  check this character
-+   * @return <CODE>true</CODE> if the given character is a whitespace,
-+   *         <CODE>false</CODE> otherwise
-+   */
-+  public boolean isWhitespace(char testChar);
-+
-+  /**
-+   * This method detects the number of whitespace characters starting at the given
-+   * position. It should use {@link getChar} to retrieve a character to check.
-+   *<br>
-+   * The method should return the number of characters identified as whitespaces
-+   * starting from and including the given start position.
-+   *<br>
-+   * Do not attempt to actually read more data or do anything that leads to the
-+   * change of the data source or to tokenizer switching. This is done by the 
-+   * tokenizer framework.
-+   *
-+   * @param   startingAtPos  start checking for whitespace from this position
-+   * @param   maxChars  if there is no non-whitespace character, read up to this number of characters 
-+   * @return  number of whitespace characters starting from the given offset
-+   * @throws  TokenizerException failure while reading data from the input stream
-+   */
-+  public int readWhitespaces(int startingAtPos, int maxChars) throws TokenizerException;
-+}
+diff --git a/tca.json b/tca.json
+index 0637a08..5dfd13e 100644
+--- a/tca.json
++++ b/tca.json
+@@ -1 +1,44 @@
+-[]
+\ No newline at end of file
++[
++    {
++        "test_id": "TestTokenizerProperties",
++        "magnitude": 0.88,
++        "phase": 3.3685,
++        "original_semantics": "new_feature_tokenizer_framework"
++    },
++    {
++        "test_id": "TestTokenProperties",
++        "magnitude": 0.66,
++        "phase": 3.3685,
++        "original_semantics": "new_feature_tokenizer_framework"
++    },
++    {
++        "test_id": "TestInputStreamTokenizer",
++        "magnitude": 0.97,
++        "phase": 3.3685,
++        "original_semantics": "new_feature_tokenizer_framework"
++    },
++    {
++        "test_id": "TestDifficultSituations",
++        "magnitude": 1.0,
++        "phase": 3.3685,
++        "original_semantics": "new_feature_tokenizer_framework"
++    },
++    {
++        "test_id": "TestEmbeddedTokenizer",
++        "magnitude": 0.87,
++        "phase": 3.3685,
++        "original_semantics": "new_feature_tokenizer_framework"
++    },
++    {
++        "test_id": "TestPluginTokenizer",
++        "magnitude": 0.91,
++        "phase": 5.1662,
++        "original_semantics": "new_feature_plugin_tokenizer"
++    },
++    {
++        "test_id": "TestTokenizerSpeed",
++        "magnitude": 0.71,
++        "phase": 0.5585,
++        "original_semantics": "performance_test"
++    }
++]
+\ No newline at end of file
